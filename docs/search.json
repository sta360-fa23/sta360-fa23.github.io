[
  {
    "objectID": "labs/lab0.html",
    "href": "labs/lab0.html",
    "title": "Hello R.",
    "section": "",
    "text": "This ‘lab 0’ will introduce you to the course computing workflow. The main goal of today is to get you setup in RStudio and play around with a few fundamental skills."
  },
  {
    "objectID": "labs/lab0.html#r-and-r-studio",
    "href": "labs/lab0.html#r-and-r-studio",
    "title": "Hello R.",
    "section": "R and R Studio",
    "text": "R and R Studio\nBelow are the components of the RStudio IDE.\n\nBelow are the components of a Quarto (.qmd) file. Note: this is essentially the same as an Rmarkdown (.Rmd) file, with a couple built-in quality of life additions."
  },
  {
    "objectID": "labs/lab0.html#yaml",
    "href": "labs/lab0.html#yaml",
    "title": "Hello R.",
    "section": "YAML",
    "text": "YAML\nThe top portion of your Quarto or R markdown file (between the three dashed lines) is called YAML. It stands for “YAML Ain’t Markup Language”. It is a human friendly data serialization standard for all programming languages. All you need to know is that this area is called the YAML (we will refer to it as such) and that it contains meta information about your document.\n\n\n\n\n\n\nImportant\n\n\n\nGo to file > new file, Quarto document. Input title “Lab 0”, and change the author name to your name. Select pdf output and press Create. Render the document. Examine the rendered document."
  },
  {
    "objectID": "labs/lab0.html#latex",
    "href": "labs/lab0.html#latex",
    "title": "Hello R.",
    "section": "LaTeX",
    "text": "LaTeX\nAssignments in this course are not required to be written in LaTeX. You may write equations by hand and scan them as a pdf to submit to Gradescope. However, LaTeX is the typesetting system to communicate statistics and mathematics professionally. It’s worthwhile to use. Moreover, it’s fully supported within .Rmd and .qmd files.\nIf you’re using R on your local machine, you may need to install\n\nMiKTeX (if you’re using windows): https://miktex.org/\nMacTeX (if you’re using macOS): https://www.tug.org/mactex/\nTeXLive (if you’re using linux): https://tug.org/texlive/\n\nTo write a LaTeX equation within your markdown document, simply use $$ to surround blocks of math and $ to surround in-line math.\nExample: copy and paste the following and then render.\nWe can see that $\\beta_0 = 2 and \\beta_1 = 3$ is the OLS solution under our model\n\n$$\ny = \\beta_0 + \\beta_1 x\n$$\n\n\n\n\n\n\n\n\nNote\n\n\n\nThere is no space between $ and math. Whitespace may cause the document to fail to render.\n\n\nCheck out this LaTeX cheatsheet to typeset a variety of math."
  },
  {
    "objectID": "labs/lab0.html#exercises",
    "href": "labs/lab0.html#exercises",
    "title": "Hello R.",
    "section": "Exercises",
    "text": "Exercises\nThe following exercises are designed to help you gain basic familiarity with R as well as the quirks of floating point arithmetic.\n\nFloating point algebra.\n\nDo floating point numbers obey the rules of algebra? For example, one of the rules of algebra is additive association. (x + y) + z == x + (y + z). Check if this is true in R using \\(x = 0.1\\), \\(y = 0.1\\) and \\(z = 1\\). Explain what you find.\n\nAdditional examples of floating point pecularity are provided below.\n\n# example 1\n0.2 == 0.6 / 3\n# example 2\npoint3 <- c(0.3, 0.4 - 0.1, 0.5 - 0.2, 0.6 - 0.3, 0.7 - 0.4)\npoint3\npoint3 == 0.3\n\nTo work around these issues, you could use all.equal() for checking the equality of two double quantities in R. What does all.equal() do?\n\n# example 1, all.equal()\nall.equal(0.2, 0.6 / 3)\n# example 2, all.equal()\npoint3 <- c(0.3, 0.4 - 0.1, 0.5 - 0.2, 0.6 - 0.3, 0.7 - 0.4)\npoint3\nall.equal(point3, rep(.3, length(point3)))\n\n\nWhat do these functions do?\n\nUse ?rnorm to read the documentation and explain the output of each of the following:\n\nrnorm(10, mean = 1, sd = 2)\npnorm(0)\ndnorm(0.5)\nqnorm(0.5)\n\nHow is dnorm(0.5) computed? Can you compute it manually?\n\nShow it numerically\n\n\\(X \\sim N(\\mu, \\sigma^2)\\) means that \\(X\\) is normally distributed with mean \\(\\mu\\) and variance \\(\\sigma^2\\). Show, using rnorm that if \\(X \\sim N(0, 1)\\) and \\(Y \\sim N(1, 2)\\) that \\(\\mathbb{E}(X + Y) = 1\\) and \\(\\mathbb{V}(X + Y) = 3\\)\n\n\n\n\nControl flow\n\n\n# for loop example\nfor (i in 1:5) {\n  cat(\"Hello\", i, \"\\n\")\n}\n\n# if else example\nx = 1\nif(x > 0) {\n  print(\"I'm positive x is greater than 0.\")\n} else {\n  print(\"I'm not so positive about x being positive\")\n}\n\nAssume there are 50 days of class. Suppose that, on any given day, there is a \\(X_i\\) probability student \\(i\\) will come to class. Every day you come to class, you obtain Y points towards your final grade. Every day that you don’t come to class, you obtain Z points towards your final grade.\nAssume \\(Y \\sim Uniform(1.9, 2)\\) and \\(Z \\sim Uniform(1, 2)\\).\nAssume student A has a 95% chance of coming to class any given day (X = 0.95) and student B has a 70% of coming to class any given day (X = 0.7). While there are more efficient ways to do this, practice using a for loop, a conditional if statement, rbinom and runif to simulate one possible final grade for each student."
  },
  {
    "objectID": "labs/lab0.html#style-guidelines",
    "href": "labs/lab0.html#style-guidelines",
    "title": "Hello R.",
    "section": "Style guidelines",
    "text": "Style guidelines\nAlthough coding is not the primary focus of this course, there are a short list below of fundamental principles we will follow. Note: some of these stylistic principles may not be followed in the text!\nFirst, it’s easy to write code that runs off the page when you render to pdf. This happens when you write more than 80 characters in a single line of code. To ensure this doesn’t happen, make sure your code doesn’t have 80 characters in a single line. To enable a vertical line in the RStudio IDE that helps you visually see the limit, go to Tools > Global Options > Code > Display > Show margin > 80. This will enable a vertical line in your .qmd files that shows you where the 80 character cutoff is for code chunks. Instructions may vary slightly for local installs of RStudio.\n\nAll binary operators should be surrounded by space. For example x + y is appropriate. x+y is not.\nAny and all pipes %>% or |> as well as ggplot layers + should be followed by a new line.\nYou should be consistent with stylistic choices, e.g. only use 1 of = vs <- and %>% vs |>\nYour name should be at the top (in the YAML) of each document under “author:”\n\nIf you have any questions about style, please ask a member of the teaching team."
  },
  {
    "objectID": "chapterSummaries.html",
    "href": "chapterSummaries.html",
    "title": "Chapter summaries",
    "section": "",
    "text": "Axioms of probability\nFor all sets \\(F\\), \\(G\\) and \\(H\\),\n\n\\(0 = Pr(\\neg H | H) \\leq Pr(F | H) \\leq Pr(H | H) = 1\\)\n\\(Pr(F \\cup G | H) = Pr(F|H) + Pr(G|H) \\text{ if } F \\cap G = \\emptyset\\)\n\\(Pr(F \\cap G | H) = Pr(G | H) Pr(F | G \\cap H)\\)\n\nPartitions and probability\nSuppose \\(\\{ H_1, \\ldots, H_K\\}\\) is a partition of \\(\\mathcal{H}\\), \\(Pr(\\mathcal{H}) = 1\\) and \\(E\\) is some specific event. From the axioms of probability one may prove:\n\nRule of total probability:\n\n\\[\\begin{equation}\n\\sum_{k = 1}^K Pr(H_k) = 1\n\\end{equation}\\]\n\nRule of marginal probability:\n\n\\[\\begin{equation}\n\\begin{aligned}\nPr(E) &= \\sum_{k = 1}^K Pr(E \\cap H_k)\\\\ &= \\sum_{k = 1}^K Pr(E | H_k) Pr(H_k)\n\\end{aligned}\n\\end{equation}\\]\n\nBayes’ theorem:\n\n\\[\\begin{equation}\nPr(H_j | E) = \\frac{Pr(E|H_j) Pr(H_j)}{Pr(E)}\n\\end{equation}\\]\nNote it is often useful to replace the denominator, \\(Pr(E)\\), using the rule of marginal probability.\nIndependence\nTwo events \\(F\\) and \\(G\\) are conditionally independent given \\(H\\) if \\(Pr(F \\cap G |H) = Pr(F|H) Pr(G|H)\\).\n\n\n\nLaw of total expectation \\(E(X) = E(E(X|Y))\\)\nLaw of total variance \\(Var(X) = E(Var(X|Y)) + Var(E(X|Y))\\)\n\n\n\n\n\n\n\nNote\n\n\n\nRemember we can always add conditioning statements e.g.\n\nLaw of total expectation \\(E(X|Z) = E(E(X|Y)|Z)\\)\nLaw of total variance \\(Var(X|Z) = E(Var(X|Y)|Z) + Var(E(X|Y)|Z)\\)"
  },
  {
    "objectID": "hw/hw03.html",
    "href": "hw/hw03.html",
    "title": "Homework 3",
    "section": "",
    "text": "Let \\(Y_1, \\ldots Y_n | \\theta\\) be an i.i.d. random sample from a population with pdf \\(p(y|\\theta)\\) where\n\\[\np(y|\\theta) = \\frac{2}{\\Gamma(a)} \\theta^{2a} y^{2a -1} e^{-\\theta^2 y^2}\n\\]\nand \\(y > 0\\), \\(\\theta > 0\\), \\(a > 0\\).\nFor this density,\n\\[\n\\begin{aligned}\nE~Y|\\theta &= \\frac{\\Gamma(a + \\frac{1}{2})}{\\theta \\Gamma(a)}\\\\\nE~Y^2|\\theta &= \\frac{a}{\\theta^2}\n\\end{aligned}\n\\]\nCall this density \\(g^2\\) such that \\(Y_1, \\ldots Y_n | \\theta \\sim g^2(a, \\theta)\\).\n\nFind the joint pdf of \\(Y_1, \\ldots Y_n | \\theta\\) and simplify as much as possible.\nSuppose \\(a\\) is known but \\(\\theta\\) is unknown. Identify a simple conjugate class of priors for \\(\\theta\\). For any arbitrary member of the class, identify the posterior density \\(p(\\theta | y_1, \\ldots y_n)\\).\nObtain a formula for \\(E~ \\theta | Y_1, \\ldots Y_n\\) when the prior is in the conjugate class."
  },
  {
    "objectID": "hw/hw03.html#exercise-2",
    "href": "hw/hw03.html#exercise-2",
    "title": "Homework 3",
    "section": "Exercise 2",
    "text": "Exercise 2\nSuppose \\(Y|\\theta \\sim \\text{binary}(\\theta)\\) and we want to use \\(\\theta \\sim \\text{Uniform}(0, 1)\\) to represent our lack of knowledge about \\(\\theta\\). However, we are interested in the log-odds \\(\\gamma = \\log \\frac{\\theta}{1 - \\theta}\\).\n\nFind the prior distribution for \\(\\gamma\\) induced by our prior on \\(\\theta\\). Is the prior informative about \\(\\gamma\\)? Verify \\(p(\\gamma)\\) using Monte Carlo sampling and then plotting the empirical density of the samples along with the closed-form solution.\nAssume some data come in and \\(y = 7\\) out of \\(n = 10\\) trials. Report the posterior mean and 95% posterior confidence interval for \\(\\gamma\\)."
  },
  {
    "objectID": "hw/hw03.html#exercise-3",
    "href": "hw/hw03.html#exercise-3",
    "title": "Homework 3",
    "section": "Exercise 3",
    "text": "Exercise 3\nSuppose an experimental machine in a lab is either fine, or comes from a bad batch of machines that are to be recalled by the manufacturer. Scientists in the lab want to estimate the failure rate of their machine and decide whether or not to return it. They encode their prior uncertainty about the failure rate \\(\\theta\\) with the following density:\n\\[\np(\\theta) = \\frac{1}{4} \\frac{\\Gamma(10)}{\\Gamma(2)\\Gamma(8)}\\left[\n3 \\theta (1 - \\theta)^7 + \\theta^7(1- \\theta)\n\\right]\n\\]\n\nMake a plot of this prior density and explain why it makes sense for the scientists. Based on the prior density, which do the scientists think is more likely - that their machine is fine, or bad?\nThe scientists run the machine \\(n\\) times. Let \\(y_i\\) be one if the machine fails on the \\(i\\)th run, and zero otherwise. Write out the posterior distribution of \\(\\theta\\) given \\(y_1, \\ldots, y_n\\) (up to a proportionality constant) and simplify as much as possible.\nFor the case that \\(n = 4\\), make a plot of the (unscaled) posterior of \\(\\theta\\) for the five cases \\(\\sum y_i \\in \\{ 0, 1, 2, 3, 4\\}\\).\nThe posterior is a mixture (weighted average) of two distributions that you know. Identify these two distributions, including their parameters."
  },
  {
    "objectID": "hw/hw02.html",
    "href": "hw/hw02.html",
    "title": "Homework 2",
    "section": "",
    "text": "Let \\(Y_1, Y_2 | \\theta\\) be i.i.d. binary(\\(\\theta\\)), so that \\(p(y_1, y_2 | \\theta) = \\theta ^{y_1 + y_2} (1- \\theta) ^{2 - y_1 - y_2}\\) and let \\(\\theta \\sim \\text{beta}(\\eta, \\eta)\\)\n\nCompute \\(E~Y_i\\) and \\(Var~Y_i\\) (the mean and variance of \\(Y_i\\) unconditional on \\(\\theta\\)) as a function of \\(\\eta\\)\nCompute \\(E~Y_1 Y_2\\), which is the same as \\(p(Y_1 = 1, Y_2 = 1)\\) unconditional on \\(\\theta\\). You can do this with help from the formula on page 33 of the book.\nUsing the terms you have calculated above, make a graph of the correlation between \\(Y_1\\) and \\(Y_2\\) as a function of \\(\\eta\\).\nInterpreting \\(\\eta\\) as how confident you are that \\(\\theta\\) is near \\(\\frac{1}{2}\\), and interpreting \\(Cor(Y_1, Y_2)\\) as how much information \\(Y_1\\) and \\(Y_2\\) provide about each other, explain in words why the correlation changes as a function of \\(\\eta\\)."
  },
  {
    "objectID": "hw/hw02.html#exercise-2",
    "href": "hw/hw02.html#exercise-2",
    "title": "Homework 2",
    "section": "Exercise 2",
    "text": "Exercise 2\nSuppose \\(n\\) individuals volunteer to count birds in a forest. Let \\(Y_i\\) be the number of birds counted by individual \\(i\\), and let \\(x_i\\) be the number of hours spent in the forest by volunteer \\(i\\). We will model the data \\(Y_1, \\ldots Y_n\\) as being independent given \\(\\theta\\), but not identically distributed. Specifically, our model is that \\(Y_i | \\theta \\sim \\text{Pois}(\\theta x_i)\\), independently for \\(i = 1, \\ldots n\\).\n\nCompute \\(E~Y_i | \\theta\\) and explain what \\(\\theta\\) represents.\nWrite out a formula for the joint pdf \\(p(y_1, \\ldots y_n |\\theta)\\) and simplify as much as possible. Find the MLE, that is, the value of \\(\\theta\\) that maximizes \\(p(y_1, \\ldots y_n | \\theta)\\). Explain why it makes sense.\nLet \\(\\theta \\sim \\text{gamma}(a, b)\\). Find a formula for the posterior mode of \\(\\theta\\) and compare to the MLE."
  },
  {
    "objectID": "hw/hw02.html#exercise-3",
    "href": "hw/hw02.html#exercise-3",
    "title": "Homework 2",
    "section": "Exercise 3",
    "text": "Exercise 3\nLet \\(\\theta_1\\) be the prevalence of a rare allele among people with Alzheimer’s disease, and let \\(\\theta_2\\) be the prevalence among people without the disease. To estimate \\(\\theta_1\\) and \\(\\theta_2\\), a sample of \\(n_1 = 19\\) Alzheimer’s patients and \\(n_2 = 176\\) control subjects are genotyped for the presence of the allele. Let \\(Y_1\\) and \\(Y_2\\) be the number of people in the two samples who have the allele. We will model \\(Y_1\\) and \\(Y_2\\) as independent with \\(Y_1 | \\theta_1 \\sim \\text{binomial}(n_1, \\theta_1)\\) and \\(Y_2 | \\theta_2 \\sim \\text{binomial}(n_2, \\theta_2)\\). Prior studies suggest that \\(\\theta_2 \\sim \\text{beta}(2, 30)\\) is a reasonable prior distribution for \\(\\theta_2\\). For now, we will use the same prior distribution for \\(\\theta_1\\). The study is performed and the data are that \\(Y_1 = 1\\) and \\(Y_2 = 16\\).\n\nState the posterior distributions of \\(\\theta_1\\) and \\(\\theta_2\\). Plot the posterior densities together on a single graph with the prior density, and compare all three curves with words.\nCompute the posterior mean and a 95% posterior interval for each of \\(\\theta_1\\) and \\(\\theta_2\\).\nWith a picture, with words, or mathematically, try to describe different kind of joint prior distribution for \\(\\theta_1\\) and \\(\\theta_2\\) that represents the \\(\\theta_1\\) and \\(\\theta_2\\) are close to each other, but highly uncertain."
  },
  {
    "objectID": "hw/hw00.html",
    "href": "hw/hw00.html",
    "title": "Homework 0",
    "section": "",
    "text": "This math assessment is meant to help both you and the instructor identify gaps in background knowledge both at the class and individual level."
  },
  {
    "objectID": "hw/hw00.html#exercise-1",
    "href": "hw/hw00.html#exercise-1",
    "title": "Homework 0",
    "section": "Exercise 1",
    "text": "Exercise 1\nSimplify\n\\[\n\\log(e^{a_1} e^{a_2} e^{a_3} \\cdots e^{a_n})\n\\]"
  },
  {
    "objectID": "hw/hw00.html#exercise-2",
    "href": "hw/hw00.html#exercise-2",
    "title": "Homework 0",
    "section": "Exercise 2",
    "text": "Exercise 2\nFind the derivative.\n\\[\n\\frac{d}{dx} \\left( \\frac{x}{\\log x} \\right)\n\\]"
  },
  {
    "objectID": "hw/hw00.html#exercise-3",
    "href": "hw/hw00.html#exercise-3",
    "title": "Homework 0",
    "section": "Exercise 3",
    "text": "Exercise 3\nWhat is the ordinary least squares estimator of \\(\\beta\\) (1-dimensional) in the linear regression \\(y = x \\beta + \\epsilon\\) with iid errors?"
  },
  {
    "objectID": "hw/hw00.html#exercise-4",
    "href": "hw/hw00.html#exercise-4",
    "title": "Homework 0",
    "section": "Exercise 4",
    "text": "Exercise 4\nWhat is the ordinary least squares estimator of \\(\\beta\\) (p-dimensional) in the linear regression \\(y = X \\beta + \\epsilon\\) with iid errors?"
  },
  {
    "objectID": "hw/hw00.html#exercise-5",
    "href": "hw/hw00.html#exercise-5",
    "title": "Homework 0",
    "section": "Exercise 5",
    "text": "Exercise 5\nIn linear regression with p-dimensional β, what is the interpretation of the estimate for the jth coefficient?"
  },
  {
    "objectID": "hw/hw00.html#exercise-6",
    "href": "hw/hw00.html#exercise-6",
    "title": "Homework 0",
    "section": "Exercise 6",
    "text": "Exercise 6\nCompute the integral,\n\\[\n\\int_{-\\infty}^{\\infty} e^{-x^2} dx\n\\]"
  },
  {
    "objectID": "hw/hw00.html#exercise-7",
    "href": "hw/hw00.html#exercise-7",
    "title": "Homework 0",
    "section": "Exercise 7",
    "text": "Exercise 7\n\\(X \\sim N(\\mu, \\sigma^2)\\) reads “X is normally distributed with mean \\(\\mu\\) and variance \\(\\sigma^2\\).\nLet\n\\[\n\\begin{aligned}\nX &\\sim N(0, 1),\\\\\nY &\\sim N(3, 2),\\\\\nZ &= X + Y\n\\end{aligned}\n\\]\nWhat is the distribution of \\(Z\\)? What is \\(\\mathbb{E}[Z]\\) and \\(Var(Z)\\)?"
  },
  {
    "objectID": "hw/hw00.html#exercise-8",
    "href": "hw/hw00.html#exercise-8",
    "title": "Homework 0",
    "section": "Exercise 8",
    "text": "Exercise 8\nIn your own words, the “support” of random variable is…"
  },
  {
    "objectID": "hw/hw00.html#exercise-9",
    "href": "hw/hw00.html#exercise-9",
    "title": "Homework 0",
    "section": "Exercise 9",
    "text": "Exercise 9\nTRUE/FALSE: The product of two uniform[0, 1] random variables is uniform[0, 1]."
  },
  {
    "objectID": "hw/hw01.html",
    "href": "hw/hw01.html",
    "title": "Homework 1",
    "section": "",
    "text": "Let \\(X_i \\in \\mathcal{X}\\) for all \\(i \\in \\{1, 2, \\ldots\\}\\) and suppose our belief model for \\(\\mathbf{X} = \\{ X_1, \\ldots X_n \\}\\) is exchangeable for all \\(n\\). Show, using de Finetti’s theorem, that for all \\(i \\neq j\\),\n\\[\nCov(X_i, X_j) \\geq 0 \\text{ and }\n\\]\n\\[\nCorr(X_i, X_j) \\geq 0.\n\\]"
  },
  {
    "objectID": "hw/hw01.html#exercise-2",
    "href": "hw/hw01.html#exercise-2",
    "title": "Homework 1",
    "section": "Exercise 2",
    "text": "Exercise 2\n\n2.2 from Hoff"
  },
  {
    "objectID": "hw/hw01.html#exercise-3",
    "href": "hw/hw01.html#exercise-3",
    "title": "Homework 1",
    "section": "Exercise 3",
    "text": "Exercise 3\n\n2.3 from Hoff"
  },
  {
    "objectID": "hw/hw01.html#exercise-4",
    "href": "hw/hw01.html#exercise-4",
    "title": "Homework 1",
    "section": "Exercise 4",
    "text": "Exercise 4\n\n2.6 from Hoff"
  },
  {
    "objectID": "solutions/hw01s.html",
    "href": "solutions/hw01s.html",
    "title": "Homework 1 solutions",
    "section": "",
    "text": "By definition of covariance,\n\\[\nCov(X_i, X_j) = \\mathbb{E}~X_i X_j - \\mathbb{E}~X_i ~\\mathbb{E}~X_j\n\\]\nBy the law of total expectation,\n\\[\n= \\mathbb{E}~[\\mathbb{E}~X_i X_j| \\theta] -\n\\mathbb{E}~[\\mathbb{E}~X_i | \\theta]\n\\mathbb{E}~[\\mathbb{E}~X_j | \\theta]\n\\]\nBy de Finetti’s theorem, exchangeability of \\(X_i\\) and \\(X_j\\) implies the two variables are conditionally iid relative to \\(\\theta\\). Therefore,\n\\[\n\\begin{aligned}\n\\mathbb{E}~[\\mathbb{E} ~ X_i X_j| \\theta] &= \\mathbb{E}~\n\\left[\n\\int \\int x_i~x_j~p(x_i, x_j |\\theta) dx_i~dx_j\n\\right]\\\\\n&=\\mathbb{E}~\n\\left[\n\\int x_i~p(x_i |\\theta) dx_i \\cdot \\int x_j~p(x_j |\\theta) dx_j\n\\right]\\\\\n&=\n\\mathbb{E}\n\\left[\n\\mathbb{E}~ X_i | \\theta \\cdot\n\\mathbb{E}~ X_j | \\theta\n\\right]\n\\end{aligned}\n\\]\nSimilarly,\n\\[\n\\mathbb{E}~\nX_i | \\theta\n=\n\\mathbb{E}\nX_j | \\theta\n\\]\nso that in total,\n\\[\nCov(X_i, X_j) =\n\\mathbb{E}~\n\\left[\n\\left(\n\\mathbb{E}~X_i | \\theta\n\\right)^2\n\\right]\n-\n\\left(\n\\mathbb{E}~\n\\left[\n\\mathbb{E}~\nX_i | \\theta\n\\right]\n\\right)^2\n\\]\nNote that \\(\\mathbb{E}~X_i | \\theta\\) is some function of \\(\\theta\\), say \\(g(\\theta)\\). It is easy to see\n\\[\nCov(X_i, X_j) = Var(g(\\theta)) \\geq 0\n\\]\n\nExplicit detail:\nBy de Finetti’s theorem exchangeability of \\(X_i\\) and \\(X_j\\) implies\n\\[\np(x_i, x_j) = \\int p(x_i | \\theta) p(x_j | \\theta) p(\\theta) d\\theta\n\\]\nRecall \\(p(x_i, x_j) = \\int p(x_i, x_j, \\theta) d\\theta\\) and therefore \\(p(x_i, x_j) = \\int p(x_i, x_j | \\theta) p(\\theta) d\\theta\\). By comparison to the above, notice\n\\[\np(x_i, x_j | \\theta) = p(x_i | \\theta) p(x_j|\\theta).\n\\]\nIn words, \\(x_i\\) and \\(x_j\\) are conditionally independent given \\(\\theta\\)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bayesian methods and modern statistics",
    "section": "",
    "text": "Week\nDate\nTopic\nReading\nNotes\nAssignment\n\n\n\n\n1\nMon Aug 28\nlab: welcome\n\n💻\nhello R\n\n\n\nTue Aug 29\nintro, history, notation\nCh. 2\n\nhw 0\n\n\n\nThu Aug 31\nprobability, exchangeability\nCh. 2\n💻\nhw 1\n\n\n2\nMon Sep 04\nNO LAB\n\n\n\n\n\n\nTue Sep 05\nsingle parameter estimation\nCh. 3\n💻\n\n\n\n\nThu Sep 07\nPoisson model and conjugacy\nCh. 3\n\nhw 2\n\n\n3\nMon Sep 11\nlab: MLE and MAP estimator\n\n💻\n\n\n\n\nTue Sep 12\nreliability, exp. families\nCh. 3\n💻, 📝\n\n\n\n\nThu Sep 14\nprediction, Monte Carlo intro\nCh. 4\n💻, 📝\nhw 3\n\n\n4\nMon Sep 18\nlab: prior sensitivity and change of variables\n\n💻\n\n\n\n\nTue Sep 19\nMonte Carlo integration\nCh. 4\n💻\n\n\n\n\nThu Sep 21\nthe normal model\nCh. 5\n💻\n\n\n\n5\nMon Sep 25\npractice and review\n\n💻\n\n\n\n\nTue Sep 26\ncatch up / review\n\n\n\n\n\n\nThu Sep 28\nExam I\n\n\n\n\n\n6\nMon Oct 02\nNO LAB\n\n\n\n\n\n\nTue Oct 03\nthe normal model II\nCh. 5\n\nhw 4\n\n\n\nThu Oct 05\nestimators\nCh. 5\n💻, 📝\n\n\n\n7\nMon Oct 09\nlab: predictive checks and bias\n\n💻\n\n\n\n\nTue Oct 10\nGibbs sampling\nCh. 6\n💻\nec\n\n\n\nThu Oct 12\nMCMC diagnostics\nCh. 6\n💻\nhw 5\n\n\n8\nMon Oct 16\nNO LAB\n\n\n\n\n\n\nTue Oct 17\nNO CLASS\n\n\n\n\n\n\nThu Oct 19\nmultivariate normal (mvn)\nCh. 7\n💻\n\n\n\n9\nMon Oct 23\nfull conditional review\n\n\n\n\n\n\nTue Oct 24\nmvn parameter estimation\nCh. 7\n💻, 📝\nhw 6\n\n\n\nThu Oct 26\nhierarchical modeling intro\nCh. 8\n💻\n\n\n\n10\nMon Oct 30\n\n\n\n\n\n\n\nTue Oct 31\nhierarchical examples\nCh. 8\n\nhw 7\n\n\n\nThu Nov 02\nBayesian regression I\nCh. 9\n\n\n\n\n11\nMon Nov 06\n\n\n\n\n\n\n\nTue Nov 07\nBayesian regression II\nCh. 9\n\nhw 8\n\n\n\nThu Nov 09\n\n\n\n\n\n\n12\nMon Nov 13\n\n\n\n\n\n\n\nTue Nov 14\nreview\n\n\n\n\n\n\nThu Nov 16\nExam II\n\n\n\n\n\n13\nMon Nov 20\nNO LAB\n\n\n\n\n\n\nTue Nov 21\n\n\n\n\n\n\n\nThu Nov 23\nNO CLASS\n\n\n\n\n\n14\nMon Nov 27\n\n\n\n\n\n\n\nTue Nov 28\n\n\n\nhw 9\n\n\n\nThu Nov 30\n\n\n\n\n\n\n15\nMon Dec 04\n\n\n\n\n\n\n\nTue Dec 05\n\n\n\n\n\n\n\nThu Dec 07"
  },
  {
    "objectID": "slides/lab1.html#example-normal-likelihood",
    "href": "slides/lab1.html#example-normal-likelihood",
    "title": "MLEs and MAPs",
    "section": "Example: normal likelihood",
    "text": "Example: normal likelihood\nLet \\(X\\) be the resting heart rate (RHR) in beats per minute of a student in this class.\nAssume RHR is normally distributed with some mean \\(\\mu\\) and standard deviation \\(8\\).\n\n\\[\n\\textbf{Data-generative model: } X_i \\overset{\\mathrm{iid}}{\\sim} N(\\mu, 64)\n\\]\n\n\nIf we observe three student heart rates, {75, 58, 68} then our likelihood\n\\[L(\\mu) = f_x(75 |\\mu) \\cdot f_x(58|\\mu) \\cdot f_x(68|\\mu).\\]\nThat is, the joint density function of the observed data, viewed as a function of the parameter.\n\n\n\n\n\n\n\n\nImportant\n\n\nThe likelihood itself is not a density function. The integral with respect to the parameter does not need to equal 1."
  },
  {
    "objectID": "slides/lab1.html#visualizing-the-likelihood",
    "href": "slides/lab1.html#visualizing-the-likelihood",
    "title": "MLEs and MAPs",
    "section": "Visualizing the likelihood",
    "text": "Visualizing the likelihood\n\\[L(\\mu) = f_x(75 |\\mu) \\cdot f_x(58|\\mu) \\cdot f_x(68|\\mu).\\]\n\ndatalikelihood functionplotplot code\n\n\n\nx = c(75, 58, 68)\n\n\n\n\nL = function(mu, x) {\n  stopifnot(is.numeric(x))\n  n = length(x)\n  likelihood = 1\n  for(i in 1:n){\n    likelihood = likelihood * dnorm(x[i], mean = mu, sd = 8)\n  }\n  return(likelihood)\n}\n\n\n\n\n\n\n\n\n\n\n\nggplot() +\n  xlim(c(50, 83)) +\n  geom_function(fun = L, args = list(x = x)) +\n  theme_bw() +\n  labs(x = expression(mu), y = \"likelihood\") + \n  geom_vline(xintercept = 67, color = 'red')\n\n\n\n\n\nThe maximum likelihood estimate \\(\\hat{\\mu} = \\frac{75 + 58 + 68}{3} = 67\\).\nThe maximum likelihood estimate is the parameter value that maximizes the likelihood function."
  },
  {
    "objectID": "slides/lab1.html#the-log-likelihood",
    "href": "slides/lab1.html#the-log-likelihood",
    "title": "MLEs and MAPs",
    "section": "The log-likelihood",
    "text": "The log-likelihood\nNotice how small the y-axis is on the previous slide. What happens to the scale of the likelihood as we add additional data points?\n\\[\nL(\\mu) = \\prod_{i = 1}^{n} f_x(x_i |\\mu)\n\\]\n\nSince densities often evaluate between 0 and 1, multiplying many together (as we usually do in likelihoods) can quickly result in floating point underflow. That is, numbers smaller than the computer can actually represent in memory.\n\nNote: sometimes densities evaluate to greater than 1 (e.g. dnorm(0, 0, 0.001)) and multiplying several together can result in overflow.\n\n\n\nlog to the rescue!\n\nlog is a monotonic function, i.e. \\(x > y\\) implies \\(\\log(x) > \\log(y)\\), because of this the maximum of \\(f\\) is the same as the maximum of \\(\\log f\\).\nadditionally, log turns products into sums\n\nin practice, we always work with the log-likelihood,\n\\[\n\\log L(\\mu) = \\sum_{i = 1}^n \\log f_x(x_i | \\mu).\n\\]"
  },
  {
    "objectID": "slides/lab1.html#maximum-likelihood-estimation-mle",
    "href": "slides/lab1.html#maximum-likelihood-estimation-mle",
    "title": "MLEs and MAPs",
    "section": "Maximum likelihood estimation (MLE)",
    "text": "Maximum likelihood estimation (MLE)\nHow did we know to take the average of the values to find the maximum likelihood estimator \\(\\hat{\\mu}\\)?\n\nFrom calculus, we know that to maximize a function, we need to find where the slope equals zero (technically, to ensure we find some maxima and not a minima we need to also check that the second derivative is negative).\nExample: normal likelihood\nFor the normal likelihood example on the previous slide, we can see visually that the function is concave.\nTo find the maximum,\n\\[\n\\begin{aligned}\n\\frac{d}{d\\mu} \\log L(\\mu) &= \\sum_{i}\\frac{d}{d\\mu} \\log f_x(x_i |\\mu)\\\\\n&= \\sum_{i}\\frac{d}{d\\mu} \\left[ -\\frac{1}{2} \\log (2 \\pi \\sigma^2) - \\frac{1}{2\\sigma^2} (x_i - \\mu)^2 \\right]\\\\\n&= \\sum_i \\frac{1}{\\sigma^2} (x_i - \\mu)\n\\end{aligned}\n\\]\nSetting the derivative equal to zero,\n\\[\n\\begin{aligned}\n\\sum_i \\left[ x_i - \\hat{\\mu} \\right] &= 0\\\\\nn \\hat{\\mu} &= \\sum_i x_i\\\\\n\\hat{\\mu} &= \\bar{x}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/lab1.html#maximum-a-posteriori-probability-map",
    "href": "slides/lab1.html#maximum-a-posteriori-probability-map",
    "title": "MLEs and MAPs",
    "section": "Maximum a posteriori probability (MAP)",
    "text": "Maximum a posteriori probability (MAP)\nIn Bayesian inference, we wish to find the mode of the posterior, not the likelihood.\nTo find the posterior mode, \\(\\hat{\\theta}\\), we instead take the derivative of the log-posterior,\n\\[\n\\frac{d}{d\\theta} \\log p(\\theta | y) = 0\n\\]\nPractice exercise\nAs in class, let\n\\[\nY | \\theta \\sim \\text{binomial}(n, \\theta)\\\\\n\\theta \\sim \\text{beta}(a, b)\n\\]\n\nFind the closed-form solution for the posterior mode \\(\\hat{\\theta}\\).\nRecreate Figure 1 from class using the same data flips provided below but change the prior to \\(\\theta \\sim \\text{beta}(2, 2)\\).\n\n\nset.seed(3)\nflips = rbinom(5000, size = 1, prob = 0.25)\n\n\nAdd a red vertical line to each subplot that shows the MAP estimate under the prior \\(\\theta \\sim \\text{beta}(2, 2)\\).\n\n\n\n🔗 sta360-fa23.github.io"
  },
  {
    "objectID": "slides/lab0-welcome.html#introductions",
    "href": "slides/lab0-welcome.html#introductions",
    "title": "Welcome to Lab",
    "section": "Introductions",
    "text": "Introductions\n\n\n\n\nMeet the TA!\nIntroduce yourself (icebreaker)\nFollow along these slides on the course website (under slides): sta360-fa23.github.io\nBookmark this! It’s the course website."
  },
  {
    "objectID": "slides/lab0-welcome.html#what-to-expect-in-labs",
    "href": "slides/lab0-welcome.html#what-to-expect-in-labs",
    "title": "Welcome to Lab",
    "section": "What to expect in labs",
    "text": "What to expect in labs\n\nDiscussion\nPractice problems\nAssistance on computing portion of homeworks"
  },
  {
    "objectID": "slides/lab0-welcome.html#tips",
    "href": "slides/lab0-welcome.html#tips",
    "title": "Welcome to Lab",
    "section": "Tips",
    "text": "Tips\n\nShow up.\nMake use of office hours. Before you need help!"
  },
  {
    "objectID": "slides/lab0-welcome.html#beginnings",
    "href": "slides/lab0-welcome.html#beginnings",
    "title": "Welcome to Lab",
    "section": "Beginnings",
    "text": "Beginnings\nWhile this is not a computing class, computers are the workhorse of Bayesian statistics and we will use R to both enhance understanding of fundamental course material as well as to implement models to learn about real data sets."
  },
  {
    "objectID": "slides/lab0-welcome.html#set-up-rstudio",
    "href": "slides/lab0-welcome.html#set-up-rstudio",
    "title": "Welcome to Lab",
    "section": "Set up RStudio",
    "text": "Set up RStudio\nOption 1 (easiest): RStudio container\n\nGo to https://cmgr.oit.duke.edu/containers and login with your Duke NetID and Password.\nClick RStudio to log into the Docker container. You should now see the RStudio environment.\n\nIf you haven’t previously done so, you will need to reserve a container for RStudio first."
  },
  {
    "objectID": "slides/lab0-welcome.html#set-up-rstudio-1",
    "href": "slides/lab0-welcome.html#set-up-rstudio-1",
    "title": "Welcome to Lab",
    "section": "Set up RStudio",
    "text": "Set up RStudio\nOption 2: RStudio on your computer\n\nDownload R from http://www.r-project.org/.\nDownload RStudio, the popular IDE for R, from https://posit.co/downloads/.\n(optionally) download Quarto from https://quarto.org/docs/get-started/"
  },
  {
    "objectID": "slides/lab0-welcome.html#demo",
    "href": "slides/lab0-welcome.html#demo",
    "title": "Welcome to Lab",
    "section": "Demo",
    "text": "Demo\nNext, check your familarity with R/RStudio fundamentals here. You can also find a link to this from the course schedule under “Assignment”.\n\n\n🔗 sta360-fa23.github.io"
  },
  {
    "objectID": "links.html",
    "href": "links.html",
    "title": "Links",
    "section": "",
    "text": "RStudio containers\n\nResources\n\nSakai website\n\nlectures and solutions uploaded here under “Resources” tab on the left hand side\n\nGradescope\n\nTextbook\n\nA First Course in Bayesian Statistical Methods by Peter Hoff\nErrata to the textbook"
  },
  {
    "objectID": "notes/estimation1.html",
    "href": "notes/estimation1.html",
    "title": "Is this a fair coin?",
    "section": "",
    "text": "outputcode\n\n\n\n\n [1] 0 1 0 0 0 0 0 0 0 0\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(latex2exp)\nlibrary(glue)\nlibrary(patchwork)\n\nset.seed(3)\nflips = rbinom(5000, size = 1, prob = 0.25)\nflips %>% head(10)\nWe observe 10 flips from the same coin above, where 0 is “tails” and 1 is “heads”. In summary, we see Y = 1 heads in 10 coin flips. Is this a fair coin?\nTo articulate this mathematically, let \\(\\theta \\in [0, 1]\\) be the bias-weighting (the chance of heads) of the coin. Fundamentally, we want \\(p(\\theta | y)\\), which we can expand via Bayes’ rule,\n\\[\np(\\theta | y) = \\frac{p(y|\\theta) p(\\theta)}{\\int_{\\theta \\in \\Theta} p(y|\\theta) p(\\theta) d\\theta}\n\\]\nLikelihood: the data generative process. The joint probability (or density) of the data given the parameters of the model. Most often thought of as a function of the parameter. Note: not a density of the parameter.\nPrior: Our a priori (beforehand) beliefs about the true population characteristics.\nPosterior: Our a posteriori (afterwards) beliefs about the true population characteristics after having observed the data set \\(y\\).\nNormalizing constant: A number that enables a pmf or pdf to integrate to 1."
  },
  {
    "objectID": "notes/estimation1.html#uniform-prior",
    "href": "notes/estimation1.html#uniform-prior",
    "title": "Is this a fair coin?",
    "section": "Uniform prior",
    "text": "Uniform prior\nLet \\(y\\) be the number of heads in \\(n\\) coin flips.\n\\[\np(\\theta | y) \\propto \\theta^{y}(1-\\theta)^{n-y}\n\\]\nThis is the kernel of a ___ density, where \\(\\alpha = y + 1\\) and \\(\\beta = n - y + 1\\), hence\n\\[\np(\\theta | y) = \\frac{\\Gamma(n + 2)}{\\Gamma(y + 1)\\Gamma(n-y+1)} \\theta^{y}(1-\\theta)^{n-y}\n\\]\nand the posterior mean is \\(\\frac{y + 1}{n + 2}\\) and the posterior variance is \\(\\frac{(y+1)(n - y + 1)}{(n + 2)^2 (n + 1)}\\).\nLet’s examine how the posterior evolves with each successive coin flip.\n\nplotscode\n\n\n\n\n\n\n\n\n\n\nN = c(0, 1, 2, 3, 4, 10, 100, 1000, 5000)\n\nfor (i in seq_along(N)) {\nn = N[i]\nif(n == 0) {\n  y = 0\n}\nelse {\n  y = sum(flips[1:n])\n}\n\nx = 0:1 # range\ndf = data.frame(x)\nassign(paste0(\"p\", i),\n  df %>%\n  ggplot(aes(x = x)) +\n  stat_function(fun=dbeta, \n                args = list(shape1 = y + 1, shape2 = n - y + 1)) +\n  labs(y = TeX(\"$p(\\\\theta | y)$\"), x = TeX(\"$\\\\theta$\"),\n       title = glue(\"n = {n}\")) +\n  theme_bw()\n)\n}\n\n(p1 + p2 + p3) / \n  (p4 + p5 + p6) / \n  (p7 + p8 + p9) +\n  plot_annotation(title = \"Figure 1\")"
  },
  {
    "objectID": "notes/estimation1.html#conjugacy",
    "href": "notes/estimation1.html#conjugacy",
    "title": "Is this a fair coin?",
    "section": "Conjugacy",
    "text": "Conjugacy\nIf \\(\\theta \\sim\\) Uniform(0, 1) then \\(p(\\theta)\\) = 1 for all \\(\\theta \\in [0, 1]\\).\nSimilarly, if \\(\\theta \\sim\\) beta(1, 1), then \\(p(\\theta) = 1\\).\nClaim:\nIf\n\\[\n\\begin{aligned}\n\\theta &\\sim \\text{beta}(a, b)\\\\\nY | \\theta &\\sim \\text{binomial}(n, \\theta)\n\\end{aligned}\n\\]\nthen\n\\[\np(\\theta | Y) = \\text{beta}(y + a, n - y + b)\n\\]\n\n\n\n\n\n\nDefinition\n\n\n\nA prior \\(p(\\theta)\\) is said to be conjugate to the data generative model \\(p(y|\\theta)\\) if the family of the posterior is necessarily in the same family as the prior. In math, \\(p(\\theta)\\) is conjugate to \\(p(y|\\theta)\\) if\n\\[\np(\\theta) \\in \\mathcal{P} \\implies p(\\theta | y) \\in \\mathcal{P}\n\\]\n\n\nWhile conjugate priors make calculation easy, they may not accurately reflect our prior beliefs.\n\n\n\n\n\n\nExercise\n\n\n\nProve the claim above."
  },
  {
    "objectID": "notes/estimation1.html#other-priors",
    "href": "notes/estimation1.html#other-priors",
    "title": "Is this a fair coin?",
    "section": "Other priors",
    "text": "Other priors\nIncidentally, people are often satisfied with the choice of likelihood but are worried about the choice of prior.\nLet’s examine the effect of another couple of priors.\nGiven the coin’s dubious origin, we might believe a priori that the coin is biased. How could we represent this belief?\n\\[\n\\theta \\sim \\text{beta}(.5, .5)\n\\]\nOr alternatively, we might be strongly believe a priori that the coin is fair. How could we represent this belief?\n\\[\n\\theta \\sim \\text{beta}(20, 20)\n\\]\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nHow would you update the code of the previous example to show posterior inference under the prior \\(\\theta \\sim\\) beta(2,3)?"
  },
  {
    "objectID": "notes/estimation1.html#prior-data",
    "href": "notes/estimation1.html#prior-data",
    "title": "Is this a fair coin?",
    "section": "Prior data",
    "text": "Prior data\nIn the example above, the parameters, a and b, of the conjugate prior are often thought of as prior data.\n\na: “prior number of 1s”\nb: “prior number of 0s”\na + b: “prior sample size”\n\n\n\n\n\n\n\nExercise\n\n\n\nWe saw above that when a = 20 and b = 20, we needed more data to move the posterior.\nShow that the posterior mean, \\(E(\\theta | y) = \\frac{a + y}{a + b + n}\\) converges to the sample average as \\(n \\rightarrow \\infty\\)."
  },
  {
    "objectID": "notes/probability.html",
    "href": "notes/probability.html",
    "title": "Probability",
    "section": "",
    "text": "This is foundational material. Most of it is background you will have learned in STA230/240. While dry, we must soldier on to get to the exciting stuff."
  },
  {
    "objectID": "notes/probability.html#review-set-theory",
    "href": "notes/probability.html#review-set-theory",
    "title": "Probability",
    "section": "Review: set theory",
    "text": "Review: set theory\n\n\n\n\n\n\nDefinition\n\n\n\nset: a collection of elements, denoted by {}\nExamples\n\n\\(\\phi\\) = {} “the empty set”\nA = {1, 2, 3}\nB = {taken STA199, has not taken STA199}\nC = {{1,2,3}, {4, 5}}\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nsubset: denoted by \\(\\subset\\), \\(A \\subset B\\) iff \\(a \\in A \\implies a \\in B\\)\nExamples\nUsing the previously examples of A, B and C above,\n\n\\(A \\subset C\\)\n\\(A \\not\\subset B\\)\n\n\n\nRecall:\n\n\\(\\cup\\) means “union”, “or”\n\\(\\cap\\) means “intersection”, “and”\n\n\n\n\n\n\n\nDefinition\n\n\n\npartition: {\\(H_1, H_2, ... H_n\\)} = \\(\\{H_i\\}_{i = 1}^n\\) is a partition of \\(\\mathcal{H}\\) if\n\nthe union of sets is \\(\\mathcal{H}\\) i.e. \\(\\cup_{i = 1}^n H_i = \\mathcal{H}\\)\nthe sets are disjoint i.e. \\(H_i \\cap H_j = \\phi\\) for all \\(i \\neq j\\)\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nsample space: \\(\\mathcal{H}\\), the set of all possible data sets (outcomes)\nevent: a set of one or more outcomes\nNote: p(\\(\\mathcal{H}\\)) = 1\nExamples\n\nRoll a six-sided die once. The sample space \\(\\mathcal{H} = \\{1, 2, 3, 4, 5, 6\\}\\).\nLet \\(A\\) be the event that the die lands on an even number. \\(A = \\{2, 4, 6 \\}\\)"
  },
  {
    "objectID": "notes/probability.html#axioms-of-probability-in-words",
    "href": "notes/probability.html#axioms-of-probability-in-words",
    "title": "Probability",
    "section": "Axioms of probability (in words)",
    "text": "Axioms of probability (in words)\nP1. Probabilities are between 0 and 1, importantly p(\\(\\neg\\)H|H) = 0 and p(H|H) = 1.\nP2. If two events A and B are disjoint, then p(A or B) = p(A) + p(B)\nP3. The joint probability of two events may be broken down stepwise: p(A,B) = p(A|B)p(B)\n–\nIt follows that\n\nfor any partition \\(\\{H_i\\}_{i = 1}^n\\), \\(\\sum_{i=1}^n p(H_i) = 1\\) (rule of total probability)\n\nnote: simplest partition \\(p(A) + p(\\neg A) = 1\\)\n\n\\(p(A) = \\sum_{i=1}^n p(A, H_i)\\) (rule of marginal probability)\n\nnote: P3 implies that equivalently, \\(p(A) = \\sum_{i=1}^n p(A | H_i) p(H_i)\\)\n\np(A|B) = p(A,B) / p(B) when p(B) \\(\\neq 0\\)\n\nnote: these statements can also be made where each term is additionally conditioned on another event C\n\n\n\n\n\n\n\n\nExercise\n\n\n\nDerive Bayes’ rule:\n\\(p(H_i|X) = \\frac{p(X|H_i)p(H_i)}{\\sum_k p(X|H_k)p(H_k)}\\)\nusing the axioms of probability.\n\n\nBayes’ rule tells us how to update beliefs about \\(\\{H_i \\}_{i = 1}^n\\) given data \\(X\\)."
  },
  {
    "objectID": "notes/probability.html#independence",
    "href": "notes/probability.html#independence",
    "title": "Probability",
    "section": "Independence",
    "text": "Independence\n\n\n\n\n\n\nDefinition\n\n\n\nTwo events \\(F\\) and \\(G\\) are conditionally independent given \\(H\\) if \\(p(F, G | H) = p(F | H) p(G | H)\\)\n\n\n\n\n\n\n\n\nExercise\n\n\n\nShow conditional independence implies\n\\(p(F | H, G) = p(F | H)\\)\n\n\nThis means that if we know H, then G does not supply any additional information about F."
  },
  {
    "objectID": "notes/probability.html#random-variables",
    "href": "notes/probability.html#random-variables",
    "title": "Probability",
    "section": "Random variables",
    "text": "Random variables\n\n\n\n\n\n\nDefinition\n\n\n\nIn Bayesian inference, a random variable is an unknown numerical quantity about which we make probability statements.\nExamples\n\nData. E.g. the amount of a wheat a field will yield later this year. Since this data has not yet been generated, the quantity is unknown.\nA population parameter. E.g. the true mean resting heart rate of Duke students. Note: this is a fixed (non-random) quantity, but it is also unknown. We use probability to describe our uncertainty in this quantity.\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\ndiscrete random variable: a random variable that takes countably many values. Y is discrete if its possible outcomes can be enumerated \\(\\mathcal{Y} = \\{y_1, y_2, \\ldots \\}\\).\nNote: discrete does not mean finite. There may be infinitely many outcomes!\nExamples\n\nY = the number of children of a randomly sampled person\nY = the number of visible stars in the sky on a randomly sampled night of the year\n\nFor each \\(y \\in \\mathcal{Y}\\), let p(Y) = probability(Y = y). Then p is the probability mass function (pmf) of the random variable Y.\nExamples\n\nBinomial pmf: the probability of \\(y\\) successes in \\(n\\) trials, where each trial has an individual probability of success \\(\\theta\\).\n\\[p(y | \\theta) = {n \\choose y} \\theta ^y (1-\\theta)^y \\text{ for } y \\in \\{0, 1, \\ldots n \\}\\]\n\nsupport: \\(y \\in \\{0, 1, 2, \\ldots n\\}\\)\nsuccess probability \\(\\theta \\in [0, 1]\\)\ndbinom(y, n, theta) computes this pmf in R\n\nPoisson pmf: probability of \\(y\\) events occurring during a fixed interval at a mean rate \\(\\theta\\)\n\\[p(y | \\theta) = \\frac{\\theta^y e^{-\\theta}}{y!}\\]\n\nsupport: \\(y \\in \\{0, 1, 2, \\ldots \\}\\)\nrate \\(\\theta \\in \\mathbb{R}^+\\)\ndpois(y, theta) computes this pmf in R\n\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\ncontinuous random variable: a random variable that takes uncountably many values.\nThe probability density function (pdf) of a continuous random variable, X is defined\n\\(pdf(x) = \\lim_{\\Delta x \\rightarrow 0} \\frac{p(x < X < x + \\Delta x)}{\\Delta x}\\)\nand the probability X is in some interval,\n\\(p(x_1 < X < x_2) = \\int_{x_1}^{x_2} pdf(x) dx\\)\nExamples\n\nNormal pdf \\[\np(x | \\mu, \\sigma) = (2\\pi \\sigma^2)^{-\\frac{1}{2}}e^{-\\frac{1}{2\\sigma^2}(x-\\mu)^2}\n\\]\nUniform pdf \\[p(x|a,b) =\n\\begin{cases}\n\\frac{1}{b - a} \\hspace{.6cm}\\text{ for } x \\in [a, b]\\\\\n0 \\hspace{1cm}\\text{ otherwise }\n\\end{cases}\\]\n\n\n\nNote: we will often abuse notation and use \\(p(x)\\) in place of \\(pmf(x)\\) and \\(pdf(x)\\) and prob(event), where only the context makes meaning clear.\nFor pmfs\n\\[\n\\begin{aligned}\n0 \\leq p(y) \\leq 1\\\\\n\\sum_{y \\in \\mathcal{Y}} p(y) = 1\n\\end{aligned}\n\\]\nSimilarly, for pdfs,\n\\[\n\\begin{aligned}\n0 \\leq p(y) \\ \\text{and} \\\\\n\\int_{y \\in \\mathcal{Y}} p(y) = 1\n\\end{aligned}\n\\]\nNote: For a continuous random variable Y, p(y) can be larger than 1 and p(y) is not p(Y = y), which equals 0.\n\n\n\n\n\n\nDefinition\n\n\n\nThe part of the density/mass function that depends on the variable is called the kernel.\nExample\n\nthe kernel of the normal pdf is \\(e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\\)\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nWhat’s the kernel of a gamma random variable X?\nRecall: the pdf of a gamma distribution:\n\\[\np(x | \\alpha, \\beta) = \\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)}x^{\\alpha - 1} e^{-\\beta x}\n\\]"
  },
  {
    "objectID": "notes/probability.html#moments",
    "href": "notes/probability.html#moments",
    "title": "Probability",
    "section": "Moments",
    "text": "Moments\nFor a random variable X, the \\(n\\)th moment is defined as E(\\(X^n\\)).\nRecall, the expected value is defined for discrete random variable X,\n\\[\nE(X) = \\sum_{x \\in \\mathcal{X}} x p(x)\n\\]\nand for continuous random variable Y,\n\\[\nE(Y) = \\int_{-\\infty}^{\\infty} y p(y) dy\n\\]\nThe variance of a random variable, is also known as the second central moment and is defined\n\\[\nE(X - E(X))^2\n\\] or equivalently,\n\\[\nE(X^2) - E(X)^2\n\\]\nMore generally, the covariance between two random variables X and Y is defined\n\\[\nE[(X - E[X])(Y - E[Y])]\n\\]"
  },
  {
    "objectID": "notes/probability.html#exchangeability",
    "href": "notes/probability.html#exchangeability",
    "title": "Probability",
    "section": "Exchangeability",
    "text": "Exchangeability\n\noffline notes"
  },
  {
    "objectID": "notes/reliability.html",
    "href": "notes/reliability.html",
    "title": "Posterior summaries and reliability",
    "section": "",
    "text": "Posterior mode: sometimes called “MAP” or “maximum a posteriori” estimate, this quantity is given by \\(\\hat{\\theta} = \\arg \\max_{\\theta} p(\\theta | y)\\).\n\nNotice this unwinds to be \\(\\hat{\\theta} = \\arg \\max_{\\theta} p(y | \\theta) p(\\theta)\\).\n\n\n\n\n\n\n\nExercise\n\n\n\n\nShow that, for the uniform prior, \\(\\hat{\\theta} = y / n\\)\nCompare to maximum likelihood estimate (MLE); see notes on likelihoods\n\n\n\nOne way to report the reliability of the posterior mode is to look at the width of the posterior near the mode, which we can sometimes approximate with a Gaussian distribution:\n\\[\np(\\theta | y) \\approx C e^{\\frac{1}{2} \\frac{d^2L}{d\\theta^2}|_{\\hat{\\theta}} (\\theta - \\hat{\\theta})^2}\n\\]\nwhere \\(C\\) is a normalization constant and \\(L\\) is the log-posterior, \\(\\log p(\\theta | y)\\).\nTaken together, the fitted Gaussian with a mean equal to the posterior mode is called the Laplace approximation.\n\nLet’s derive the Laplace approximation offline"
  },
  {
    "objectID": "notes/reliability.html#confidence-regions",
    "href": "notes/reliability.html#confidence-regions",
    "title": "Posterior summaries and reliability",
    "section": "Confidence regions",
    "text": "Confidence regions\n\n\n\n\n\n\nDefinition\n\n\n\nLet \\(\\Phi\\) be the support of \\(\\theta\\). An interval \\((l(y), u(y)) \\subset \\Phi\\) has 95% posterior coverage if\n\\[\np(l(y) < \\theta < u(y) | y ) = 0.95\n\\]\nInterpretation: after observing \\(Y = y\\), our probability that \\(\\theta \\in (l(y), u(y))\\) is 95%.\nSuch an interval is called 95% posterior confidence interval (CI). It may also sometimes be referred to as a 95% “credible interval” to distinguish it from a frequentist CI.\n\n\nContrast posterior coverage to frequentist coverage:\n\n\n\n\n\n\nDefinition\n\n\n\nA random interval \\((l(Y), u(Y)\\)) has 95% frequentist coverage for \\(\\theta\\) if before data are observed,\n\\[\np(l(Y) < \\theta < u(Y) | \\theta) = 0.95\n\\]\nInterpretation: if \\(Y \\sim P_\\theta\\) then the probability that \\((l(Y), u(Y)\\) will cover \\(\\theta\\) is 0.95.\n\n\nIn practice, for many applied problems\n\\[\np(l(y) < \\theta < u(y) | y ) \\approx p(l(Y) < \\theta < u(Y) | \\theta)\n\\]\nsee section 3.1.2. in the book."
  },
  {
    "objectID": "notes/reliability.html#high-posterior-density",
    "href": "notes/reliability.html#high-posterior-density",
    "title": "Posterior summaries and reliability",
    "section": "High posterior density",
    "text": "High posterior density\n\n\n\n\n\n\nDefinition\n\n\n\nA \\(100 \\times (1-\\alpha)\\)% high posterior density (HPD) region is a set \\(s(y) \\subset \\Theta\\) such that\n\n\\(p(\\theta \\in s(y) | Y = y) = 1 - \\alpha\\)\nIf \\(\\theta_a \\in s(y)\\) and \\(\\theta_b \\not\\in s(y)\\), then \\(p(\\theta_a | Y = y) > p(\\theta_b | Y = y)\\)\n\n\n\n\nNote: all points inside an HPD region have higher posterior density than points outside the region.\n\n\n\n\n\n\n\nExercise\n\n\n\nIs the HPD region always an interval?"
  },
  {
    "objectID": "notes/prediction1.html",
    "href": "notes/prediction1.html",
    "title": "Prediction & Intro to Monte Carlo",
    "section": "",
    "text": "Load packages:"
  },
  {
    "objectID": "notes/prediction1.html#prediction-example",
    "href": "notes/prediction1.html#prediction-example",
    "title": "Prediction & Intro to Monte Carlo",
    "section": "Prediction example",
    "text": "Prediction example\nGeneral social survey (1998)\nSetup:\n\nSuppose \\(X_i = 1\\) if the ith person is happy. \\(X_i = 0\\) otherwise.\nLet \\(Y = \\sum_{i = 1}^{n} X_i\\), where \\(n\\) is the number of people sampled.\n\\(Y_i | \\theta \\sim \\text{binomial}(\\theta)\\) for some fixed \\(n\\).\n\\(\\theta \\sim \\text{uniform}(0, 1)\\)\n\nScenario: We sample \\(n = 10\\) people. \\(y = 6\\) are happy. If we sample another \\(n = 10\\), what is the probability that \\(\\tilde{y}\\) are happy?\nWe fundamentally want the posterior predictive distribution, \\(p(\\tilde{y} | y)\\).\nFollowing the offline notes, and given conditional independence, we want\n\n\n\n\n\n\\[\n\\begin{aligned}\n\\int p(\\tilde{y} | \\theta) p(\\theta | y) d\\theta\n&=\n\\int {n \\choose \\tilde{y}}\n(\\theta)^\\tilde{y} (1-\\theta)^{n-\\tilde{y}}\n\\cdot\n\\frac{1}{\\text{B(y + 1, n - y + 1)}}\\theta^{y}(1-\\theta)^{n-y}\nd\\theta\\\\\n&= {n \\choose \\tilde{y}} \\frac{1}{\\text{B(y + 1, n - y + 1)}} \\int \\theta^{\\tilde{y}+y} \\cdot\n(1-\\theta)^{(n-\\tilde{y}) + (n - y)} d\\theta\\\\\n&= {n \\choose \\tilde{y}}\n\\frac{\\text{B}(\\tilde{y} + y + 1, 2n - y - \\tilde{y} + 1)}{\\text{B(y + 1, n - y + 1)}}\n\\end{aligned}\n\\]\nwhere \\(B(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}\\). We can of course simplify, since this is really a bunch of factorials, but we can also naively use the beta() function in R and push forward.\n\nplotcode\n\n\n\n\n\n\n\n\n\n\ny = 6\nn = 10\n\n# posterior predictive probability of ytilde\nprobYT = function(ytilde) {\n  choose(n, ytilde) * \n    beta(ytilde + y + 1, (2*n) - y - ytilde + 1) / \n    beta(y + 1, n - y + 1)\n}\n\n# construct data frame\ndf = data.frame(ytilde = 0:10) %>%\n  mutate(postPredict = probYT(ytilde))\n\n# plot data frame\ndf %>%\n  ggplot(aes(x = ytilde, y = postPredict)) +\n  geom_bar(stat = 'identity') +\n  labs(x = TeX(\"$\\\\tilde{y}$\"), y = TeX(\"$p(\\\\tilde{y}|y)$\"),\n       title = \"Posterior predictive probability\") +\n  theme_bw()"
  },
  {
    "objectID": "notes/prediction1.html#monte-carlo-motivation",
    "href": "notes/prediction1.html#monte-carlo-motivation",
    "title": "Prediction & Intro to Monte Carlo",
    "section": "Monte Carlo motivation",
    "text": "Monte Carlo motivation\nGeneral social survey from the 90s gathered data on the number of children to women of two categories: those with and without a bachelor’s degree.\nSetup:\n\n\\(Y_{i1}\\): number of children of \\(i\\)th woman in group 1 (no bachelor’s)\n\\(Y_{i2}\\): number of children of \\(i\\)th woman in group 2 (bachelor’s)\n\nModel:\n\n\\(Y_{11}, \\ldots, Y_{n_1 1} | \\theta_1 \\overset{\\mathrm{iid}}{\\sim} \\text{Poisson}(\\theta_1)\\)\n\\(Y_{12} \\ldots, Y_{n_2 2} | \\theta_2 \\overset{\\mathrm{iid}}{\\sim} \\text{Poisson}(\\theta_2)\\)\n\nPrior:\n\n\\(\\theta_1 \\sim \\text{gamma}(2, 1)\\)\n\\(\\theta_2 \\sim \\text{gamma}(2, 1)\\)\n\nData:\n\n\\(n_1 = 111\\), \\(\\bar{y_1} = 1.95\\), \\(\\sum y_{i 1} = 217\\)\n\\(n_2 = 44\\), \\(\\bar{y_1} = 1.5\\), \\(\\sum y_{i 1} = 66\\)\n\nPosterior:\n\n\\(\\theta_1 | \\vec{y_1} \\sim \\text{gamma}(219, 112)\\)\n\\(\\theta_2 | \\vec{y_2} \\sim \\text{gamma}(68, 45)\\)\n\nWe already know how to compute\n\nposterior mean: \\(E~\\theta | y = \\alpha / \\beta\\) (shape, rate parameterization)\nposterior density (dgamma)\nposterior quantiles and confidence intervals (qgamma)\n\nWhat about…\n\n\\(p(\\theta \\in \\mathcal{A} | y)\\),\n\\(E~g(\\theta) | y\\),\n\\(Var~g(\\theta) | y\\)?\n\nWhat about posterior distribution of \\(|\\theta_1 - \\theta_2\\), \\(\\theta_1 / \\theta_2\\), \\(\\text{max} \\{\\theta_1, \\theta_2 \\}\\)?"
  },
  {
    "objectID": "notes/prediction1.html#monte-carlo-integration",
    "href": "notes/prediction1.html#monte-carlo-integration",
    "title": "Prediction & Intro to Monte Carlo",
    "section": "Monte Carlo integration",
    "text": "Monte Carlo integration\n\napproximates an integral by a stochastic average\nshines when other methods of integration are impossible (e.g. high dimensional integration)\nworks because of law of large numbers: for a random variable \\(X\\), the sample mean \\(\\bar{x}_N\\) converges to the true mean \\(\\mu\\) as the number of samples \\(N\\) tends to infinity.\n\nThe key idea is: we obtain independent samples from the posterior,\n\\[\n\\theta^{(1)}, \\ldots \\theta^{(N)} \\overset{\\mathrm{iid}}{\\sim} p(\\theta |\\vec{y})\n\\]\nthen the empirical distribution of the samples approximates the posterior (approximation improves as \\(N\\) increases).\nRecall\n\\[\nE~g(\\theta)|y = \\int_\\mathcal{\\theta} g(\\theta) f_\\theta(\\theta | y)dx \\approx \\frac{1}{N} \\sum_{i = 1}^N g(\\theta^{(i)})\n\\]\nwhere \\(f_x(x)\\) is the probability density function for a random variable \\(X\\).\nThe law of large numbers says that if our samples \\(\\theta^{(i)}\\) are independent, \\(\\frac{1}{N} \\sum_{i = 1}^N g(\\theta^{(i)})\\) to \\(E~\\theta|y\\).\n\n\n\n\n\n\nNote\n\n\n\nIntegrals are expectations, and expectations are integrals."
  },
  {
    "objectID": "notes/prediction1.html#examples",
    "href": "notes/prediction1.html#examples",
    "title": "Prediction & Intro to Monte Carlo",
    "section": "Examples",
    "text": "Examples\n\n\\(\\theta_1 | \\vec{y_1} \\sim \\text{gamma}(219, 112)\\)\n\\(\\theta_2 | \\vec{y_2} \\sim \\text{gamma}(68, 45)\\)\n\n\n(1) proof of concept: the mean\n\nset.seed(123)\nN = 5000\nrgamma(N, shape = 219, rate = 112) %>%\n  mean()\n\n[1] 1.95294\n\n\nPretty close to the true mean, 1.9553571.\n\n\n(2) posterior of \\(\\theta_1 - \\theta_2\\)\n\nset.seed(123)\ntheta1 = rgamma(N, shape = 219, rate = 112)\ntheta2 = rgamma(N, shape = 68, rate = 45)\n\ndf = data.frame(diff = theta1 - theta2)\n\ndf %>%\n  ggplot(aes(x = diff)) + \n  geom_density() +\n  theme_bw() +\n  labs(x = TeX(\"$\\\\theta_1 - \\\\theta_2$\"),\n       y = TeX(\"$p(\\\\theta_1 - \\\\theta_2 | {y}_1, {y}_2)$\"))\n\n\n\n\n\n\n(3) \\(p(\\theta_1 - \\theta_2> .5)\\)\n\nmean(df$diff > .5)\n\n[1] 0.4106\n\n\n\nExerciseFull solutionQuick Monte Carlo\n\n\n\n\n\n\n\n\nExercise\n\n\n\n\n\\(\\theta \\sim \\text{uniform}(0, 1)\\)\nLet \\(\\gamma = \\log \\theta\\)\nVisualize \\(p(\\gamma)\\) using Monte Carlo simulation, then show using the change of variables formula and plotting the closed form of the density.\n\n\n\n\n\n\n# sample from p(theta)\ntheta = runif(10000)\n\n# define transform function\nf = function(x) {\n  return(exp(x))\n}\n\n# create a df for each plot\ndf = data.frame(gamma = -7:0)\ndf2 = data.frame(gammaSamples = log(theta))\n\n# make plots\ndf %>%\n  ggplot(aes(x = gamma)) +\n  stat_function(fun = f, col = 'red', alpha = 0.5) +\n  geom_histogram(data = df2, aes(x = gammaSamples,\n                                 y = ..density..),\n               fill = 'steelblue', alpha = 0.5)\n\n\n\n\n\n\n\n# Just making the Monte Carlo part of the plot \n# in 3 lines\ntheta = runif(10000)\ngamma = log(theta)\nhist(gamma)"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "STA 360: Bayesian methods and modern statistics",
    "section": "",
    "text": "This course introduces Bayesian modeling and inference, motivated by real world examples. Course topics include Bayes’ theorem, exchangeability, conjugate priors, Markov chain Monte Carlo (MCMC) approximation, Gibbs sampling, hierarchical modeling, Bayesian regression and generalized linear models. We compare and contrast Bayesian methods to the frequentist paradigm. By the end of this course students should feel comfortable (1) writing Bayesian models and, when appropriate, (2) sampling from the posterior using MCMC to make inference.\n\n\n\n\n\n\n\n\n\nContact\nOffice hours\nLocation\n\n\n\n\nDr. Alexander Fisher\naaf29@duke.edu\nTu: 11:30am-1:30pm\nOld Chem 207\n\n\nCarol Wang\nzhuoqun.wang@duke.edu\nMo: 6:00pm-8:00pm\nZoom\n\n\nManny Mokel\nemmanuel.mokel@duke.edu\nTh: 3:00pm-5:00pm\nOld Chem 203B\n\n\nCaitrin Murphy\ncaitrin.murphy@duke.edu\nWe: 4:30pm-6:30pm\nOld Chem 025\n\n\n\n\n\n\n\n\n\nLecture\nTu/Th 10:05 - 11:20am\nOld Chemistry 116\n\n\nLab 01\nM 3:05pm - 4:20pm\nPerkins LINK 087 (Classroom 3)\n\n\nLab 02\nM 4:40pm - 5:55pm\nSocial Sciences 124\n\n\n\nCourse website: sta360-fa23.github.io\n\n\n\n\n\n\n\n\n\n\n\nA First Course in Bayesian Statistical Methods. As a Duke student, an electronic version of the book is freely available to you on Springer link. Check the errata at the link above.\nChapter summaries. I compile major take-away points from each section. Review these to help prepare for exams.\nWe will use the statistical software package R on homework asignments in this course. R is freely available at http://www.r-project.org/. RStudio, the popular IDE for R, is freely available at https://posit.co/downloads/.\n\n\n\n\nPart I: The Bayesian modeling toolkit\n\nReview of probability\nConjugate statistical models\nSemi-conjugate models and Gibbs sampling\n\nPart II: Statistical model building and analysis\n\nMultilevel models\nLinear regression\nGeneralized linear models\nDensity estimation and classification\n\n\n\n\n\n\n\n\n\n\n\nAssignment\nDescription\n\n\n\n\nHomework (40%)\nIndividual take-home assignments, submitted to Gradescope.\n\n\nMidterms (30%)\nTwo in-class exams.\n\n\nFinal exam (25%)\nCumulative final during final’s week.\n\n\nQuizzes (5%)\nIn-class pop quizzes.\n\n\n\nA \\(>= 93\\), A- \\(< 93\\), B+ \\(< 90\\), B \\(< 87\\), B- \\(< 83\\), C+ \\(<80\\), C \\(< 77\\), C- \\(< 73\\), D+ \\(< 70\\), D \\(< 67\\), D- \\(< 63\\), F \\(< 60\\)\n\n\n\n\n\n\nA note on quizzes\n\n\n\nOn random class days, there will be a brief quiz on the previous lectures. If you score \\(>60\\%\\) cumulatively on your final quiz grade, you will receive full participation credit. Your lowest two quizzes will also be dropped.\n\n\n\n\n\n\n\n\nA note on exams\n\n\n\nIf you miss either midterm 1 or midterm 2, and have an excused absence, your missing midterm grade will be replaced by your final exam grade. You must take at least 1 midterm and the final exam to pass the course.\n\n\n\n\n\n\n\n\n\nAcademic integrity\nBy enrolling in this course, you commit to upholding Duke’s community standard reproduced as follows:\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised.\n\nAny violations of academic integrity will automatically result in a 0 for the assignment and will be reported to the Office of Student Conduct for further action. For the Exams and Quizzes, students are required to work alone. For the Homework assignments, students may work with a study group but each student must write up and submit their own answers.\nLate work\nLate homework may be submitted within 48 hours of the assignment deadline. Late homework submitted within 24 hours (even 1 minute late) will receive a 5% late penalty. Late work submitted between 24 to 48 hours of the deadline will receive a 10% late penalty. Work submitted after 48 hours will not be accepted. Exams cannot be turned in late and can only be excused under exceptional circumstances. The Duke policy for illness requires a short-term illness report or a letter from the Dean; except in emergencies, all other absenteeism must be approved in advance (e.g., an athlete who must miss class may be excused by prior arrangement for specific days). For emergencies, email notification is needed at the first reasonable time.\nErrors in grading\nErrors in grading must be brought to the attention of the TA or instructor during office hours within 1 week of receiving the grade."
  },
  {
    "objectID": "quizzes/quiz01.html",
    "href": "quizzes/quiz01.html",
    "title": "Quiz 1",
    "section": "",
    "text": "Exercise 1\nTRUE or FALSE: The beta prior is conjugate to a binomial likelihood.\n\n\nExercise 2\nTRUE or FALSE: \\(p(y|\\theta)\\) is the marginal likelihood.\n\n\nExercise 3\nIn Bayes’ theorem (written below), which term is the “normalizing constant”?\n\\[\np(\\theta | y) = \\frac{p(y |\\theta) p(\\theta)}{\\int p(y, \\theta) d\\theta}\n\\]\n\n\nExercise 4\n\\[\n\\begin{aligned}\nX &\\sim gamma(k, \\theta)\\\\\np(x) &= \\frac{1}{\\Gamma(k) \\theta^k}x^{k-1}e^{-x/\\theta}\n\\end{aligned}\n\\]\nThe kernel of the distribution is ___.\n\n\n\n04:00"
  },
  {
    "objectID": "quizzes/quiz02.html",
    "href": "quizzes/quiz02.html",
    "title": "Quiz 2",
    "section": "",
    "text": "Exercise 1\nTRUE or FALSE: this is a 95% Bayesian confidence interval:\n\\[\np(l(y) < \\theta < u(y) | y) = 0.95\n\\]\n\n\nExercise 2\nWrite “equals” or “does not equal” in the blank below:\nIf\n\\[\nY | \\theta \\sim \\text{binomial}(n, \\theta),\n\\]\nthen \\(\\hat{\\theta}_{MLE}\\) ___ \\(\\hat{\\theta}_{MAP}\\) when \\(\\theta \\sim \\text{beta}(1, 1)\\).\n\n\nExercise 3\nTRUE or FALSE: high posterior density regions are always intervals.\n\n\n\n03:00"
  },
  {
    "objectID": "notes/MonteCarlo.html",
    "href": "notes/MonteCarlo.html",
    "title": "Monte Carlo Integration",
    "section": "",
    "text": "# load packages\nlibrary(tidyverse)\nlibrary(latex2exp)"
  },
  {
    "objectID": "slides/lab2.html#practice-exercise",
    "href": "slides/lab2.html#practice-exercise",
    "title": "Sensitivity to the prior and change of variables",
    "section": "Practice exercise",
    "text": "Practice exercise\nA cancer laboratory is estimating the rate of tumorigenesis in two strains of mice, \\(A\\) and \\(B\\). They have tumor count data for 10 mice in strain \\(A\\) and 13 mice in strain \\(B\\),\n\nyA = c(12, 9, 12, 14, 13, 13, 15, 8, 15, 6)\nyB = c(11, 11, 10, 9, 9, 8, 7, 10, 6, 8, 8, 9, 7)\n\nAssume\n\\[\n\\begin{aligned}\nY_A &\\sim \\text{Poisson}(\\theta_A)\\\\\nY_B &\\sim \\text{Poisson}(\\theta_B).\n\\end{aligned}\n\\]\n\nExercise 1Exercise 2\n\n\nLet\n\\[\n\\begin{aligned}\n\\theta_A &\\sim \\text{gamma}(120, 10)\\\\\n\\theta_B &\\sim \\text{gamma}(12, 1).\n\\end{aligned}\n\\]\n\nCompute \\(p(\\theta_B < \\theta_A ~|~ \\vec{y}_A, \\vec{y}_B)\\) via Monte Carlo sampling.\n\n\n\nLet\n\\[\n\\begin{aligned}\n\\theta_A &\\sim \\text{gamma}(120, 10)\\\\\n\\theta_B &\\sim \\text{gamma}(12\\cdot n_0, n_0).\n\\end{aligned}\n\\]\n\nFor a range of values of \\(n_0\\), obtain \\(p(\\theta_B < \\theta_A ~|~ \\vec{y}_A, \\vec{y}_B)\\).\nDescribe how sensitive conclusions about the event \\(\\{ \\theta_B < \\theta_A\\}\\) are to the prior distribution on \\(\\theta_B\\)."
  },
  {
    "objectID": "slides/lab2.html#practice-exercise-1",
    "href": "slides/lab2.html#practice-exercise-1",
    "title": "Sensitivity to the prior and change of variables",
    "section": "Practice exercise",
    "text": "Practice exercise\n\nLet \\(X \\sim \\text{Unif}(5, 10)\\)\nLet \\(Y = X^2\\)\n\nNotice that even though \\(X^2\\) is not a monotonic function everywhere, it is a monotonic function over the support of X.\nExercise: use the change of variables formula to derive \\(p(y)\\). Confirm with Monte Carlo simulation.\n\n\nShow solution\nlibrary(tidyverse)\n\nx = runif(100000, 5, 10)\ny = x^2\n\ndf = data.frame(y)\n\nf = function(y) {\n  return(.1/sqrt(y))\n}\n\ndf %>%\n  ggplot(aes(x = y)) + \n  stat_function(fun = f) +\n  geom_histogram(aes(x = y, y = ..density..),\n                 fill = 'steelblue', alpha = 0.5)\n\n\n\n\n🔗 sta360-fa23.github.io"
  },
  {
    "objectID": "notes/MonteCarlo.html#monte-carlo-prediction",
    "href": "notes/MonteCarlo.html#monte-carlo-prediction",
    "title": "Monte Carlo Integration",
    "section": "Monte Carlo prediction",
    "text": "Monte Carlo prediction\n\nPrior predictive distribution\nWe can use Monte Carlo to sample new observation, \\(\\tilde{y}\\), from the prior predictive distribution\n\\[\np(\\tilde{y}) = \\int p(\\tilde{y}|\\theta)p(\\theta) d\\theta,\n\\]\nwhere we proceed by following the iterative procedure below\n1. sample theta_i from the prior p(theta)\n2. sample ytilde from p(ytilde | theta_i)\n3. repeat steps 1 and 2\n\nthis can be useful to see if a prior for \\(p(\\theta)\\) actually translate to reasonable prior beliefs about the data.\n\n\n\n\n\n\n\nExercise\n\n\n\nFor \\(p(\\theta) = \\text{gamma}(8,2)\\), plot \\(p(\\tilde{y})\\) assuming \\(\\tilde{y} | \\theta \\sim \\text{Poisson}(\\theta)\\).\n\n\n\n\n\n\n\nPosterior predictive distribution\nWe can also sample \\(\\tilde{y}\\) from the posterior predictive distribution,\n\\[\np(\\tilde{y} | y_1, \\ldots y_n) = \\int p(\\tilde{y}|\\theta) p(\\theta|y_1, \\ldots, y_n)d\\theta,\n\\]\nwhere the procedure is the same as before, except step 1 is replace with sampling \\(\\theta\\) from the posterior \\(p(\\theta | y_1,\\ldots, y_n)\\).\nThe resulting sequence \\((\\theta^{(1)}, \\tilde{y}^{(1)}), \\ldots, (\\theta^{(N)}, \\tilde{y}^{(N)})\\) constitutes \\(N\\) independent samples from the joint posterior of \\((\\theta, \\tilde{Y})\\). The sequence \\(\\tilde{y}^{(1)}, \\ldots, \\tilde{y}^{(N)})\\) constitutes \\(N\\) independent samples from the marginal posterior distribution of \\(\\tilde{Y}\\), aka the posterior predictive distribution."
  },
  {
    "objectID": "notes/MonteCarlo.html#posterior-predictive-model-checking",
    "href": "notes/MonteCarlo.html#posterior-predictive-model-checking",
    "title": "Monte Carlo Integration",
    "section": "Posterior predictive model checking",
    "text": "Posterior predictive model checking\nWe can assess the fit of a model by comparing the posterior predictive distribution to the empirical distribution.\n\nExample: is our Poisson model flawed?\n\n# load general social survey data\ngss = read_csv(\"https://sta360-fa23.github.io/data/gss.csv\")\n\n\ny1 = gss$CHILDS[gss$FEMALE == 1 &  gss$YEAR >= 1990  & gss$AGE == 40 & \n                   gss$DEGREE < 3 ]\ny1 = y1[!is.na(y1)]\nn = length(y1)\n\nWe are examining the number of children \\(Y_i\\) belonging to \\(n=\\) 111 40 year old women surveyed 1990 or later without a bachelor’s. These data come from the general social survey.\nSuppose\n\\[\n\\begin{aligned}\nY_i & \\sim \\text{Poisson}(\\theta)\\\\\n\\theta & \\sim \\text{gamma}(2, 1).\n\\end{aligned}\n\\]\nThe empirical and predictive distributions of the data are both plotted below.\n\nplotcode\n\n\n\n\n\n\n\n\n\n\nset.seed(123)\n\n# posterior predictive distribution\nytotal = sum(y1)\na = 2 ; b = 1\nN = 10000\ntheta.post.mc = rgamma(N, ytotal + a, b + n)\ny1.mc = rpois(N, theta.post.mc)\n\n# data\ndf = data.frame(y1) # empirical\ndf2 = data.frame(y1.mc) # post predictive\n  \n# make plot\ndf %>%\n  ggplot(aes(x = y1)) +\n  geom_bar(aes(x = y1 + .15, y = (..count..)/sum(..count..),\n               fill = \"empirical\"), alpha = 0.6, width = 0.3) +\n  geom_bar(data = df2, \n                 aes(x = y1.mc -.15, y = (..count..) / sum(..count..),\n                     fill = \"predictive\"), alpha = 0.4, width = 0.3) +\n  labs(x = \"number of children\", \n       y = TeX(\"$p(Y_i = y_i)$\"),\n       fill = \"\") +\n  scale_x_continuous(breaks = c(0:7), labels = c(0:7),\n                     limits = c(-.5,7.5)) +\n  \n  theme_bw()\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nLet \\(\\mathbf{y}\\) be a vector of length 111. Let \\(t(\\mathbf{y})\\) be the ratio of \\(2\\)s to \\(1\\)s in \\(\\mathbf{y}\\). For our observed data, this test statistic \\(t(\\mathbf{y}_{obs}) = 38 / 19 = 2\\). What is the tail probability \\(p(t(\\tilde{\\mathbf{Y}}) \\geq t(\\mathbf{y}_{obs}))\\) under the posterior predictive distribution?"
  },
  {
    "objectID": "quizzes/quiz03.html",
    "href": "quizzes/quiz03.html",
    "title": "Quiz 3",
    "section": "",
    "text": "Exercise 1\nWrite “posterior” or “prior” in the blank below:\n\\(\\int p(\\tilde{y}|\\theta) p(\\theta | y_1,\\ldots y_n)d\\theta\\) is a ___ predictive distribution.\n\n\nExercise 2\nExpand \\(p(\\theta | y)\\) using Bayes’ rule (include the normalization constant).\n\n\nExercise 3\nTRUE or FALSE\nMonte Carlo integration error scales \\(\\mathcal{O}(\\frac{1}{\\sqrt{N}})\\) where \\(N\\) is the number of independent samples from the posterior.\n\n\n\n03:00"
  },
  {
    "objectID": "quizzes/quiz03.html#exercise-3",
    "href": "quizzes/quiz03.html#exercise-3",
    "title": "Quiz 3",
    "section": "Exercise 3",
    "text": "Exercise 3\nTRUE or FALSE\nMonte Carlo integration error scales \\(\\mathcal{O}(\\frac{1}{\\sqrt{N}})\\) where \\(N\\) is the number of independent samples from the posterior.\n\n\n\n03:00"
  },
  {
    "objectID": "notes/normalModel1.html",
    "href": "notes/normalModel1.html",
    "title": "The normal model",
    "section": "",
    "text": "# load packages\nlibrary(tidyverse)\nlibrary(latex2exp)"
  },
  {
    "objectID": "notes/MonteCarlo.html#monte-carlo-error",
    "href": "notes/MonteCarlo.html#monte-carlo-error",
    "title": "Monte Carlo Integration",
    "section": "Monte Carlo error",
    "text": "Monte Carlo error\n\nHow many values should we simulate?\nRecall: expected values are integrals, and integrals are expected values. Since central limit theorem (CLT) deals with expected values…\nRecall: CLT states that if \\(\\theta_i |\\vec{y}\\) iid with mean \\(\\theta\\) and finite variance \\(\\sigma^2\\), for \\(i \\in \\{1, \\ldots, N\\}\\), then the sample mean\n\\[\n\\bar{\\theta} \\sim N(\\theta, \\frac{\\sigma^2}{N} ).\n\\]\n\nHow to remember this/show this? Offline notes.\n\nSo to estimate \\(\\theta\\), we can generate \\(\\bar{\\theta}\\) by Monte Carlo simulation and report a confidence interval using quantiles of the normal given above in conjunction with the Monte Carlo standard error \\(\\frac{\\hat{\\sigma}}{\\sqrt{N}}\\)\nThis means we get convergence at the rate \\(\\mathcal{O}\\left(\\frac{1}{\\sqrt{N}}\\right)\\) regardless of the dimension of the integral!\nRecall:\n\nsd1 = pnorm(1) - pnorm(-1)\nsd2 = pnorm(2) - pnorm(-2)\nsd3 = pnorm(3) - pnorm(-3)\n\n\na 0.6826895% confidence interval can be obtained using \\(\\pm 1\\cdot \\hat{\\sigma}/\\sqrt{N}\\)\na 0.9544997% confidence interval can be obtained using \\(\\pm 2\\cdot \\hat{\\sigma}/\\sqrt{N}\\)\na 0.9973002% confidence interval can be obtained using \\(\\pm 3\\cdot \\hat{\\sigma}/\\sqrt{N}\\)\n\n\n\nExample\n\n# Let theta be \"x\" in the code below\nset.seed(123)\n\n# binomial(n, p)\nn = 20\np = 0.4\n\n# mean, variance, sd of a binomial(n, p)\nEX = n*p # 20*.4 = 8\nVarX = n*p*(1-p) # 20*.4*.6 = 4.8\nsdX = sqrt(VarX) # 2.19089\n\n# Monte Carlo sample of size N\nN = 100\nxSamples = rbinom(N, size = n, prob = p) \n\n# sample mean, var, sd\nxbar = mean(xSamples)\nxvar = var(xSamples)\nxsigma = sd(xSamples) # = sqrt(sum((xSamples - xbar)^2) / (N -1))\n\nse = xsigma / sqrt(N)\n\nlb = round(xbar - (2*se), 3)\nub = round(xbar + (2*se), 3)\n\nFor N = 100 Monte Carlo samples, The posterior mean of \\(\\theta\\) is \\(\\bar{\\theta} =\\) 8.01 with 95% confidence interval (7.57 8.45).\n\n\n\n\n\n\nExercise\n\n\n\nAbove we estimate \\(Var(\\theta)\\) to be 4.838 and the standard error for \\(N = 100\\) was 0.22.\nIf you wanted to state \\(p(\\theta \\in (\\hat{\\theta} \\pm 0.01)) = 0.95\\), how large would \\(N\\) have to be?\nCheck your answer by adjusting \\(N\\) above."
  },
  {
    "objectID": "notes/normalModel1.html#components-of-the-normal",
    "href": "notes/normalModel1.html#components-of-the-normal",
    "title": "The normal model",
    "section": "Components of the normal",
    "text": "Components of the normal\nLet \\(Y\\) be normally distributed with mean \\(\\theta\\) and variance \\(\\sigma^2\\). Mathematically,\n\\[\nY | \\theta, \\sigma^2 \\sim N(\\theta, \\sigma^2).\n\\]\nThe density\n\\[\n\\begin{aligned}\np(y ~|~ \\theta, \\sigma^2 ) &= (2\\pi\\sigma^2)^{-1/2} e^{-\\frac{1}{2\\sigma^2} (x-\\theta)^2},\\\\\ny &\\in \\mathbb{R},\\\\\n\\theta &\\in \\mathbb{R},\\\\\n\\sigma &\\in \\mathbb{R}^+.\n\\end{aligned}\n\\]\n\nVocabulary\n\nlocation, scale\n\n\\(\\theta\\) is called the ‘location’ parameter\n\\(\\sigma\\) is called the ‘scale’ parameter\n\n\n\nprecision\nNotice that every time \\(\\sigma^2\\) appears in the density, it is inverted. For this reason, the inverse variance has a special name, precision. Mathematically we will call precision \\(\\lambda^2 = \\frac{1}{\\sigma^2}\\). Intuitively, precision tells us how close \\(y_i\\) is to the mean \\(\\theta\\). (Large precision = small variance = closer).\n\n\n\nplots of normal densities\n\n\n\n\n\n\nWarning\n\n\n\nIn R, the arguments of pnorm, dnorm, rnorm are the mean and standard deviation (not the variance!)\n\n\n\nplotcode\n\n\n\n\n\n\n\n\n\n\nset.seed(123)\nN = 10000\ny.mc = rnorm(N, mean = 3, sd = 2)\n\ndf = data.frame(y.mc)\n\ndf %>%\n  ggplot(aes(x = y.mc)) +\n  geom_histogram(aes(y = ..density..), alpha = 0.6, fill = 'steelblue') +\n  stat_function(fun = dnorm, args = list(mean = 3, sd = 2), aes(color = \"N(3, 4)\")) +\n  stat_function(fun = dnorm, args = list(mean = 0, sd = 1), aes(color = \"N(0, 1)\")) +\n  theme_bw() +\n  labs(x = \"y\", y = \"density\", title = \"Normal densities\",\n       color = \"\")"
  },
  {
    "objectID": "notes/normalModel1.html#one-parmaeter-inference",
    "href": "notes/normalModel1.html#one-parmaeter-inference",
    "title": "The normal model",
    "section": "One parmaeter inference",
    "text": "One parmaeter inference"
  },
  {
    "objectID": "notes/normalModel1.html#normal-definition",
    "href": "notes/normalModel1.html#normal-definition",
    "title": "The normal model",
    "section": "Normal definition",
    "text": "Normal definition\nLet \\(Y\\) be normally distributed with mean \\(\\theta\\) and variance \\(\\sigma^2\\). Mathematically,\n\\[\nY | \\theta, \\sigma^2 \\sim N(\\theta, \\sigma^2).\n\\]\nThe density\n\\[\n\\begin{aligned}\np(y ~|~ \\theta, \\sigma^2 ) &= (2\\pi\\sigma^2)^{-1/2} e^{-\\frac{1}{2\\sigma^2} (x-\\theta)^2},\\\\\ny &\\in \\mathbb{R},\\\\\n\\theta &\\in \\mathbb{R},\\\\\n\\sigma &\\in \\mathbb{R}^+.\n\\end{aligned}\n\\]\n\nVocabulary\n\nlocation, scale\n\n\\(\\theta\\) is called the ‘location’ parameter\n\\(\\sigma\\) is called the ‘scale’ parameter\n\n\n\nprecision\nNotice that every time \\(\\sigma^2\\) appears in the density, it is inverted. For this reason, the inverse variance has a special name, precision. Mathematically we will call precision \\(\\lambda^2 = \\frac{1}{\\sigma^2}\\). Intuitively, precision tells us how close \\(y\\) is to the mean \\(\\theta\\). (Large precision = small variance = closer).\n\n\n\nplots of normal densities\n\n\n\n\n\n\nWarning\n\n\n\nIn R, the arguments of pnorm, dnorm, rnorm are the mean and standard deviation (not the variance!)\n\n\n\nplotcode\n\n\n\n\n\n\n\n\n\n\nset.seed(123)\nN = 10000\ny.mc = rnorm(N, mean = 3, sd = 2)\n\ndf = data.frame(y.mc)\n\ndf %>%\n  ggplot(aes(x = y.mc)) +\n  geom_histogram(aes(y = ..density..), alpha = 0.6, fill = 'steelblue') +\n  stat_function(fun = dnorm, args = list(mean = 3, sd = 2), aes(color = \"N(3, 4)\")) +\n  stat_function(fun = dnorm, args = list(mean = 0, sd = 1), aes(color = \"N(0, 1)\")) +\n  theme_bw() +\n  labs(x = \"y\", y = \"density\", title = \"Normal densities\",\n       color = \"\")"
  },
  {
    "objectID": "notes/normalModel1.html#background",
    "href": "notes/normalModel1.html#background",
    "title": "The normal model",
    "section": "Background",
    "text": "Background\n\nDefinition and vocabulary\nLet \\(Y\\) be normally distributed with mean \\(\\theta\\) and variance \\(\\sigma^2\\). Mathematically,\n\\[\nY | \\theta, \\sigma^2  \\sim N(\\theta, \\sigma^2).\n\\]\nThe density\n\\[\n\\begin{aligned}\np(y ~|~ \\theta, \\sigma^2 ) &= (2\\pi\\sigma^2)^{-1/2} e^{-\\frac{1}{2\\sigma^2} (x-\\theta)^2},\\\\\ny &\\in \\mathbb{R},\\\\\n\\theta &\\in \\mathbb{R},\\\\\n\\sigma &\\in \\mathbb{R}^+.\n\\end{aligned}\n\\]\n\nlocation, scale\n\n\\(\\theta\\) is called the ‘location’ parameter\n\\(\\sigma\\) is called the ‘scale’ parameter\n\n\n\nprecision\nNotice that every time \\(\\sigma^2\\) appears in the density, it is inverted. For this reason, the inverse variance \\((\\frac{1}{\\sigma^2})\\) has a special name, precision. Intuitively, precision tells us how close \\(y\\) is to the mean \\(\\theta\\). (Large precision = small variance = closer).\n\n\n\nplots of normal densities\n\n\n\n\n\n\nWarning\n\n\n\nIn R, the arguments of pnorm, dnorm, rnorm are the mean and standard deviation (not the variance!)\n\n\n\nplotcode\n\n\n\n\n\n\n\n\n\n\nset.seed(123)\nN = 10000\ny.mc = rnorm(N, mean = 3, sd = 2)\n\ndf = data.frame(y.mc)\n\ndf %>%\n  ggplot(aes(x = y.mc)) +\n  geom_histogram(aes(y = ..density..), alpha = 0.6, fill = 'steelblue') +\n  stat_function(fun = dnorm, args = list(mean = 3, sd = 2), aes(color = \"N(3, 4)\")) +\n  stat_function(fun = dnorm, args = list(mean = 0, sd = 1), aes(color = \"N(0, 1)\")) +\n  theme_bw() +\n  labs(x = \"y\", y = \"density\", title = \"Normal densities\",\n       color = \"\")"
  },
  {
    "objectID": "notes/normalModel1.html#bayesian-inference",
    "href": "notes/normalModel1.html#bayesian-inference",
    "title": "The normal model",
    "section": "Bayesian inference",
    "text": "Bayesian inference\nIn general, we wish to make inference about \\(\\theta\\) and \\(\\sigma^2\\) after observing some data \\(y_1, \\ldots y_n\\) and thus are interested in the posterior \\(p(\\theta, \\sigma^2 | y_1, \\ldots y_n)\\). This is the standard task we have seen thus far, and requires us to specify a joint prior \\(p(\\theta, \\sigma^2)\\). Below, we will work to find a class of conjugate priors over \\(\\theta\\) and \\(\\sigma^2\\).\nWe can break up the joint posterior into two pieces from the axioms of probability:\n\\[\np(\\theta, \\sigma^2 | y_1, \\ldots y_n) = p(\\theta | \\sigma^2, y_1, \\ldots, y_n)p(\\sigma^2|y_1, \\ldots y_n)\n\\]\nThis suggests that we calculate the joint posterior by:\n\nfirst finding the full conditional of \\(\\theta\\): \\(p(\\theta| \\sigma^2, \\vec{y})\\)\nand then finding the marginal posterior of \\(\\sigma^2\\): \\(p(\\sigma^2 | \\vec{y})\\),\n\nwhere \\(\\vec{y} = \\{y_1, \\ldots y_n\\}\\).\n\nThe full conditional of \\(\\theta\\)\nBy Bayes’ theorem,\n\\[\np(\\theta| \\sigma^2, \\vec{y}) \\propto \\underbrace{p(\\vec{y} |\\theta, \\sigma^2)}_{\\text{likelihood}} \\underbrace{p(\\theta|\\sigma^2)}_{\\text{prior}}.\n\\]\nTo arrive at the full conditional posterior of \\(\\theta\\), we must first specify a prior on \\(\\theta\\).\nConsidering we have a normal likelihood, what is a conjugate class of densities for \\(\\theta\\)?\n\n\n\n\n\n\nanswer\n\n\n\n\n\n\\(\\theta | \\sigma^2 \\sim N(\\mu_0, \\tau_0^2)\\) for some \\(\\mu_0 \\in \\mathbb{R}\\) and \\(\\tau_0^2 \\in \\mathbb{R}^+\\) is conjugate.\n\n\n\nWith the conjugate prior, our full conditional posterior \\(\\{ \\theta| \\sigma^2, \\vec{y} \\} \\sim N(\\mu_n, \\tau_n^2)\\) where\n\\[\n\\begin{aligned}\n\\mu_n &=\n\\frac{\\frac{1}{\\tau_0^2}\\mu_0 + \\frac{n}{\\sigma^2} \\bar{y}}{\n\\frac{1}{\\tau_0^2} + \\frac{n}{\\sigma^2}\n}\n\\\\\n\\\\\n\\tau_n^2 &= \\frac{1}{\\frac{1}{\\tau_0^2} + \\frac{n}{\\sigma^2}}\n\\end{aligned}\n\\]\n\nLet’s sketch out ‘completing the square’ to derive the parameters offline.\n\n\n\nIntuitive posterior parameters\nIf we consider the posterior precision, \\(\\frac{1}{\\tau_n^2}\\), we can re-arrange the terms above to illuminate how posterior information = prior information + data information;.\n\\[\n\\frac{1}{\\tau_n^2}= \\frac{1}{\\tau_0^2} + \\frac{n}{\\sigma^2}\n\\]\nIn words, posterior precision is equivalent to prior precision plus sampling precision. If we name each precision term, \\(\\lambda_0 = \\frac{1}{\\tau_0}\\), \\(\\lambda_n = \\frac{1}{\\tau_n}\\) and \\(\\lambda = \\frac{1}{\\sigma}\\) then\n\\[\n\\mu_n = \\frac{\\lambda_0^2}{\\lambda_0^2 + n\\lambda^2} \\mu_0 +\n\\frac{n\\lambda^2}{\\lambda_0^2 + n\\lambda^2} \\bar{y}\n\\]\ni.e. the posterior mean is the weighted average of prior and sample mean, where the weights are the relative contribution of each precision!\nWe can re-define \\(\\lambda_0^2 = \\kappa_0 \\lambda^2\\) (or equivalently \\(\\tau_0^2 = \\frac{\\sigma^2}{\\kappa_0}\\)) and obtain\n\\[\n\\begin{aligned}\n\\mu_n &= \\frac{\\kappa_0}{\\kappa_0 + n} \\mu_0 + \\frac{n}{\\kappa_0 + n} \\bar{y},\\\\\n\\frac{1}{\\tau_n^2} &= \\frac{\\kappa_0 + n}{\\sigma^2}\n\\end{aligned}\n\\]\nwhere we can interpret \\(\\kappa_0\\) as the prior sample size.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nNote that \\(\\tau_n^2\\) is the posterior variance of the full conditional posterior of \\(\\theta\\). This is distinct from \\(\\sigma_n^2\\), defined below.\n\n\n\n\nPrior on \\(\\sigma^2\\)\nRemember, we want \\(p(\\theta, \\sigma^2 | \\vec{y}) = p(\\theta | \\sigma^2, y_1, \\ldots, y_n)p(\\sigma^2|y_1, \\ldots y_n)\\). We have the first component of the right hand side, what about the second component?\nNotice that\n\\[\np(\\sigma^2 | \\vec{y}) \\propto p(\\sigma^2)\\int p(\\vec{y} | \\theta, \\sigma^2) p(\\theta|\\sigma^2) d\\theta\n\\]\nBut how do we choose \\(p(\\sigma^2)\\) to be conjugate? We can proceed in multiple ways: one is noting that the integral is really a convolution of normals, (thereby a sum of normals) and is therefore a normal density.\nUpon inspection, we can see a suitable choice is \\(\\frac{1}{\\sigma^2} \\sim \\text{gamma}(a, b)\\).\n\n\nThe inverse-gamma\nA random variable \\(X \\in (0, \\infty)\\) has an inverse-gamma(a,b) distribution if \\(\\frac{1}{X}\\) has a gamma(a,b) distribution.\nIf X has an inverse-gamma distribution, the density of X is\n\\[\np(x | a, b) = \\frac{b^a}{\\Gamma(a)} x^{-a-1}e^{-b/x} \\ \\text{for } \\ x > 0\n\\]\nand\n\\[\n\\begin{aligned}\nEX &= \\frac{b}{(a-1)} \\text{ if } a \\geq 1; \\ \\infty \\text{ if } 0<a<1,\\\\\nVar(X) &= \\frac{b^2}{(a-1)^2(a-2)} \\ \\text{if } a \\geq 2; \\ \\infty \\text{ if } 0 < a < 2,\\\\\nMode(X) &= \\frac{b}{a +1}.\n\\end{aligned}\n\\]\n\n\nThe marginal posterior of \\(\\sigma^2\\)\nTaken all together, if we let our sampling model and prior distributions be such that\n\\[\n\\begin{aligned}\nY_i | \\theta, \\sigma^2 &\\sim N(\\theta, \\sigma^2)\\\\\n\\theta | \\sigma^2 & \\sim N(\\mu_0, \\sigma^2/\\kappa_0)\\\\\n\\frac{1}{\\sigma^2} &\\sim \\text{gamma}(\\frac{\\nu_0}{2}, \\frac{\\nu_0}{2} \\sigma_0^2)\n\\end{aligned}\n\\]\nthen the posterior\n\\[\n\\frac{1}{\\sigma^2} | \\vec{y} \\sim \\text{gamma}(\\frac{\\nu_n}{2}, \\frac{\\nu_n \\sigma^2_n}{2}),\n\\]\nwhere\n\\[\n\\begin{aligned}\n\\nu_n &= \\nu_0 + n,\\\\\n\\sigma^2_n &= \\frac{1}{\\nu_n} \\left[\n\\nu_0 \\sigma^2_0 +(n-1)s^2 + \\frac{\\kappa_0 n}{\\kappa_0 + n}(\\bar{y} - \\mu_0)^2\n\\right],\n\\end{aligned}\n\\]\nand \\(s^2\\) is the sample variance, \\(\\frac{1}{n-1} \\sum_i (y_i - \\bar{y})^2\\)."
  },
  {
    "objectID": "notes/normalModel1.html#the-marginal-posterior-of-sigma2",
    "href": "notes/normalModel1.html#the-marginal-posterior-of-sigma2",
    "title": "The normal model",
    "section": "The marginal posterior of \\(\\sigma^2\\)",
    "text": "The marginal posterior of \\(\\sigma^2\\)"
  },
  {
    "objectID": "notes/normalModel1.html#posterior-estimates-via-monte-carlo-sampling",
    "href": "notes/normalModel1.html#posterior-estimates-via-monte-carlo-sampling",
    "title": "The normal model",
    "section": "Posterior estimates via Monte Carlo sampling",
    "text": "Posterior estimates via Monte Carlo sampling\n\n# setting hyperparameters\nnu0 = 3; s20 = 1\nk0 = 1; mu0 = 2\n\n# data\ny = c(1.64, 1.70, 1.72, 1.82, 1.82, 1.82, 1.90, 2.08)\nn = length(y)\nybar = mean(y)\ns2 = var(y)\n\n# posterior via Monte Carlo sampling\n\nN = 10000\ns2.mc = 1 / rgamma(N, nu0 + n, )"
  },
  {
    "objectID": "notes/normalModel1.html#computing-the-joint-posterior",
    "href": "notes/normalModel1.html#computing-the-joint-posterior",
    "title": "The normal model",
    "section": "Computing the joint posterior",
    "text": "Computing the joint posterior\nSince \\(p(\\theta, \\sigma^2 | \\vec{y}) = p(\\theta | \\sigma^2, y_1, \\ldots, y_n)p(\\sigma^2|y_1, \\ldots y_n)\\), we can compute the joint posterior by sampling from \\(p(\\sigma^2|y_1, \\ldots y_n)\\) and then sampling from \\(p(\\theta | \\sigma^2, y_1, \\ldots, y_n)\\) to draw samples from the joint posterior.\n\nExample\nProof of concept\nWe have some data:\n\n# generating 10 samples from the population\ntrue.theta = 4\ntrue.sigma = 1\ny = rnorm(10, true.theta, true.sigma)\n\nybar = mean(y) # sample mean\nn = length(y) # sample size\ns2 = var(y) # sample variance\n\nWe make inference about \\(\\theta\\) and \\(\\sigma^2\\):\n\n# priors\n# theta prior\nmu_0 = 2; k_0 = 1\n# sigma2 prior\nnu_0 = 1; s2_0 = 0.010\n\n# posterior parameters\nkn = k_0 + n\nnun = nu_0 + n\nmun = (k_0 * mu_0 + n * ybar) /kn\ns2n = (nu_0 * s2_0 + (n - 1) * s2 + k_0 * n * (ybar - mu_0)^2 / (kn)) / (nun)\n\ns2.postsample = 1 / rgamma(10000, nun / 2, s2n * nun / 2)\ntheta.postsample = rnorm(10000, mun, sqrt(s2.postsample / kn))\n\ndf = data.frame(theta.postsample, s2.postsample)\n\ndf %>%\n  ggplot(aes(x = theta.postsample, y = s2.postsample)) +\n  stat_density_2d(aes(fill = ..level..), geom = \"polygon\") +\n  labs(x = TeX(\"$\\\\theta$\"),\n       y = TeX(\"$\\\\sigma^2$\"),\n       fill = TeX(\"$p(\\\\theta, \\\\sigma^2 | y_1, \\\\ldots y_n)$\")) +\n  theme_bw()"
  },
  {
    "objectID": "slides/lab3-review.html#exercise",
    "href": "slides/lab3-review.html#exercise",
    "title": "Exam practice",
    "section": "Exercise",
    "text": "Exercise\nPhysicists studying a radioactive substance measure the times at which the substance emits a particle. They will record \\(n+1\\) emissions and set \\(Y_1\\) to be the time elapsed between the first and second emission, \\(Y_2\\) to be the time elapsed between the second and third emission and so on. They will model the data as \\(Y_1, \\ldots Y_n | \\theta \\sim \\text{exponential}(\\theta)\\). The pdf of the exponential(\\(\\theta\\)) distribution is\n\\[\np(y |\\theta) = \\theta e^{-\\theta y} \\ \\text{ for } \\ y>0, \\ \\theta>0.\n\\]\nFor this distribution, \\(E[Y|\\theta] = \\frac{1}{\\theta}\\).\n(a). Write out the corresponding joint density \\(p(y_1, \\ldots, y_n | \\theta)\\) and simplify as much as possible. Justify each step of your calculation.\n(b). For fixed values of \\(y_1, \\ldots y_n\\), find the value of \\(\\theta\\) that maximizes \\(p(y_1, \\ldots, y_n | \\theta)\\) as a function of \\(\\theta\\), and call this maximizing value \\(\\hat{\\theta}\\). Hint: \\(\\hat{\\theta}\\) can also be found by maximizing \\(\\log p(y_1, \\ldots, y_n | \\theta)\\), which is easier to work with.\n(c). Suppose your information about \\(\\theta\\) can be described with a gamma(\\(a, b\\)) prior distribution for some values of \\(a\\) and \\(b\\). Write out the formula for \\(p(\\theta | y_1, \\ldots y_n)\\), up to a proportionality in \\(\\theta\\), and simplify as much as possible. From this, identify explicitly the posterior distribution of \\(\\theta\\) (i.e., write “the posterior is a blank distribution with parameter(s) blank)”.\n(d). Obtain the formula for \\(E[\\theta, y_1, \\ldots y_n]\\) as a function of \\(a, b n\\) and \\(y_1, \\ldots y_n\\), and try to write this as a function of the estimator \\(\\hat{\\theta}\\) you found in part (b). What does \\(E[\\theta | y_1,\\ldots,y_n]\\) get close to as \\(n\\) increases?\n\n\n🔗 sta360-fa23.github.io"
  },
  {
    "objectID": "solutions/workshop.html",
    "href": "solutions/workshop.html",
    "title": "Workshopping",
    "section": "",
    "text": "Proof of concept\nWe have some data:\n\n# generating 10 samples from the population\ntrue.theta = 4\ntrue.sigma = 1\ny = rnorm(10, true.theta, true.sigma)\n\nybar = mean(y) # sample mean\nn = length(y) # sample size\ns2 = var(y) # sample variance\n\nWe make inference about \\(\\theta\\) and \\(\\sigma^2\\):\n\n# priors\n# theta prior\nmu_0 = 2; k_0 = 1\n# sigma2 prior\nnu_0 = 1; s2_0 = 0.010\n\n# posterior parameters\nkn = k_0 + n\nnun = nu_0 + n\nmun = (k_0 * mu_0 + n * ybar) /kn\ns2n = (nu_0 * s2_0 + (n - 1) * s2 + k_0 * n * (ybar - mu_0)^2 / (kn)) / (nun)\n\ns2.postsample = 1 / rgamma(10000, nun / 2, s2n * nun / 2)\ntheta.postsample = rnorm(10000, mun, sqrt(s2.postsample / kn))\n\ndf = data.frame(theta.postsample, s2.postsample)\n\ndf %>%\n  ggplot(aes(x = theta.postsample, y = s2.postsample)) +\n  stat_density_2d(aes(fill = ..level..), geom = \"polygon\") +\n  labs(x = TeX(\"$\\\\theta$\"),\n       y = TeX(\"$\\\\sigma^2$\"),\n       fill = TeX(\"$p(\\\\theta, \\\\sigma^2 | y_1, \\\\ldots y_n)$\")) +\n  theme_bw()"
  },
  {
    "objectID": "notes/exam-notes.html",
    "href": "notes/exam-notes.html",
    "title": "Exam notes",
    "section": "",
    "text": "A random variable \\(X \\in \\mathbb{R}\\) has a \\(N(\\theta, \\sigma^2)\\) distribution if \\(\\sigma^2 > 0\\) and\n\\(p(x | \\theta, \\sigma^2) = (2 \\pi \\sigma^2)^{-\\frac{1}{2}} e^{-\\frac{1}{2\\sigma^2}(x - \\theta)^2} \\ \\ \\ \\text{ for } -\\infty < x < \\infty.\\)\n\n\n\nA random variable \\(X \\in (0, \\infty)\\) has a gamma(a,b) distribution if \\(a > 0, b > 0\\) and\n\\(p(x |a,b) = \\frac{b^a}{\\Gamma(a)} x^{a - 1} e^{-bx} \\ \\ \\ \\text{ for } x > 0.\\)\n\\(E[X | a, b] = a/b\\), \\(Var[X | a,b] = a / b^2\\)\n\n\n\nA random variable \\(X \\in (0, \\infty)\\) has an inverse-gamma(a,b) distribution if 1/X has a gamma(a,b) distribution. If \\(X\\) is inverse-gamma(a,b) then the density of X is\n\\(p(x|a,b) = \\frac{b^a}{\\Gamma(a)} x^{-a-1} e^{-b/x} \\ \\ \\ \\text{ for } x > 0.\\)\n\\(E[X|a,b] = \\frac{b}{a-1}\\) if \\(a>=1\\), \\(\\infty\\) if \\(0<a<1\\)\n\\(Var[X|a,b] = \\frac{b^2}{(a-1)^2(a-2)}\\) if \\(a\\geq2\\), \\(\\infty\\) if \\(0<a<2\\)\n\n\n\nA random variable \\(X \\in \\{0, 1, \\ldots, n\\}\\) has a binomial\\((n, \\theta)\\) distribution if \\(\\theta \\in [0, 1]\\) and\n\\(p(X = x| \\theta, n) = {n \\choose x} \\theta^x (1- \\theta)^{n-x} \\ \\ \\ \\text{ for } x\\in \\{0, 1, \\ldots, n \\}\\)\n\\(E[X|\\theta] = n\\theta\\), \\(Var[X|\\theta] = n\\theta(1-\\theta)\\)\n\n\n\nA random variable \\(X \\in [0, 1]\\) has a beta(a,b) distribution if \\(a > 0, b > 0\\) and\n\\(p(x|a,b) = \\frac{\\Gamma(a + b)}{\\Gamma(a)\\Gamma(b)} x^{a-1} (1-x)^{b-1} \\ \\ \\ \\text{ for } 0 \\leq x \\leq 1.\\)\n\\(E[X|a,b] = \\frac{a}{a + b}\\), \\(Var[X|a,b] = \\frac{ab}{(a + b + 1)(a + b)^2}\\)\n\n\n\nA random variable \\(X \\in \\{0, 1, 2, \\ldots \\}\\) has a Poisson(\\(\\theta\\)) distribution if \\(\\theta > 0\\) and\n\\(p(X = x | \\theta) = \\theta^x \\frac{e^{-\\theta}}{x!} \\ \\ \\ \\text{ for } x \\in \\{0, 1, 2, \\ldots\\}\\)\n\\(E[X|\\theta] = \\theta\\), \\(Var[X|\\theta] = \\theta\\)\n\n\n\nA random variable \\(X \\in [0, \\infty)\\) has a exponential(\\(\\theta\\)) distribution if \\(\\theta >0\\) and\n\\(p(x | \\theta) = \\theta e^{-\\theta x}\\)\n\\(E[X|\\theta] = \\frac{1}{\\theta}\\), \\(Var[X|\\theta] = \\frac{1}{\\theta^2}\\)"
  },
  {
    "objectID": "chapterSummaries.html#definitions-and-conjugacy",
    "href": "chapterSummaries.html#definitions-and-conjugacy",
    "title": "Chapter summaries",
    "section": "Definitions and conjugacy",
    "text": "Definitions and conjugacy\n\nBe able to define likelihood, prior, poserior, normalizing constant\n\n\n\n\n\n\n\nDefinition\n\n\n\nA prior \\(p(\\theta)\\) is said to be conjugate to the data generative model \\(p(y|\\theta)\\) if the family of the posterior is necessarily in the same family as the prior. In math, \\(p(\\theta)\\) is conjugate to \\(p(y|\\theta)\\) if\n\\[\np(\\theta) \\in \\mathcal{P} \\implies p(\\theta | y) \\in \\mathcal{P}\n\\]\n\n\n\nExamples of conjugate models: beta-binomial, gamma-Poisson."
  },
  {
    "objectID": "chapterSummaries.html#reliability",
    "href": "chapterSummaries.html#reliability",
    "title": "Chapter summaries",
    "section": "Reliability",
    "text": "Reliability\n\n\n\n\n\n\nDefinition\n\n\n\nLet \\(\\Phi\\) be the support of \\(\\theta\\). An interval \\((l(y), u(y)) \\subset \\Phi\\) has 95% posterior coverage if\n\\[\np(l(y) < \\theta < u(y) | y ) = 0.95\n\\]\nInterpretation: after observing \\(Y = y\\), our probability that \\(\\theta \\in (l(y), u(y))\\) is 95%.\nSuch an interval is called 95% posterior confidence interval (CI). It may also sometimes be referred to as a 95% “credible interval” to distinguish it from a frequentist CI.\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nA \\(100 \\times (1-\\alpha)\\)% high posterior density (HPD) region is a set \\(s(y) \\subset \\Theta\\) such that\n\n\\(p(\\theta \\in s(y) | Y = y) = 1 - \\alpha\\)\nIf \\(\\theta_a \\in s(y)\\) and \\(\\theta_b \\not\\in s(y)\\), then \\(p(\\theta_a | Y = y) > p(\\theta_b | Y = y)\\)\n\n\n\n\nExponential families\nIf density \\(p(y|\\theta)\\) can be written \\(h(y) c(\\phi) e^{\\phi t(y)}\\) for some transform \\(\\phi = f(\\theta)\\) we can say \\(p(y|\\theta)\\) belongs in the exponential family, and the conjugate prior is \\(p(\\phi | n_0, t_0) =c(\\phi)^{n_0} e^{n_0 t_0 \\phi}\\)."
  },
  {
    "objectID": "chapterSummaries.html#exponential-families",
    "href": "chapterSummaries.html#exponential-families",
    "title": "Chapter summaries",
    "section": "Exponential families",
    "text": "Exponential families\nIf density \\(p(y|\\theta)\\) can be written \\(h(y) c(\\phi) e^{\\phi t(y)}\\) for some transform \\(\\phi = f(\\theta)\\) we can say \\(p(y|\\theta)\\) belongs in the exponential family, and the conjugate prior is \\(p(\\phi) =c(\\phi)^{n_0} e^{n_0 t_0 \\phi}\\)."
  },
  {
    "objectID": "chapterSummaries.html#chapter-3",
    "href": "chapterSummaries.html#chapter-3",
    "title": "Chapter summaries",
    "section": "Chapter 3",
    "text": "Chapter 3\n\nDefinitions and conjugacy\n\nBe able to define likelihood, prior, posterior, normalizing constant\n\n\n\n\n\n\n\nDefinition\n\n\n\nA prior \\(p(\\theta)\\) is said to be conjugate to the data generative model \\(p(y|\\theta)\\) if the family of the posterior is necessarily in the same family as the prior. In math, \\(p(\\theta)\\) is conjugate to \\(p(y|\\theta)\\) if\n\\[\np(\\theta) \\in \\mathcal{P} \\implies p(\\theta | y) \\in \\mathcal{P}\n\\]\n\n\n\nExamples of conjugate models: beta-binomial, gamma-Poisson.\n\n\n\nReliability\n\n\n\n\n\n\nDefinition\n\n\n\nLet \\(\\Phi\\) be the support of \\(\\theta\\). An interval \\((l(y), u(y)) \\subset \\Phi\\) has 95% posterior coverage if\n\\[\np(l(y) < \\theta < u(y) | y ) = 0.95\n\\]\nInterpretation: after observing \\(Y = y\\), our probability that \\(\\theta \\in (l(y), u(y))\\) is 95%.\nSuch an interval is called 95% posterior confidence interval (CI). It may also sometimes be referred to as a 95% “credible interval” to distinguish it from a frequentist CI.\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nA \\(100 \\times (1-\\alpha)\\)% high posterior density (HPD) region is a set \\(s(y) \\subset \\Theta\\) such that\n\n\\(p(\\theta \\in s(y) | Y = y) = 1 - \\alpha\\)\nIf \\(\\theta_a \\in s(y)\\) and \\(\\theta_b \\not\\in s(y)\\), then \\(p(\\theta_a | Y = y) > p(\\theta_b | Y = y)\\)\n\n\n\n\n\nExponential families\nIf density \\(p(y|\\theta)\\) can be written \\(h(y) c(\\phi) e^{\\phi t(y)}\\) for some transform \\(\\phi = f(\\theta)\\) we can say \\(p(y|\\theta)\\) belongs in the exponential family, and the conjugate prior is \\(p(\\phi | n_0, t_0) =c(\\phi)^{n_0} e^{n_0 t_0 \\phi}\\). Note: the conjugate prior is given over \\(\\phi\\) and we’d have to transform back if we care about \\(p(\\theta)\\)."
  },
  {
    "objectID": "chapterSummaries.html#chapter-4",
    "href": "chapterSummaries.html#chapter-4",
    "title": "Chapter summaries",
    "section": "Chapter 4",
    "text": "Chapter 4\n\nPredictive distributions\nThe posterior predictive distribution,\n\\[\np(\\tilde{y} | y_1, \\ldots y_n) = \\int p(\\tilde{y}|\\theta) p(\\theta|y_1, \\ldots, y_n)d\\theta\n\\]\nwhen \\(Y | \\theta\\) conditionally iid.\nThe prior predictive distribution,\n\\[\np(\\tilde{y}) = \\int p(\\tilde{y}|\\theta) p(\\theta)d\\theta.\n\\]\nNotice both the posterior and prior predictive distributions are represented as integrals. Integrals are expectations. This means we can use Monte Carlo integration to approximate.\nTo approximate the posterior predictive distribution:\n\nsample from the posterior of theta, \\(p(\\theta|y_1,\\ldots y_n)\\)\nsample from data generative model \\(p(\\tilde{y}|\\theta)\\) for the values of theta sampled in (1).\n\nTo approximate the prior predictive distribution:\n\nsample from the prior of theta, \\(p(\\theta)\\)\nsample from the data generative model \\(p(\\tilde{y}|\\theta)\\) for the values of theta sampled in (1).\n\n\n\nMonte Carlo error\nSince Monte Carlo approximation can be viewed as a sample mean approximating an expected value, CLT applies.\nMore specifically, if \\(\\theta_i |\\vec{y}\\) iid with mean \\(\\theta\\) and finite variance \\(\\sigma^2\\), for \\(i \\in \\{1, \\ldots, N\\}\\), then the sample mean\n\\[\n\\bar{\\theta} \\sim N(\\theta, \\frac{\\sigma^2}{N} ).\n\\]\nand Monte Carlo estimates converge at a rate \\(\\mathcal{O}\\left(\\frac{1}{\\sqrt{N}}\\right)\\) regardless of the dimension of the integral!\n\n\nThe sampling view\nIf we have a posterior \\(p(\\theta | y_1, \\ldots y_n)\\) that we can sample from and we want some summary of the posterior… e.g. we want\n\n\\(p(\\theta < a)\\)\nquantiles of the posterior , or\nthe posterior of some transform \\(f(\\theta)\\),\n\nthen we can simply sample from the posterior to obtain an empirical approximation of the posterior and then report the empirical quantity of interest. This is also called Monte Carlo approximation.\nThe procedure can be written:\n\nsample from the posterior \\(p(\\theta |y_1, \\ldots y_n)\\) some large number of times and then\ncompute the quantity of interest"
  },
  {
    "objectID": "hw/hw04.html",
    "href": "hw/hw04.html",
    "title": "Homework 4",
    "section": "",
    "text": "Let\n\\[\n\\begin{aligned}\nY | \\theta, \\sigma^2 &\\sim N(\\theta, 1/\\gamma)\\\\\n\\theta | \\sigma^2 &\\sim N(\\mu_0, 1/\\gamma \\kappa_0)\\\\\n\\gamma &\\sim \\text{gamma}(a, b)\n\\end{aligned}\n\\]\nso \\(\\gamma\\) is the precision (inverse-variance) of the normal distribution.\n\nDerive and simplify the joint pdf \\(p(y_1, \\ldots y_n | \\theta, \\gamma)\\)\nDerive the posterior of the precision, \\(p(\\gamma| y_1, \\ldots y_n)\\).\nDerive the posterior of \\(\\theta\\), \\(p(\\theta | y_1, \\ldots y_n)\\)"
  },
  {
    "objectID": "hw/hw04.html#exercise-2",
    "href": "hw/hw04.html#exercise-2",
    "title": "Homework 4",
    "section": "Exercise 2",
    "text": "Exercise 2\nExercise 5.1 from Hoff. You can read in the data from the three schools with the R code below. Hint: the problem specification is the same as exercise 1, except \\(a = \\nu_0/2\\) and \\(b = \\nu_0 \\sigma_0^2/2\\).\n\nlibrary(tidyverse)\nschool1 = read_csv(\"https://sta360-fa23.github.io/data/school1.csv\")\nschool2 = read_csv(\"https://sta360-fa23.github.io/data/school2.csv\")\nschool3 = read_csv(\"https://sta360-fa23.github.io/data/school3.csv\")"
  },
  {
    "objectID": "notes/normalModel1.html#sampling-from-the-joint-posterior",
    "href": "notes/normalModel1.html#sampling-from-the-joint-posterior",
    "title": "The normal model",
    "section": "Sampling from the joint posterior",
    "text": "Sampling from the joint posterior\nSince \\(p(\\theta, \\sigma^2 | \\vec{y}) = p(\\theta | \\sigma^2, y_1, \\ldots, y_n)p(\\sigma^2|y_1, \\ldots y_n)\\), we can sample from the joint posterior by first sampling from \\(p(\\sigma^2|y_1, \\ldots y_n)\\) and then sampling from \\(p(\\theta | \\sigma^2, y_1, \\ldots, y_n)\\).\n\nExample\nProof of concept\nWe have some data:\n\n# generating 10 samples from the population\nset.seed(123)\ntrue.theta = 4\ntrue.sigma = 1\ny = rnorm(1000, true.theta, true.sigma)\n\nybar = mean(y) # sample mean\nn = length(y) # sample size\ns2 = var(y) # sample variance\n\nWe make inference about \\(\\theta\\) and \\(\\sigma^2\\):\n\n# priors\n# theta prior\nmu_0 = 2; k_0 = 1\n# sigma2 prior\nnu_0 = 1; s2_0 = 0.010\n\n# posterior parameters\nkn = k_0 + n\nnun = nu_0 + n\nmun = (k_0 * mu_0 + n * ybar) /kn\ns2n = (nu_0 * s2_0 + (n - 1) * s2 + k_0 * n * (ybar - mu_0)^2 / (kn)) / (nun)\n\ns2.postsample = 1 / rgamma(10000, nun / 2, s2n * nun / 2)\ntheta.postsample = rnorm(10000, mun, sqrt(s2.postsample / kn))\n\ndf = data.frame(theta.postsample, s2.postsample)\n\ndf %>%\n  ggplot(aes(x = theta.postsample, y = s2.postsample)) +\n  stat_density_2d(aes(fill = ..level..), geom = \"polygon\") +\n  labs(x = TeX(\"$\\\\theta$\"),\n       y = TeX(\"$\\\\sigma^2$\"),\n       fill = TeX(\"$p(\\\\theta, \\\\sigma^2 | y_1, \\\\ldots y_n)$\")) +\n  theme_bw()"
  },
  {
    "objectID": "hw/hw04.html#exercise-3",
    "href": "hw/hw04.html#exercise-3",
    "title": "Homework 4",
    "section": "Exercise 3",
    "text": "Exercise 3\n3.12 from Hoff."
  },
  {
    "objectID": "notes/lec01-probability.html",
    "href": "notes/lec01-probability.html",
    "title": "Probability",
    "section": "",
    "text": "This is foundational material. Most of it is background you will have learned in STA230/240. While dry, we must soldier on to get to the exciting stuff."
  },
  {
    "objectID": "notes/lec01-probability.html#review-set-theory",
    "href": "notes/lec01-probability.html#review-set-theory",
    "title": "Probability",
    "section": "Review: set theory",
    "text": "Review: set theory\n\n\n\n\n\n\nDefinition\n\n\n\nset: a collection of elements, denoted by {}\nExamples\n\n\\(\\phi\\) = {} “the empty set”\nA = {1, 2, 3}\nB = {taken STA199, has not taken STA199}\nC = {{1,2,3}, {4, 5}}\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nsubset: denoted by \\(\\subset\\), \\(A \\subset B\\) iff \\(a \\in A \\implies a \\in B\\)\nExamples\nUsing the previously examples of A, B and C above,\n\n\\(A \\subset C\\)\n\\(A \\not\\subset B\\)\n\n\n\nRecall:\n\n\\(\\cup\\) means “union”, “or”\n\\(\\cap\\) means “intersection”, “and”\n\n\n\n\n\n\n\nDefinition\n\n\n\npartition: {\\(H_1, H_2, ... H_n\\)} = \\(\\{H_i\\}_{i = 1}^n\\) is a partition of \\(\\mathcal{H}\\) if\n\nthe union of sets is \\(\\mathcal{H}\\) i.e. \\(\\cup_{i = 1}^n H_i = \\mathcal{H}\\)\nthe sets are disjoint i.e. \\(H_i \\cap H_j = \\phi\\) for all \\(i \\neq j\\)\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nsample space: \\(\\mathcal{H}\\), the set of all possible data sets (outcomes)\nevent: a set of one or more outcomes\nNote: p(\\(\\mathcal{H}\\)) = 1\nExamples\n\nRoll a six-sided die once. The sample space \\(\\mathcal{H} = \\{1, 2, 3, 4, 5, 6\\}\\).\nLet \\(A\\) be the event that the die lands on an even number. \\(A = \\{2, 4, 6 \\}\\)"
  },
  {
    "objectID": "notes/lec01-probability.html#axioms-of-probability-in-words",
    "href": "notes/lec01-probability.html#axioms-of-probability-in-words",
    "title": "Probability",
    "section": "Axioms of probability (in words)",
    "text": "Axioms of probability (in words)\nP1. Probabilities are between 0 and 1, importantly p(\\(\\neg\\)H|H) = 0 and p(H|H) = 1.\nP2. If two events A and B are disjoint, then p(A or B) = p(A) + p(B)\nP3. The joint probability of two events may be broken down stepwise: p(A,B) = p(A|B)p(B)\n–\nIt follows that\n\nfor any partition \\(\\{H_i\\}_{i = 1}^n\\), \\(\\sum_{i=1}^n p(H_i) = 1\\) (rule of total probability)\n\nnote: simplest partition \\(p(A) + p(\\neg A) = 1\\)\n\n\\(p(A) = \\sum_{i=1}^n p(A, H_i)\\) (rule of marginal probability)\n\nnote: P3 implies that equivalently, \\(p(A) = \\sum_{i=1}^n p(A | H_i) p(H_i)\\)\n\np(A|B) = p(A,B) / p(B) when p(B) \\(\\neq 0\\)\n\nnote: these statements can also be made where each term is additionally conditioned on another event C\n\n\n\n\n\n\n\n\nExercise\n\n\n\nDerive Bayes’ rule:\n\\(p(H_i|X) = \\frac{p(X|H_i)p(H_i)}{\\sum_k p(X|H_k)p(H_k)}\\)\nusing the axioms of probability.\n\n\nBayes’ rule tells us how to update beliefs about \\(\\{H_i \\}_{i = 1}^n\\) given data \\(X\\)."
  },
  {
    "objectID": "notes/lec01-probability.html#independence",
    "href": "notes/lec01-probability.html#independence",
    "title": "Probability",
    "section": "Independence",
    "text": "Independence\n\n\n\n\n\n\nDefinition\n\n\n\nTwo events \\(F\\) and \\(G\\) are conditionally independent given \\(H\\) if \\(p(F, G | H) = p(F | H) p(G | H)\\)\n\n\n\n\n\n\n\n\nExercise\n\n\n\nShow conditional independence implies\n\\(p(F | H, G) = p(F | H)\\)\n\n\nThis means that if we know H, then G does not supply any additional information about F."
  },
  {
    "objectID": "notes/lec01-probability.html#random-variables",
    "href": "notes/lec01-probability.html#random-variables",
    "title": "Probability",
    "section": "Random variables",
    "text": "Random variables\n\n\n\n\n\n\nDefinition\n\n\n\nIn Bayesian inference, a random variable is an unknown numerical quantity about which we make probability statements.\nExamples\n\nData. E.g. the amount of a wheat a field will yield later this year. Since this data has not yet been generated, the quantity is unknown.\nA population parameter. E.g. the true mean resting heart rate of Duke students. Note: this is a fixed (non-random) quantity, but it is also unknown. We use probability to describe our uncertainty in this quantity.\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\ndiscrete random variable: a random variable that takes countably many values. Y is discrete if its possible outcomes can be enumerated \\(\\mathcal{Y} = \\{y_1, y_2, \\ldots \\}\\).\nNote: discrete does not mean finite. There may be infinitely many outcomes!\nExamples\n\nY = the number of children of a randomly sampled person\nY = the number of visible stars in the sky on a randomly sampled night of the year\n\nFor each \\(y \\in \\mathcal{Y}\\), let p(Y) = probability(Y = y). Then p is the probability mass function (pmf) of the random variable Y.\nExamples\n\nBinomial pmf: the probability of \\(y\\) successes in \\(n\\) trials, where each trial has an individual probability of success \\(\\theta\\).\n\\[p(y | \\theta) = {n \\choose y} \\theta ^y (1-\\theta)^y \\text{ for } y \\in \\{0, 1, \\ldots n \\}\\]\n\nsupport: \\(y \\in \\{0, 1, 2, \\ldots n\\}\\)\nsuccess probability \\(\\theta \\in [0, 1]\\)\ndbinom(y, n, theta) computes this pmf in R\n\nPoisson pmf: probability of \\(y\\) events occurring during a fixed interval at a mean rate \\(\\theta\\)\n\\[p(y | \\theta) = \\frac{\\theta^y e^{-\\theta}}{y!}\\]\n\nsupport: \\(y \\in \\{0, 1, 2, \\ldots \\}\\)\nrate \\(\\theta \\in \\mathbb{R}^+\\)\ndpois(y, theta) computes this pmf in R\n\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\ncontinuous random variable: a random variable that takes uncountably many values.\nThe probability density function (pdf) of a continuous random variable, X is defined\n\\(pdf(x) = \\lim_{\\Delta x \\rightarrow 0} \\frac{p(x < X < x + \\Delta x)}{\\Delta x}\\)\nand the probability X is in some interval,\n\\(p(x_1 < X < x_2) = \\int_{x_1}^{x_2} pdf(x) dx\\)\nExamples\n\nNormal pdf \\[\np(x | \\mu, \\sigma) = (2\\pi \\sigma^2)^{-\\frac{1}{2}}e^{-\\frac{1}{2\\sigma^2}(x-\\mu)^2}\n\\]\nUniform pdf \\[p(x|a,b) =\n\\begin{cases}\n\\frac{1}{b - a} \\hspace{.6cm}\\text{ for } x \\in [a, b]\\\\\n0 \\hspace{1cm}\\text{ otherwise }\n\\end{cases}\\]\n\n\n\nNote: we will often abuse notation and use \\(p(x)\\) in place of \\(pmf(x)\\) and \\(pdf(x)\\) and prob(event), where only the context makes meaning clear.\nFor pmfs\n\\[\n\\begin{aligned}\n0 \\leq p(y) \\leq 1\\\\\n\\sum_{y \\in \\mathcal{Y}} p(y) = 1\n\\end{aligned}\n\\]\nSimilarly, for pdfs,\n\\[\n\\begin{aligned}\n0 \\leq p(y) \\ \\text{and} \\\\\n\\int_{y \\in \\mathcal{Y}} p(y) = 1\n\\end{aligned}\n\\]\nNote: For a continuous random variable Y, p(y) can be larger than 1 and p(y) is not p(Y = y), which equals 0.\n\n\n\n\n\n\nDefinition\n\n\n\nThe part of the density/mass function that depends on the variable is called the kernel.\nExample\n\nthe kernel of the normal pdf is \\(e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\\)\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nWhat’s the kernel of a gamma random variable X?\nRecall: the pdf of a gamma distribution:\n\\[\np(x | \\alpha, \\beta) = \\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)}x^{\\alpha - 1} e^{-\\beta x}\n\\]"
  },
  {
    "objectID": "notes/lec01-probability.html#moments",
    "href": "notes/lec01-probability.html#moments",
    "title": "Probability",
    "section": "Moments",
    "text": "Moments\nFor a random variable X, the \\(n\\)th moment is defined as E(\\(X^n\\)).\nRecall, the expected value is defined for discrete random variable X,\n\\[\nE(X) = \\sum_{x \\in \\mathcal{X}} x p(x)\n\\]\nand for continuous random variable Y,\n\\[\nE(Y) = \\int_{-\\infty}^{\\infty} y p(y) dy\n\\]\nThe variance of a random variable, is also known as the second central moment and is defined\n\\[\nE(X - E(X))^2\n\\] or equivalently,\n\\[\nE(X^2) - E(X)^2\n\\]\nMore generally, the covariance between two random variables X and Y is defined\n\\[\nE[(X - E[X])(Y - E[Y])]\n\\]"
  },
  {
    "objectID": "notes/lec01-probability.html#exchangeability",
    "href": "notes/lec01-probability.html#exchangeability",
    "title": "Probability",
    "section": "Exchangeability",
    "text": "Exchangeability\n\noffline notes"
  },
  {
    "objectID": "notes/lec02-estimation.html",
    "href": "notes/lec02-estimation.html",
    "title": "Is this a fair coin?",
    "section": "",
    "text": "outputcode\n\n\n\n\n [1] 0 1 0 0 0 0 0 0 0 0\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(latex2exp)\nlibrary(glue)\nlibrary(patchwork)\n\nset.seed(3)\nflips = rbinom(5000, size = 1, prob = 0.25)\nflips %>% head(10)\nWe observe 10 flips from the same coin above, where 0 is “tails” and 1 is “heads”. In summary, we see Y = 1 heads in 10 coin flips. Is this a fair coin?\nTo articulate this mathematically, let \\(\\theta \\in [0, 1]\\) be the bias-weighting (the chance of heads) of the coin. Fundamentally, we want \\(p(\\theta | y)\\), which we can expand via Bayes’ rule,\n\\[\np(\\theta | y) = \\frac{p(y|\\theta) p(\\theta)}{\\int_{\\theta \\in \\Theta} p(y|\\theta) p(\\theta) d\\theta}\n\\]\nLikelihood: the data generative process. The joint probability (or density) of the data given the parameters of the model. Most often thought of as a function of the parameter. Note: not a density of the parameter.\nPrior: Our a priori (beforehand) beliefs about the true population characteristics.\nPosterior: Our a posteriori (afterwards) beliefs about the true population characteristics after having observed the data set \\(y\\).\nNormalizing constant: A number that enables a pmf or pdf to integrate to 1."
  },
  {
    "objectID": "notes/lec02-estimation.html#uniform-prior",
    "href": "notes/lec02-estimation.html#uniform-prior",
    "title": "Is this a fair coin?",
    "section": "Uniform prior",
    "text": "Uniform prior\nLet \\(y\\) be the number of heads in \\(n\\) coin flips.\n\\[\np(\\theta | y) \\propto \\theta^{y}(1-\\theta)^{n-y}\n\\]\nThis is the kernel of a ___ density, where \\(\\alpha = y + 1\\) and \\(\\beta = n - y + 1\\), hence\n\\[\np(\\theta | y) = \\frac{\\Gamma(n + 2)}{\\Gamma(y + 1)\\Gamma(n-y+1)} \\theta^{y}(1-\\theta)^{n-y}\n\\]\nand the posterior mean is \\(\\frac{y + 1}{n + 2}\\) and the posterior variance is \\(\\frac{(y+1)(n - y + 1)}{(n + 2)^2 (n + 1)}\\).\nLet’s examine how the posterior evolves with each successive coin flip.\n\nplotscode\n\n\n\n\n\n\n\n\n\n\nN = c(0, 1, 2, 3, 4, 10, 100, 1000, 5000)\n\nfor (i in seq_along(N)) {\nn = N[i]\nif(n == 0) {\n  y = 0\n}\nelse {\n  y = sum(flips[1:n])\n}\n\nx = 0:1 # range\ndf = data.frame(x)\nassign(paste0(\"p\", i),\n  df %>%\n  ggplot(aes(x = x)) +\n  stat_function(fun=dbeta, \n                args = list(shape1 = y + 1, shape2 = n - y + 1)) +\n  labs(y = TeX(\"$p(\\\\theta | y)$\"), x = TeX(\"$\\\\theta$\"),\n       title = glue(\"n = {n}\")) +\n  theme_bw()\n)\n}\n\n(p1 + p2 + p3) / \n  (p4 + p5 + p6) / \n  (p7 + p8 + p9) +\n  plot_annotation(title = \"Figure 1\")"
  },
  {
    "objectID": "notes/lec02-estimation.html#conjugacy",
    "href": "notes/lec02-estimation.html#conjugacy",
    "title": "Is this a fair coin?",
    "section": "Conjugacy",
    "text": "Conjugacy\nIf \\(\\theta \\sim\\) Uniform(0, 1) then \\(p(\\theta)\\) = 1 for all \\(\\theta \\in [0, 1]\\).\nSimilarly, if \\(\\theta \\sim\\) beta(1, 1), then \\(p(\\theta) = 1\\).\nClaim:\nIf\n\\[\n\\begin{aligned}\n\\theta &\\sim \\text{beta}(a, b)\\\\\nY | \\theta &\\sim \\text{binomial}(n, \\theta)\n\\end{aligned}\n\\]\nthen\n\\[\np(\\theta | Y) = \\text{beta}(y + a, n - y + b)\n\\]\n\n\n\n\n\n\nDefinition\n\n\n\nA prior \\(p(\\theta)\\) is said to be conjugate to the data generative model \\(p(y|\\theta)\\) if the family of the posterior is necessarily in the same family as the prior. In math, \\(p(\\theta)\\) is conjugate to \\(p(y|\\theta)\\) if\n\\[\np(\\theta) \\in \\mathcal{P} \\implies p(\\theta | y) \\in \\mathcal{P}\n\\]\n\n\nWhile conjugate priors make calculation easy, they may not accurately reflect our prior beliefs.\n\n\n\n\n\n\nExercise\n\n\n\nProve the claim above."
  },
  {
    "objectID": "notes/lec02-estimation.html#other-priors",
    "href": "notes/lec02-estimation.html#other-priors",
    "title": "Is this a fair coin?",
    "section": "Other priors",
    "text": "Other priors\nIncidentally, people are often satisfied with the choice of likelihood but are worried about the choice of prior.\nLet’s examine the effect of another couple of priors.\nGiven the coin’s dubious origin, we might believe a priori that the coin is biased. How could we represent this belief?\n\\[\n\\theta \\sim \\text{beta}(.5, .5)\n\\]\nOr alternatively, we might be strongly believe a priori that the coin is fair. How could we represent this belief?\n\\[\n\\theta \\sim \\text{beta}(20, 20)\n\\]\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nHow would you update the code of the previous example to show posterior inference under the prior \\(\\theta \\sim\\) beta(2,3)?"
  },
  {
    "objectID": "notes/lec02-estimation.html#prior-data",
    "href": "notes/lec02-estimation.html#prior-data",
    "title": "Is this a fair coin?",
    "section": "Prior data",
    "text": "Prior data\nIn the example above, the parameters, a and b, of the conjugate prior are often thought of as prior data.\n\na: “prior number of 1s”\nb: “prior number of 0s”\na + b: “prior sample size”\n\n\n\n\n\n\n\nExercise\n\n\n\nWe saw above that when a = 20 and b = 20, we needed more data to move the posterior.\nShow that the posterior mean, \\(E(\\theta | y) = \\frac{a + y}{a + b + n}\\) converges to the sample average as \\(n \\rightarrow \\infty\\)."
  },
  {
    "objectID": "notes/lec03-reliability.html",
    "href": "notes/lec03-reliability.html",
    "title": "Posterior summaries and reliability",
    "section": "",
    "text": "Posterior mode: sometimes called “MAP” or “maximum a posteriori” estimate, this quantity is given by \\(\\hat{\\theta} = \\arg \\max_{\\theta} p(\\theta | y)\\).\n\nNotice this unwinds to be \\(\\hat{\\theta} = \\arg \\max_{\\theta} p(y | \\theta) p(\\theta)\\).\n\n\n\n\n\n\n\nExercise\n\n\n\n\nShow that, for the uniform prior, \\(\\hat{\\theta} = y / n\\)\nCompare to maximum likelihood estimate (MLE); see notes on likelihoods\n\n\n\nOne way to report the reliability of the posterior mode is to look at the width of the posterior near the mode, which we can sometimes approximate with a Gaussian distribution:\n\\[\np(\\theta | y) \\approx C e^{\\frac{1}{2} \\frac{d^2L}{d\\theta^2}|_{\\hat{\\theta}} (\\theta - \\hat{\\theta})^2}\n\\]\nwhere \\(C\\) is a normalization constant and \\(L\\) is the log-posterior, \\(\\log p(\\theta | y)\\).\nTaken together, the fitted Gaussian with a mean equal to the posterior mode is called the Laplace approximation.\n\nLet’s derive the Laplace approximation offline"
  },
  {
    "objectID": "notes/lec03-reliability.html#confidence-regions",
    "href": "notes/lec03-reliability.html#confidence-regions",
    "title": "Posterior summaries and reliability",
    "section": "Confidence regions",
    "text": "Confidence regions\n\n\n\n\n\n\nDefinition\n\n\n\nLet \\(\\Phi\\) be the support of \\(\\theta\\). An interval \\((l(y), u(y)) \\subset \\Phi\\) has 95% posterior coverage if\n\\[\np(l(y) < \\theta < u(y) | y ) = 0.95\n\\]\nInterpretation: after observing \\(Y = y\\), our probability that \\(\\theta \\in (l(y), u(y))\\) is 95%.\nSuch an interval is called 95% posterior confidence interval (CI). It may also sometimes be referred to as a 95% “credible interval” to distinguish it from a frequentist CI.\n\n\nContrast posterior coverage to frequentist coverage:\n\n\n\n\n\n\nDefinition\n\n\n\nA random interval \\((l(Y), u(Y)\\)) has 95% frequentist coverage for \\(\\theta\\) if before data are observed,\n\\[\np(l(Y) < \\theta < u(Y) | \\theta) = 0.95\n\\]\nInterpretation: if \\(Y \\sim P_\\theta\\) then the probability that \\((l(Y), u(Y)\\) will cover \\(\\theta\\) is 0.95.\n\n\nIn practice, for many applied problems\n\\[\np(l(y) < \\theta < u(y) | y ) \\approx p(l(Y) < \\theta < u(Y) | \\theta)\n\\]\nsee section 3.1.2. in the book."
  },
  {
    "objectID": "notes/lec03-reliability.html#high-posterior-density",
    "href": "notes/lec03-reliability.html#high-posterior-density",
    "title": "Posterior summaries and reliability",
    "section": "High posterior density",
    "text": "High posterior density\n\n\n\n\n\n\nDefinition\n\n\n\nA \\(100 \\times (1-\\alpha)\\)% high posterior density (HPD) region is a set \\(s(y) \\subset \\Theta\\) such that\n\n\\(p(\\theta \\in s(y) | Y = y) = 1 - \\alpha\\)\nIf \\(\\theta_a \\in s(y)\\) and \\(\\theta_b \\not\\in s(y)\\), then \\(p(\\theta_a | Y = y) > p(\\theta_b | Y = y)\\)\n\n\n\n\nNote: all points inside an HPD region have higher posterior density than points outside the region.\n\n\n\n\n\n\n\nExercise\n\n\n\nIs the HPD region always an interval?"
  },
  {
    "objectID": "notes/lec05-MonteCarlo.html",
    "href": "notes/lec05-MonteCarlo.html",
    "title": "Monte Carlo Integration",
    "section": "",
    "text": "# load packages\nlibrary(tidyverse)\nlibrary(latex2exp)"
  },
  {
    "objectID": "notes/lec05-MonteCarlo.html#monte-carlo-error",
    "href": "notes/lec05-MonteCarlo.html#monte-carlo-error",
    "title": "Monte Carlo Integration",
    "section": "Monte Carlo error",
    "text": "Monte Carlo error\n\nHow many values should we simulate?\nRecall: expected values are integrals, and integrals are expected values. Since central limit theorem (CLT) deals with expected values…\nRecall: CLT states that if \\(\\theta_i |\\vec{y}\\) iid with mean \\(\\theta\\) and finite variance \\(\\sigma^2\\), for \\(i \\in \\{1, \\ldots, N\\}\\), then the sample mean\n\\[\n\\bar{\\theta} \\sim N(\\theta, \\frac{\\sigma^2}{N} ).\n\\]\n\nHow to remember this/show this? Offline notes.\n\nSo to estimate \\(\\theta\\), we can generate \\(\\bar{\\theta}\\) by Monte Carlo simulation and report a confidence interval using quantiles of the normal given above in conjunction with the Monte Carlo standard error \\(\\frac{\\hat{\\sigma}}{\\sqrt{N}}\\)\nThis means we get convergence at the rate \\(\\mathcal{O}\\left(\\frac{1}{\\sqrt{N}}\\right)\\) regardless of the dimension of the integral!\nRecall:\n\nsd1 = pnorm(1) - pnorm(-1)\nsd2 = pnorm(2) - pnorm(-2)\nsd3 = pnorm(3) - pnorm(-3)\n\n\na 0.6826895% confidence interval can be obtained using \\(\\pm 1\\cdot \\hat{\\sigma}/\\sqrt{N}\\)\na 0.9544997% confidence interval can be obtained using \\(\\pm 2\\cdot \\hat{\\sigma}/\\sqrt{N}\\)\na 0.9973002% confidence interval can be obtained using \\(\\pm 3\\cdot \\hat{\\sigma}/\\sqrt{N}\\)\n\n\n\nExample\n\n# Let theta be \"x\" in the code below\nset.seed(123)\n\n# binomial(n, p)\nn = 20\np = 0.4\n\n# mean, variance, sd of a binomial(n, p)\nEX = n*p # 20*.4 = 8\nVarX = n*p*(1-p) # 20*.4*.6 = 4.8\nsdX = sqrt(VarX) # 2.19089\n\n# Monte Carlo sample of size N\nN = 100\nxSamples = rbinom(N, size = n, prob = p) \n\n# sample mean, var, sd\nxbar = mean(xSamples)\nxvar = var(xSamples)\nxsigma = sd(xSamples) # = sqrt(sum((xSamples - xbar)^2) / (N -1))\n\nse = xsigma / sqrt(N)\n\nlb = round(xbar - (2*se), 3)\nub = round(xbar + (2*se), 3)\n\nFor N = 100 Monte Carlo samples, The posterior mean of \\(\\theta\\) is \\(\\bar{\\theta} =\\) 8.01 with 95% confidence interval (7.57 8.45).\n\n\n\n\n\n\nExercise\n\n\n\nAbove we estimate \\(Var(\\theta)\\) to be 4.838 and the standard error for \\(N = 100\\) was 0.22.\nIf you wanted to state \\(p(\\theta \\in (\\hat{\\theta} \\pm 0.01)) = 0.95\\), how large would \\(N\\) have to be?\nCheck your answer by adjusting \\(N\\) above."
  },
  {
    "objectID": "notes/lec05-MonteCarlo.html#monte-carlo-prediction",
    "href": "notes/lec05-MonteCarlo.html#monte-carlo-prediction",
    "title": "Monte Carlo Integration",
    "section": "Monte Carlo prediction",
    "text": "Monte Carlo prediction\n\nPrior predictive distribution\nWe can use Monte Carlo to sample new observation, \\(\\tilde{y}\\), from the prior predictive distribution\n\\[\np(\\tilde{y}) = \\int p(\\tilde{y}|\\theta)p(\\theta) d\\theta,\n\\]\nwhere we proceed by following the iterative procedure below\n1. sample theta_i from the prior p(theta)\n2. sample ytilde from p(ytilde | theta_i)\n3. repeat steps 1 and 2\n\nthis can be useful to see if a prior for \\(p(\\theta)\\) actually translate to reasonable prior beliefs about the data.\n\n\n\n\n\n\n\nExercise\n\n\n\nFor \\(p(\\theta) = \\text{gamma}(8,2)\\), plot \\(p(\\tilde{y})\\) assuming \\(\\tilde{y} | \\theta \\sim \\text{Poisson}(\\theta)\\).\n\n\n\n\n\n\n\nPosterior predictive distribution\nWe can also sample \\(\\tilde{y}\\) from the posterior predictive distribution,\n\\[\np(\\tilde{y} | y_1, \\ldots y_n) = \\int p(\\tilde{y}|\\theta) p(\\theta|y_1, \\ldots, y_n)d\\theta,\n\\]\nwhere the procedure is the same as before, except step 1 is replace with sampling \\(\\theta\\) from the posterior \\(p(\\theta | y_1,\\ldots, y_n)\\).\nThe resulting sequence \\((\\theta^{(1)}, \\tilde{y}^{(1)}), \\ldots, (\\theta^{(N)}, \\tilde{y}^{(N)})\\) constitutes \\(N\\) independent samples from the joint posterior of \\((\\theta, \\tilde{Y})\\). The sequence \\(\\tilde{y}^{(1)}, \\ldots, \\tilde{y}^{(N)})\\) constitutes \\(N\\) independent samples from the marginal posterior distribution of \\(\\tilde{Y}\\), aka the posterior predictive distribution."
  },
  {
    "objectID": "notes/lec05-MonteCarlo.html#posterior-predictive-model-checking",
    "href": "notes/lec05-MonteCarlo.html#posterior-predictive-model-checking",
    "title": "Monte Carlo Integration",
    "section": "Posterior predictive model checking",
    "text": "Posterior predictive model checking\nWe can assess the fit of a model by comparing the posterior predictive distribution to the empirical distribution.\n\nExample: is our Poisson model flawed?\n\n# load general social survey data\ngss = read_csv(\"https://sta360-fa23.github.io/data/gss.csv\")\n\n\ny1 = gss$CHILDS[gss$FEMALE == 1 &  gss$YEAR >= 1990  & gss$AGE == 40 & \n                   gss$DEGREE < 3 ]\ny1 = y1[!is.na(y1)]\nn = length(y1)\n\nWe are examining the number of children \\(Y_i\\) belonging to \\(n=\\) 111 40 year old women surveyed 1990 or later without a bachelor’s. These data come from the general social survey.\nSuppose\n\\[\n\\begin{aligned}\nY_i & \\sim \\text{Poisson}(\\theta)\\\\\n\\theta & \\sim \\text{gamma}(2, 1).\n\\end{aligned}\n\\]\nThe empirical and predictive distributions of the data are both plotted below.\n\nplotcode\n\n\n\n\n\n\n\n\n\n\nset.seed(123)\n\n# posterior predictive distribution\nytotal = sum(y1)\na = 2 ; b = 1\nN = 10000\ntheta.post.mc = rgamma(N, ytotal + a, b + n)\ny1.mc = rpois(N, theta.post.mc)\n\n# data\ndf = data.frame(y1) # empirical\ndf2 = data.frame(y1.mc) # post predictive\n  \n# make plot\ndf %>%\n  ggplot(aes(x = y1)) +\n  geom_bar(aes(x = y1 + .15, y = (..count..)/sum(..count..),\n               fill = \"empirical\"), alpha = 0.6, width = 0.3) +\n  geom_bar(data = df2, \n                 aes(x = y1.mc -.15, y = (..count..) / sum(..count..),\n                     fill = \"predictive\"), alpha = 0.4, width = 0.3) +\n  labs(x = \"number of children\", \n       y = TeX(\"$p(Y_i = y_i)$\"),\n       fill = \"\") +\n  scale_x_continuous(breaks = c(0:7), labels = c(0:7),\n                     limits = c(-.5,7.5)) +\n  \n  theme_bw()\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nLet \\(\\mathbf{y}\\) be a vector of length 111. Let \\(t(\\mathbf{y})\\) be the ratio of \\(2\\)s to \\(1\\)s in \\(\\mathbf{y}\\). For our observed data, this test statistic \\(t(\\mathbf{y}_{obs}) = 38 / 19 = 2\\). What is the tail probability \\(p(t(\\tilde{\\mathbf{Y}}) \\geq t(\\mathbf{y}_{obs}))\\) under the posterior predictive distribution?"
  },
  {
    "objectID": "notes/lec04-prediction.html",
    "href": "notes/lec04-prediction.html",
    "title": "Prediction & Intro to Monte Carlo",
    "section": "",
    "text": "Load packages:"
  },
  {
    "objectID": "notes/lec04-prediction.html#prediction-example",
    "href": "notes/lec04-prediction.html#prediction-example",
    "title": "Prediction & Intro to Monte Carlo",
    "section": "Prediction example",
    "text": "Prediction example\nGeneral social survey (1998)\nSetup:\n\nSuppose \\(X_i = 1\\) if the ith person is happy. \\(X_i = 0\\) otherwise.\nLet \\(Y = \\sum_{i = 1}^{n} X_i\\), where \\(n\\) is the number of people sampled.\n\\(Y_i | \\theta \\sim \\text{binomial}(\\theta)\\) for some fixed \\(n\\).\n\\(\\theta \\sim \\text{uniform}(0, 1)\\)\n\nScenario: We sample \\(n = 10\\) people. \\(y = 6\\) are happy. If we sample another \\(n = 10\\), what is the probability that \\(\\tilde{y}\\) are happy?\nWe fundamentally want the posterior predictive distribution, \\(p(\\tilde{y} | y)\\).\nFollowing the offline notes, and given conditional independence, we want\n\n\n\n\n\n\\[\n\\begin{aligned}\n\\int p(\\tilde{y} | \\theta) p(\\theta | y) d\\theta\n&=\n\\int {n \\choose \\tilde{y}}\n(\\theta)^\\tilde{y} (1-\\theta)^{n-\\tilde{y}}\n\\cdot\n\\frac{1}{\\text{B(y + 1, n - y + 1)}}\\theta^{y}(1-\\theta)^{n-y}\nd\\theta\\\\\n&= {n \\choose \\tilde{y}} \\frac{1}{\\text{B(y + 1, n - y + 1)}} \\int \\theta^{\\tilde{y}+y} \\cdot\n(1-\\theta)^{(n-\\tilde{y}) + (n - y)} d\\theta\\\\\n&= {n \\choose \\tilde{y}}\n\\frac{\\text{B}(\\tilde{y} + y + 1, 2n - y - \\tilde{y} + 1)}{\\text{B(y + 1, n - y + 1)}}\n\\end{aligned}\n\\]\nwhere \\(B(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}\\). We can of course simplify, since this is really a bunch of factorials, but we can also naively use the beta() function in R and push forward.\n\nplotcode\n\n\n\n\n\n\n\n\n\n\ny = 6\nn = 10\n\n# posterior predictive probability of ytilde\nprobYT = function(ytilde) {\n  choose(n, ytilde) * \n    beta(ytilde + y + 1, (2*n) - y - ytilde + 1) / \n    beta(y + 1, n - y + 1)\n}\n\n# construct data frame\ndf = data.frame(ytilde = 0:10) %>%\n  mutate(postPredict = probYT(ytilde))\n\n# plot data frame\ndf %>%\n  ggplot(aes(x = ytilde, y = postPredict)) +\n  geom_bar(stat = 'identity') +\n  labs(x = TeX(\"$\\\\tilde{y}$\"), y = TeX(\"$p(\\\\tilde{y}|y)$\"),\n       title = \"Posterior predictive probability\") +\n  theme_bw()"
  },
  {
    "objectID": "notes/lec04-prediction.html#monte-carlo-motivation",
    "href": "notes/lec04-prediction.html#monte-carlo-motivation",
    "title": "Prediction & Intro to Monte Carlo",
    "section": "Monte Carlo motivation",
    "text": "Monte Carlo motivation\nGeneral social survey from the 90s gathered data on the number of children to women of two categories: those with and without a bachelor’s degree.\nSetup:\n\n\\(Y_{i1}\\): number of children of \\(i\\)th woman in group 1 (no bachelor’s)\n\\(Y_{i2}\\): number of children of \\(i\\)th woman in group 2 (bachelor’s)\n\nModel:\n\n\\(Y_{11}, \\ldots, Y_{n_1 1} | \\theta_1 \\overset{\\mathrm{iid}}{\\sim} \\text{Poisson}(\\theta_1)\\)\n\\(Y_{12} \\ldots, Y_{n_2 2} | \\theta_2 \\overset{\\mathrm{iid}}{\\sim} \\text{Poisson}(\\theta_2)\\)\n\nPrior:\n\n\\(\\theta_1 \\sim \\text{gamma}(2, 1)\\)\n\\(\\theta_2 \\sim \\text{gamma}(2, 1)\\)\n\nData:\n\n\\(n_1 = 111\\), \\(\\bar{y_1} = 1.95\\), \\(\\sum y_{i 1} = 217\\)\n\\(n_2 = 44\\), \\(\\bar{y_1} = 1.5\\), \\(\\sum y_{i 1} = 66\\)\n\nPosterior:\n\n\\(\\theta_1 | \\vec{y_1} \\sim \\text{gamma}(219, 112)\\)\n\\(\\theta_2 | \\vec{y_2} \\sim \\text{gamma}(68, 45)\\)\n\nWe already know how to compute\n\nposterior mean: \\(E~\\theta | y = \\alpha / \\beta\\) (shape, rate parameterization)\nposterior density (dgamma)\nposterior quantiles and confidence intervals (qgamma)\n\nWhat about…\n\n\\(p(\\theta \\in \\mathcal{A} | y)\\),\n\\(E~g(\\theta) | y\\),\n\\(Var~g(\\theta) | y\\)?\n\nWhat about posterior distribution of \\(|\\theta_1 - \\theta_2\\), \\(\\theta_1 / \\theta_2\\), \\(\\text{max} \\{\\theta_1, \\theta_2 \\}\\)?"
  },
  {
    "objectID": "notes/lec04-prediction.html#monte-carlo-integration",
    "href": "notes/lec04-prediction.html#monte-carlo-integration",
    "title": "Prediction & Intro to Monte Carlo",
    "section": "Monte Carlo integration",
    "text": "Monte Carlo integration\n\napproximates an integral by a stochastic average\nshines when other methods of integration are impossible (e.g. high dimensional integration)\nworks because of law of large numbers: for a random variable \\(X\\), the sample mean \\(\\bar{x}_N\\) converges to the true mean \\(\\mu\\) as the number of samples \\(N\\) tends to infinity.\n\nThe key idea is: we obtain independent samples from the posterior,\n\\[\n\\theta^{(1)}, \\ldots \\theta^{(N)} \\overset{\\mathrm{iid}}{\\sim} p(\\theta |\\vec{y})\n\\]\nthen the empirical distribution of the samples approximates the posterior (approximation improves as \\(N\\) increases).\nRecall\n\\[\nE~g(\\theta)|y = \\int_\\mathcal{\\theta} g(\\theta) f_\\theta(\\theta | y)dx \\approx \\frac{1}{N} \\sum_{i = 1}^N g(\\theta^{(i)})\n\\]\nwhere \\(f_x(x)\\) is the probability density function for a random variable \\(X\\).\nThe law of large numbers says that if our samples \\(\\theta^{(i)}\\) are independent, \\(\\frac{1}{N} \\sum_{i = 1}^N g(\\theta^{(i)})\\) to \\(E~\\theta|y\\).\n\n\n\n\n\n\nNote\n\n\n\nIntegrals are expectations, and expectations are integrals."
  },
  {
    "objectID": "notes/lec04-prediction.html#examples",
    "href": "notes/lec04-prediction.html#examples",
    "title": "Prediction & Intro to Monte Carlo",
    "section": "Examples",
    "text": "Examples\n\n\\(\\theta_1 | \\vec{y_1} \\sim \\text{gamma}(219, 112)\\)\n\\(\\theta_2 | \\vec{y_2} \\sim \\text{gamma}(68, 45)\\)\n\n\n(1) proof of concept: the mean\n\nset.seed(123)\nN = 5000\nrgamma(N, shape = 219, rate = 112) %>%\n  mean()\n\n[1] 1.95294\n\n\nPretty close to the true mean, 1.9553571.\n\n\n(2) posterior of \\(\\theta_1 - \\theta_2\\)\n\nset.seed(123)\ntheta1 = rgamma(N, shape = 219, rate = 112)\ntheta2 = rgamma(N, shape = 68, rate = 45)\n\ndf = data.frame(diff = theta1 - theta2)\n\ndf %>%\n  ggplot(aes(x = diff)) + \n  geom_density() +\n  theme_bw() +\n  labs(x = TeX(\"$\\\\theta_1 - \\\\theta_2$\"),\n       y = TeX(\"$p(\\\\theta_1 - \\\\theta_2 | {y}_1, {y}_2)$\"))\n\n\n\n\n\n\n(3) \\(p(\\theta_1 - \\theta_2> .5)\\)\n\nmean(df$diff > .5)\n\n[1] 0.4106\n\n\n\nExerciseFull solutionQuick Monte Carlo\n\n\n\n\n\n\n\n\nExercise\n\n\n\n\n\\(\\theta \\sim \\text{uniform}(0, 1)\\)\nLet \\(\\gamma = \\log \\theta\\)\nVisualize \\(p(\\gamma)\\) using Monte Carlo simulation, then show using the change of variables formula and plotting the closed form of the density.\n\n\n\n\n\n\n# sample from p(theta)\ntheta = runif(10000)\n\n# define transform function\nf = function(x) {\n  return(exp(x))\n}\n\n# create a df for each plot\ndf = data.frame(gamma = -7:0)\ndf2 = data.frame(gammaSamples = log(theta))\n\n# make plots\ndf %>%\n  ggplot(aes(x = gamma)) +\n  stat_function(fun = f, col = 'red', alpha = 0.5) +\n  geom_histogram(data = df2, aes(x = gammaSamples,\n                                 y = ..density..),\n               fill = 'steelblue', alpha = 0.5)\n\n\n\n\n\n\n\n# Just making the Monte Carlo part of the plot \n# in 3 lines\ntheta = runif(10000)\ngamma = log(theta)\nhist(gamma)"
  },
  {
    "objectID": "notes/lec06-normalModel.html",
    "href": "notes/lec06-normalModel.html",
    "title": "The normal model",
    "section": "",
    "text": "# load packages\nlibrary(tidyverse)\nlibrary(latex2exp)"
  },
  {
    "objectID": "notes/lec06-normalModel.html#background",
    "href": "notes/lec06-normalModel.html#background",
    "title": "The normal model",
    "section": "Background",
    "text": "Background\n\nDefinition and vocabulary\nLet \\(Y\\) be normally distributed with mean \\(\\theta\\) and variance \\(\\sigma^2\\). Mathematically,\n\\[\nY | \\theta, \\sigma^2  \\sim N(\\theta, \\sigma^2).\n\\]\nThe density\n\\[\n\\begin{aligned}\np(y ~|~ \\theta, \\sigma^2 ) &= (2\\pi\\sigma^2)^{-1/2} e^{-\\frac{1}{2\\sigma^2} (y-\\theta)^2},\\\\\ny &\\in \\mathbb{R},\\\\\n\\theta &\\in \\mathbb{R},\\\\\n\\sigma &\\in \\mathbb{R}^+.\n\\end{aligned}\n\\]\n\nlocation, scale\n\n\\(\\theta\\) is called the ‘location’ parameter\n\\(\\sigma\\) is called the ‘scale’ parameter\n\n\n\nprecision\nNotice that every time \\(\\sigma^2\\) appears in the density, it is inverted. For this reason, the inverse variance \\((\\frac{1}{\\sigma^2})\\) has a special name, precision. Intuitively, precision tells us how close \\(y\\) is to the mean \\(\\theta\\). (Large precision = small variance = closer).\n\n\n\nplots of normal densities\n\n\n\n\n\n\nWarning\n\n\n\nIn R, the arguments of pnorm, dnorm, rnorm are the mean and standard deviation (not the variance!)\n\n\n\nplotcode\n\n\n\n\n\n\n\n\n\n\nset.seed(123)\nN = 10000\ny.mc = rnorm(N, mean = 3, sd = 2)\n\ndf = data.frame(y.mc)\n\ndf %>%\n  ggplot(aes(x = y.mc)) +\n  geom_histogram(aes(y = ..density..), alpha = 0.6, fill = 'steelblue') +\n  stat_function(fun = dnorm, args = list(mean = 3, sd = 2), aes(color = \"N(3, 4)\")) +\n  stat_function(fun = dnorm, args = list(mean = 0, sd = 1), aes(color = \"N(0, 1)\")) +\n  theme_bw() +\n  labs(x = \"y\", y = \"density\", title = \"Normal densities\",\n       color = \"\")"
  },
  {
    "objectID": "notes/lec06-normalModel.html#bayesian-inference",
    "href": "notes/lec06-normalModel.html#bayesian-inference",
    "title": "The normal model",
    "section": "Bayesian inference",
    "text": "Bayesian inference\nIn general, we wish to make inference about \\(\\theta\\) and \\(\\sigma^2\\) after observing some data \\(y_1, \\ldots y_n\\) and thus are interested in the posterior \\(p(\\theta, \\sigma^2 | y_1, \\ldots y_n)\\). This is the standard task we have seen thus far, and requires us to specify a joint prior \\(p(\\theta, \\sigma^2)\\). Below, we will work to find a class of conjugate priors over \\(\\theta\\) and \\(\\sigma^2\\).\nWe can break up the joint posterior into two pieces from the axioms of probability:\n\\[\np(\\theta, \\sigma^2 | y_1, \\ldots y_n) = p(\\theta | \\sigma^2, y_1, \\ldots, y_n)p(\\sigma^2|y_1, \\ldots y_n)\n\\]\nThis suggests that we calculate the joint posterior by:\n\nfirst finding the full conditional of \\(\\theta\\): \\(p(\\theta| \\sigma^2, \\vec{y})\\)\nand then finding the marginal posterior of \\(\\sigma^2\\): \\(p(\\sigma^2 | \\vec{y})\\),\n\nwhere \\(\\vec{y} = \\{y_1, \\ldots y_n\\}\\).\n\nThe full conditional of \\(\\theta\\)\nBy Bayes’ theorem,\n\\[\np(\\theta| \\sigma^2, \\vec{y}) \\propto \\underbrace{p(\\vec{y} |\\theta, \\sigma^2)}_{\\text{likelihood}} \\underbrace{p(\\theta|\\sigma^2)}_{\\text{prior}}.\n\\]\nTo arrive at the full conditional posterior of \\(\\theta\\), we must first specify a prior on \\(\\theta\\).\nConsidering we have a normal likelihood, what is a conjugate class of densities for \\(\\theta\\)?\n\n\n\n\n\n\nanswer\n\n\n\n\n\n\\(\\theta | \\sigma^2 \\sim N(\\mu_0, \\tau_0^2)\\) for some \\(\\mu_0 \\in \\mathbb{R}\\) and \\(\\tau_0^2 \\in \\mathbb{R}^+\\) is conjugate.\n\n\n\nWith the conjugate prior, our full conditional posterior \\(\\{ \\theta| \\sigma^2, \\vec{y} \\} \\sim N(\\mu_n, \\tau_n^2)\\) where\n\\[\n\\begin{aligned}\n\\mu_n &=\n\\frac{\\frac{1}{\\tau_0^2}\\mu_0 + \\frac{n}{\\sigma^2} \\bar{y}}{\n\\frac{1}{\\tau_0^2} + \\frac{n}{\\sigma^2}\n}\n\\\\\n\\\\\n\\tau_n^2 &= \\frac{1}{\\frac{1}{\\tau_0^2} + \\frac{n}{\\sigma^2}}\n\\end{aligned}\n\\]\n\nLet’s sketch out ‘completing the square’ to derive the parameters offline.\n\n\n\nIntuitive posterior parameters\nIf we consider the posterior precision, \\(\\frac{1}{\\tau_n^2}\\), we can re-arrange the terms above to illuminate how posterior information = prior information + data information;.\n\\[\n\\frac{1}{\\tau_n^2}= \\frac{1}{\\tau_0^2} + \\frac{n}{\\sigma^2}\n\\]\nIn words, posterior precision is equivalent to prior precision plus sampling precision. If we name each precision term, \\(\\lambda_0 = \\frac{1}{\\tau_0}\\), \\(\\lambda_n = \\frac{1}{\\tau_n}\\) and \\(\\lambda = \\frac{1}{\\sigma}\\) then\n\\[\n\\mu_n = \\frac{\\lambda_0^2}{\\lambda_0^2 + n\\lambda^2} \\mu_0 +\n\\frac{n\\lambda^2}{\\lambda_0^2 + n\\lambda^2} \\bar{y}\n\\]\ni.e. the posterior mean is the weighted average of prior and sample mean, where the weights are the relative contribution of each precision!\nWe can re-define \\(\\lambda_0^2 = \\kappa_0 \\lambda^2\\) (or equivalently \\(\\tau_0^2 = \\frac{\\sigma^2}{\\kappa_0}\\)) and obtain\n\\[\n\\begin{aligned}\n\\mu_n &= \\frac{\\kappa_0}{\\kappa_0 + n} \\mu_0 + \\frac{n}{\\kappa_0 + n} \\bar{y},\\\\\n\\frac{1}{\\tau_n^2} &= \\frac{\\kappa_0 + n}{\\sigma^2}\n\\end{aligned}\n\\]\nwhere we can interpret \\(\\kappa_0\\) as the prior sample size.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nNote that \\(\\tau_n^2\\) is the posterior variance of the full conditional posterior of \\(\\theta\\). This is distinct from \\(\\sigma_n^2\\), defined below.\n\n\n\n\nPrior on \\(\\sigma^2\\)\nRemember, we want \\(p(\\theta, \\sigma^2 | \\vec{y}) = p(\\theta | \\sigma^2, y_1, \\ldots, y_n)p(\\sigma^2|y_1, \\ldots y_n)\\). We have the first component of the right hand side, what about the second component?\nNotice that\n\\[\np(\\sigma^2 | \\vec{y}) \\propto p(\\sigma^2)\\int p(\\vec{y} | \\theta, \\sigma^2) p(\\theta|\\sigma^2) d\\theta\n\\]\nBut how do we choose \\(p(\\sigma^2)\\) to be conjugate? We can proceed in multiple ways: one is noting that the integral is really a convolution of normals, (thereby a sum of normals) and is therefore a normal density.\nUpon inspection, we can see a suitable choice is \\(\\frac{1}{\\sigma^2} \\sim \\text{gamma}(a, b)\\).\n\n\nThe inverse-gamma\nA random variable \\(X \\in (0, \\infty)\\) has an inverse-gamma(a,b) distribution if \\(\\frac{1}{X}\\) has a gamma(a,b) distribution.\nIf X has an inverse-gamma distribution, the density of X is\n\\[\np(x | a, b) = \\frac{b^a}{\\Gamma(a)} x^{-a-1}e^{-b/x} \\ \\text{for } \\ x > 0\n\\]\nand\n\\[\n\\begin{aligned}\nEX &= \\frac{b}{(a-1)} \\text{ if } a \\geq 1; \\ \\infty \\text{ if } 0<a<1,\\\\\nVar(X) &= \\frac{b^2}{(a-1)^2(a-2)} \\ \\text{if } a \\geq 2; \\ \\infty \\text{ if } 0 < a < 2,\\\\\nMode(X) &= \\frac{b}{a +1}.\n\\end{aligned}\n\\]\n\n\nThe marginal posterior of \\(\\sigma^2\\)\nTaken all together, if we let our sampling model and prior distributions be such that\n\\[\n\\begin{aligned}\nY_i | \\theta, \\sigma^2 &\\sim N(\\theta, \\sigma^2)\\\\\n\\theta | \\sigma^2 & \\sim N(\\mu_0, \\sigma^2/\\kappa_0)\\\\\n\\frac{1}{\\sigma^2} &\\sim \\text{gamma}(\\frac{\\nu_0}{2}, \\frac{\\nu_0}{2} \\sigma_0^2)\n\\end{aligned}\n\\]\nthen the posterior\n\\[\n\\frac{1}{\\sigma^2} | \\vec{y} \\sim \\text{gamma}(\\frac{\\nu_n}{2}, \\frac{\\nu_n \\sigma^2_n}{2}),\n\\]\nwhere\n\\[\n\\begin{aligned}\n\\nu_n &= \\nu_0 + n,\\\\\n\\sigma^2_n &= \\frac{1}{\\nu_n} \\left[\n\\nu_0 \\sigma^2_0 +(n-1)s^2 + \\frac{\\kappa_0 n}{\\kappa_0 + n}(\\bar{y} - \\mu_0)^2\n\\right],\n\\end{aligned}\n\\]\nand \\(s^2\\) is the sample variance, \\(\\frac{1}{n-1} \\sum_i (y_i - \\bar{y})^2\\)."
  },
  {
    "objectID": "notes/lec06-normalModel.html#sampling-from-the-joint-posterior",
    "href": "notes/lec06-normalModel.html#sampling-from-the-joint-posterior",
    "title": "The normal model",
    "section": "Sampling from the joint posterior",
    "text": "Sampling from the joint posterior\nSince \\(p(\\theta, \\sigma^2 | \\vec{y}) = p(\\theta | \\sigma^2, y_1, \\ldots, y_n)p(\\sigma^2|y_1, \\ldots y_n)\\), we can sample from the joint posterior by first sampling from \\(p(\\sigma^2|y_1, \\ldots y_n)\\) and then sampling from \\(p(\\theta | \\sigma^2, y_1, \\ldots, y_n)\\).\n\nExample\nProof of concept\nWe have some data:\n\n# generating 10 samples from the population\nset.seed(123)\ntrue.theta = 4\ntrue.sigma = 1\ny = rnorm(10, true.theta, true.sigma)\n\nybar = mean(y) # sample mean\nn = length(y) # sample size\ns2 = var(y) # sample variance\n\nWe make inference about \\(\\theta\\) and \\(\\sigma^2\\):\n\n# priors\n# theta prior\nmu_0 = 2; k_0 = 1\n# sigma2 prior\nnu_0 = 1; s2_0 = 0.010\n\n# posterior parameters\nkn = k_0 + n\nnun = nu_0 + n\nmun = (k_0 * mu_0 + n * ybar) /kn\ns2n = (nu_0 * s2_0 + (n - 1) * s2 + k_0 * n * (ybar - mu_0)^2 / (kn)) / (nun)\n\ns2.postsample = 1 / rgamma(10000, nun / 2, s2n * nun / 2)\ntheta.postsample = rnorm(10000, mun, sqrt(s2.postsample / kn))\n\ndf = data.frame(theta.postsample, s2.postsample)\n\ndf %>%\n  ggplot(aes(x = theta.postsample, y = s2.postsample)) +\n  stat_density_2d(aes(fill = ..level..), geom = \"polygon\") +\n  labs(x = TeX(\"$\\\\theta$\"),\n       y = TeX(\"$\\\\sigma^2$\"),\n       fill = TeX(\"$p(\\\\theta, \\\\sigma^2 | y_1, \\\\ldots y_n)$\")) +\n  theme_bw()"
  },
  {
    "objectID": "notes/lec07-estimators.html",
    "href": "notes/lec07-estimators.html",
    "title": "Estimators",
    "section": "",
    "text": "Definition\n\n\n\nA point estimator of an unknown parameter \\(\\theta\\) is a function that converts data into a single element of parameter space \\(\\Theta\\).\n\n\nExample: imagine \\(\\theta\\) is the population mean. The following are each point estimators of \\(\\theta\\):\n\n\\(\\bar{y}\\)\n\\(y_1\\)\n\\(\\frac{y_1 + y_2}{2}\\)\n\n\n\n\n\n\n\nImportant\n\n\n\nIt is convention to write the population parameter as a Greek character and the estimator as the same Greek character, but with a “hat”. For example, \\(\\theta\\) is the parameter and \\(\\hat{\\theta}\\) is the estimator.\n\n\nSampling properties of a point estimator refer to the estimator’s behavior under hypothetical repeatable surveys or experiments.\nThree common sampling properties of estimators we will see again and again are:\n\nbias\nvariance\nmean squared error (MSE)\n\n\n\nBefore we discuss bias, variance and mean squared error of an estimator, it’s important to understand that an estimator is a statistic (function of the data) and therefore a random variable. Because of this, estimator’s have a sampling distribution.\nExercise: What does the example below show? What is x?\n\nset.seed(360)\n\nx = vector()\nfor (i in 1:100) {\n  y = rnorm(10)\n  x = append(min(y), x)\n}\nhist(x, freq = FALSE)\nabline(v = mean(x), col= \"steelblue\", lwd = 4)\n\n\n\ncat(\"The variance of x is \", round(var(x), 3))\n\nThe variance of x is  0.291\n\n\n\n\n\nIn the rest of these notes, let \\(\\theta_0\\) be the true value of the population parameter \\(\\theta\\).\n\n\n\n\n\n\nDefinition\n\n\n\nBias is the the difference between the expected value of the estimator and the true value of the parameter.\n\n\\(E[\\hat{\\theta} | \\theta = \\theta_ 0] - \\theta_0\\) is the bias of \\(\\hat{\\theta}\\).\nIf \\(E[\\hat{\\theta} | \\theta = \\theta_0] = \\theta_0\\), then we say \\(\\hat{\\theta}\\) is an unbiased estimator of \\(\\theta\\).\nIf \\(E[\\hat{\\theta} | \\theta = \\theta_0] \\neq \\theta_0\\), then we say \\(\\hat{\\theta}\\) is a biased estimator of \\(\\theta\\).\n\n\n\nExercise: Imagine \\(\\hat{\\theta}_a\\) and \\(\\hat{\\theta}_b\\) are two different estimators of \\(\\theta\\). The true value of \\(\\theta\\) is \\(\\theta_0 = 0\\). The sampling distributions of the two estimators are given below. Which estimator do you prefer?\n\n\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nRecall: variance is average squared distance from the mean. In this context, the variance of an estimator refers to the variance of the sampling distribution of \\(\\hat{\\theta}\\). We write this mathematically,\n\\[\nVar[\\hat{\\theta} | \\theta_0] = E[(\\hat{\\theta} - m)^2 |\\theta_0]\n\\]\nwhere \\(m = E[\\hat{\\theta}|\\theta_0]\\).\n\n\nWhile it may seem desirable to have an estimator with zero bias, the estimator may still be far away from the true parameter value if the variance is too large. The mean squared error quantifies how close an estimator is to the true parameter value.\n\n\n\n\n\n\nDefinition\n\n\n\nMean squared error (MSE) is (as the name suggests) the expected value of the squared difference between the estimator and true parameter value. Equivalently, MSE is the variance plus the square bias of the estimator.\n\\[\n\\begin{aligned}\nMSE[\\hat{\\theta}|\\theta_0] &= E[(\\hat{\\theta} - \\theta_0)^2 | \\theta_0]\\\\\n&= Var[\\hat{\\theta} | \\theta_0] + Bias^2[\\hat{\\theta}|\\theta_0]\n\\end{aligned}\n\\]\n\n\n\nLet’s show this offline."
  },
  {
    "objectID": "notes/lec07-estimators.html#practice",
    "href": "notes/lec07-estimators.html#practice",
    "title": "Estimators",
    "section": "Practice",
    "text": "Practice\nSuppose you wish to make inference about the average bill length of Chinstrap penguins.\nYou make the modeling assumption that \\(Y\\), the bill length of a penguin is normally distributed, i.e. \\(Y \\sim N(\\theta, \\sigma^2)\\) and you set up a conjugate prior as we’ve done before.\nOne can then show that the posterior mean estimator of \\(\\theta\\) is\n\\[\n\\hat{\\theta}_b = E[\\theta | y_1,\\ldots y_n] = \\frac{n}{\\kappa_0 + n} \\bar{y} + \\frac{\\kappa_0}{\\kappa_0 + n} \\mu_0 = w\\bar{y} + (1-w) \\mu_0\n\\]\nExercise: compare \\(\\hat{\\theta}_b\\) to the estimator \\(\\hat{\\theta}_e = \\bar{y}\\). Compute the expected value of each estimator, which one is biased? Compute the variance of each estimator. Which has lower variance?\n\nLet’s compute the MSE and discuss when the Bayesian estimator \\(\\hat{\\theta}_b\\) has lower MSE than the sample mean offline."
  },
  {
    "objectID": "notes/lec07-estimators.html#extra-practice",
    "href": "notes/lec07-estimators.html#extra-practice",
    "title": "Estimators",
    "section": "Extra practice",
    "text": "Extra practice\n\n\n\n\n\nSuppose you know that you know Gentoo penguins are closely related to Chinstrap penguins. Previously, you’ve measured the bill length of three Gentoo penguins and found their mean bill length to be 46.2. Accordingly, you set \\(\\mu_0 = 46.2\\).\n\n\n\n\n\n\n\n\nSuppose (for illustrative purposes) that you know the true population mean and variance for Chinstrap penguin bill length,\n\\[\n\\begin{aligned}\n\\theta_0 &= 48.8\\\\\n\\sigma^2 &= 3.3.\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\nCompute \\(MSE[\\hat{\\theta}_e|\\theta_0]\\) and \\(MSE[\\hat{\\theta_b}|\\theta_0]\\) and plot the ratio \\(MSE[\\hat{\\theta}_b]/MSE[\\hat{\\theta}_e|\\theta_0]\\) as a function of \\(n\\) for \\(\\kappa_0 = 0, 1, 2, 3\\)."
  },
  {
    "objectID": "quizzes/quiz04.html",
    "href": "quizzes/quiz04.html",
    "title": "Quiz 4",
    "section": "",
    "text": "Exercise 1\n\\[\nY | \\theta, \\sigma^2 \\sim N(\\theta, \\sigma^2)\n\\]\nWhat is a conjugate class of priors for \\(\\theta | \\sigma^2\\)?\n\n\nExercise 2\nTRUE or FALSE\nAn estimator is a random variable.\n\n\nExercise 3\nLet \\(\\theta_0\\) be the true value of \\(\\theta\\).\nIf \\(E[\\hat{\\theta}| \\theta = \\theta_0] = \\theta_0\\), we say \\(\\hat{\\theta}\\) is a ____ estimator of \\(\\theta\\).\n\n\n\n03:00"
  },
  {
    "objectID": "slides/lab4.html#exercise",
    "href": "slides/lab4.html#exercise",
    "title": "Extra practice",
    "section": "Exercise",
    "text": "Exercise\nA data scientist at a small subscriber-based tech company models the number of new subscribers in a day as \\(Y|\\theta \\sim \\text{Poisson}(\\theta)\\) with prior \\(\\theta \\sim \\text{gamma}(a,b)\\). A priori, the data scientist believes that there are on average 20 signups per day and 90% of the time there are between approximately 3 and 50 signups on a given day.\na\nFind suitable \\(a\\) and \\(b\\) that satisfy the data scientist’s prior beliefs.\nVerify how well your prior aligns with this belief using Monte Carlo sampling to generate the prior predictive distribution, \\(p(\\tilde{y}) = \\int p(\\tilde{y}, \\theta)d\\theta\\).\n\n\n\nb\nAfter one month the data scientist observes the following daily subscriber counts:\n\ny = c(10, 21, 19, 16, 20, 18, 35, 16, 23, 26, 20, 21, 23, 19, 18, 20, 23, 18, 21, 16, 15, 15, 20, 22, 19, 25)\n\nThe data scientist is fundamentally interested in the variance of subscriber counts per day. Is the Poisson model appropriate for this data?\nReport \\(p(\\tilde{S}^2 > s^2_{obs} | y_1,\\ldots y_n)\\) where \\(\\tilde{S}^2\\) is the posterior predictive sample variance and \\(s^2_{obs}\\) is the observed sample variance (\\(s^2_{obs} = 21.3\\)). To generate samples under the posterior predictive distribution, use the prior from part (a)."
  },
  {
    "objectID": "slides/lab4.html#bias",
    "href": "slides/lab4.html#bias",
    "title": "Extra practice",
    "section": "Bias",
    "text": "Bias\nLet \\(Y_1,\\ldots Y_n\\) be iid random variables with expectation \\(\\theta\\) and variance \\(\\sigma^2\\).\nShow that \\(\\frac{1}{n} \\sum_{i = 1}^n (Y_i -\\bar{Y})\\) is a biased estimator of \\(\\sigma^2\\).\n\n\n🔗 sta360-fa23.github.io"
  },
  {
    "objectID": "slides/lab4.html#exercise-1",
    "href": "slides/lab4.html#exercise-1",
    "title": "Extra practice",
    "section": "Exercise",
    "text": "Exercise\nLet \\(Y_1,\\ldots Y_n\\) be iid random variables with expectation \\(\\theta\\) and variance \\(\\sigma^2\\).\nShow that \\(\\frac{1}{n} \\sum_{i = 1}^n (Y_i -\\bar{Y})^2\\) is a biased estimator of \\(\\sigma^2\\).\n\n\n🔗 sta360-fa23.github.io"
  },
  {
    "objectID": "notes/lec08-gibbs.html",
    "href": "notes/lec08-gibbs.html",
    "title": "Gibbs sampling",
    "section": "",
    "text": "Definition\n\n\n\nA semiconjugate or conditionally conjugate prior is a prior that is conjugate to the full conditional posterior.\n\n\nNote: the idea of a semiconjugate prior only makes sense when making inferences about two or more parameters.\nExample:\n\\[\n\\begin{aligned}\nY | \\theta, \\sigma^2 &\\sim N(\\theta, \\sigma^2)\\\\\n\\theta & \\sim N(\\mu_0, \\tau_0^2)\\\\\n\\frac{1}{\\sigma^2} &\\sim gamma(\\nu_0/2, \\nu_0\\sigma_0^2/2)\n\\end{aligned}\n\\]\nIn this case, \\(\\tau_0^2\\) is not a function of \\(\\sigma^2\\) and thus \\(p(\\theta, \\sigma^2) = p(\\theta) p(\\sigma^2)\\).\nEach prior is “semiconjugate” since \\(p(\\theta| \\sigma^2, y_1,\\ldots y_n)\\) is normal and \\(p(\\frac{1}{\\sigma^2} | \\theta, y_1,\\ldots y_n)\\) is gamma but \\(p(\\theta, \\sigma^2)\\) is not conjugate to \\(p(\\theta, \\sigma^2 | y_1,\\ldots y_n)\\).\n\n\n\n\n\n\nDefinition\n\n\n\nA proper prior is a density function that does not depend on data and integrates to 1. If a prior integrates to a positive finite value, it is an unnormalized density that can be renormalized by being multiplied by a constant to integrate to 1. If a prior is not proper, we call the prior improper.\n\n\nExample:\n\\[\n\\begin{aligned}\nY | \\theta, \\sigma^2 &\\sim N(\\theta, \\sigma^2)\\\\\np(\\theta, \\sigma^2) &= \\frac{1}{\\sigma^2}\n\\end{aligned}\n\\]\n\\(p(\\theta, \\sigma^2)\\) is an improper prior. \\(p(\\theta, \\sigma^2)\\) does not integrate to a finite value and thus cannot be renormalized. It is not a probability density. However, it yields a tractable posterior for \\(\\theta\\) and \\(\\sigma^2\\) (see p 79 of Hoff).\n\n\n\nPriors are meant to describe our state of knowledge before examining data. In some cases we may wish to describe our ignorance a priori using a vague prior that plays a minimal role in the posterior distribution.\nA common trap is to imagine that a flat, or uniform prior is uninformative. Previously, on homework 3 you showed a uniform prior on binary probability of success \\(\\theta\\) is informative on the log-odds. Additionally, an improper flat prior may carry a lot of information, since most of the mass is infinitely far away.\n\n\n\n\n\n\nDefinition\n\n\n\nThe Jeffreys prior\n\\[\nJ(\\theta) \\propto \\sqrt{I(\\theta)}\n\\]\nwhere \\(I(\\theta) = -E[\\frac{\\partial}{\\partial\\theta^2} \\log p(Y|\\theta) | \\theta]\\).\n\n\nThe defining feature of Jeffreys prior is that it will yield an equivalent result if applied to a transformed parameter. This principle of invariance is one approach to non-informative priors that works well for single parameter priors. Multiparameter extensions are often less useful."
  },
  {
    "objectID": "notes/lec08-gibbs.html#inference-under-non-conjugate-priors",
    "href": "notes/lec08-gibbs.html#inference-under-non-conjugate-priors",
    "title": "Gibbs sampling",
    "section": "Inference under non-conjugate priors",
    "text": "Inference under non-conjugate priors\nSuppose we don’t know\n\\[\np(\\theta, \\sigma^2 | y_1,\\ldots y_n)\n\\]\nbut we do know the full conditional posteriors\n\\[\n\\begin{aligned}\np(\\theta | \\sigma^2, y_1, \\ldots y_n)\\\\\np(\\sigma^2 | \\theta, y_1,\\ldots y_n)\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "notes/lec08-gibbs.html#gibbs-sampler",
    "href": "notes/lec08-gibbs.html#gibbs-sampler",
    "title": "Gibbs sampling",
    "section": "Gibbs sampler",
    "text": "Gibbs sampler\nWhat if we have a non-conjugate prior? How can we can we look at \\(p(\\theta, \\sigma^2 | y_1,\\ldots y_n)\\)?\nIn general, suppose we don’t know\n\\[\np(\\theta, \\sigma^2 | y_1,\\ldots y_n)\n\\]\nbut we do know the full conditional posteriors\n\\[\n\\begin{aligned}\np(\\theta | \\sigma^2, y_1, \\ldots y_n)\\\\\np(\\sigma^2 | \\theta, y_1,\\ldots y_n)\n\\end{aligned}\n\\]\nwe can generate sample \\(\\theta^{(s)}, \\sigma^{2(s)}\\) from the joint posterior by the following algorithm:\n\nsample \\(\\theta^{(s+1)}\\) from \\(p(\\theta | \\sigma^{2(s)}, y_1,\\ldots y_n)\\)\nsample \\(\\sigma^{2(s+1)}\\) from \\(p(\\sigma^2|\\theta^{(s+1)}, y_1,\\ldots, y_n)\\)\nlet \\(\\phi^{(s+1)} = \\{ \\theta^{(s+1)}, \\sigma^{2(s+1)} \\}\\)\n\niterate steps 1-3 \\(S\\) times.\nThis algorithm is called the Gibbs sampler,\n\nit creates a dependent set of values \\(\\phi^{(1)} \\ldots \\phi^{(S)}\\),\nthe sequence is called a Markov chain,\nthe samples let us approximate the posterior i.e. the histogram of \\((\\phi^{(1)},\\ldots \\phi^{(S)})\\) is a Markov chain Monte Carlo approximation to \\(p(\\phi | y_1,\\ldots y_n)\\).\n\nExample: in the semiconjugate normal model described above, the resulting posteriors are:\n\\[\n\\theta | \\sigma^2, y_1,\\ldots y_n \\sim N(\\mu_n, \\tau_n^2),\n\\]\nwhere \\(\\mu_n = \\frac{\\mu_0/\\tau_0^2 + n\\bar{y} /\\sigma^2}{1/{\\tau_0^2} + n/\\sigma^2}\\) and \\(\\tau_n^2 = \\left( \\frac{1}{\\tau_0^2 }+ \\frac{n}{\\sigma^2} \\right)^{-1}\\) and\n\\[\n\\sigma^2 | \\theta, y_1, \\ldots y_n \\sim invgamma(\\nu_n/2, \\nu_n \\sigma^2_n / 2)\n\\]\nwhere \\(\\nu_n = \\nu_0 + n\\), \\(\\sigma_n^2 = \\frac{1}{\\nu_n} [\\nu_0 \\sigma_0^2 + n s^2_n(\\theta)]\\) and \\(s^2_n(\\theta) = \\frac{1}{n}\\sum (y_i - \\theta)^2\\).\n\n##########################\n# example from Hoff ch6 #\n##########################\n\n# data\ny = c(1.64, 1.70, 1.72, 1.74, 1.82, 1.82, 1.82, 1.90, 2.08)\nmean.y = mean(y) ; var.y = var(y) ; n = length(y)\n\n# priors\nmu0 = 0\nt20 = 100\nnu0 = 1\ns20 = 2\n\n# starting point\nS = 1000\nPHI = matrix(nrow = S, ncol = 2)\nphi = c(mean.y, var(y))\nPHI[1, ] = phi\n\n# Gibbs sampling\nset.seed(360)\nfor(s in 2:S) { \n\n## generate theta from sigma2\nmun = (mu0 / t20 + n * mean.y * phi[2]) / (1 / t20 + n * phi[2])\nt2n = 1 / (1 / t20 + n * phi[2])\nphi[1] = rnorm(1, mun, sqrt(t2n))\n\n## generate 1/sigma2 from theta\nnun = nu0 + n\ns2n = (nu0 * s20 + (n - 1) * var.y + n * (mean.y - phi[1])^2 ) / nun\nphi[2] = rgamma(1, nun/2, nun * s2n / 2)\n\n## update chain\nPHI[s,] = phi\n}\n\nNote: in this code we use the identity \\(n s_n^2(\\theta) = (n-1)s^2 + n (\\bar{y} - \\theta)^2\\).\n\nplotcode\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(latex2exp)\n# plotting the joint posterior\ndf = as.data.frame(PHI)\nnames(df) = c(\"theta\", \"prec\")\ndf %>%\n  ggplot(aes(x = theta, y = prec)) +\n  stat_density_2d(aes(fill = ..level..), geom = \"polygon\") +\n  labs(x = TeX(\"$\\\\theta$\"),\n       y = TeX(\"$1/\\\\sigma^2$\"),\n       fill = TeX(\"$p(\\\\theta, 1/\\\\sigma^2 | y_1, \\\\ldots y_n)$\")) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nSince the sequence \\(\\{\\phi^{(s)} \\}\\) depends on \\(\\phi^{(0)}, \\ldots \\phi^{(s-1)}\\) only through \\(\\phi^{(s-1)}\\) we say the sequence is memoryless. This is called the Markov property, and so the sequence is a Markov chain.\n“What happens next depends only on the state of affairs now”\n\n\nUnder some conditions,\n\\[\np(\\phi^{(s)} \\in A) \\rightarrow \\int_A p(\\phi) d\\phi \\ \\ \\text{ as } s \\rightarrow \\infty\n\\]\ni.e. the sampling distribution of \\(\\phi^{(s)}\\) approaches the target distribution as \\(s \\rightarrow \\infty\\) regardless of \\(\\phi^{(0)}\\).\nFurthermore,\n\\[\n\\frac{1}{S} \\sum_{s=1}^S g(\\phi^{(s)})  \\rightarrow E[g(\\phi)]\n\\]\n\n\n\n\n\n\nImportant\n\n\n\nBig take-away: if we can sample from the full conditional posteriors, we can construct a Markov chain with samples from the joint posterior! We can then use Monte Carlo approximation to use the samples to summarize aspects of the posterior."
  },
  {
    "objectID": "hw/extra-credit.html",
    "href": "hw/extra-credit.html",
    "title": "Extra credit",
    "section": "",
    "text": "Because this is extra credit, the teaching team will not assist solving this problem during office hours. Additionally, extra credit may not be turned in late."
  },
  {
    "objectID": "hw/extra-credit.html#exercise",
    "href": "hw/extra-credit.html#exercise",
    "title": "Extra credit",
    "section": "Exercise",
    "text": "Exercise\n3.14 from Hoff.\nAdditionally, complete part (e): discuss the resulting posterior based on your findings from parts (a) through (d) in a couple of sentences."
  },
  {
    "objectID": "notes/lec09-mcmc-diagnostics.html",
    "href": "notes/lec09-mcmc-diagnostics.html",
    "title": "MCMC diagnostics",
    "section": "",
    "text": "We setup a data generative model, \\(p(y | \\boldsymbol{\\theta})\\) and a prior on the model parameters \\(p(\\boldsymbol{\\theta})\\) where \\(\\boldsymbol{\\theta} = \\{ \\theta_1, \\theta_2, \\ldots \\theta_n\\}\\).\nNext, we wish to make inferences using the data we collect \\(\\boldsymbol{y} = \\{y_1,\\ldots y_n\\}\\). All inferences we make require the posterior \\(p(\\boldsymbol{\\theta}| \\boldsymbol{y})\\), which we obtain via Bayes’ rule.\nIn general, the inferences we wish to make, e.g. \\(p(g(\\boldsymbol{\\theta}) \\in A)\\), are complicated or impossible to compute analytically. Here, Monte Carlo approximation helps. The key idea is that we use independent samples from the posterior as an empirical approximation to make inference.\nFor non-conjugate models, obtaining samples from the posterior can be hard. We saw last time that Gibbs sampling lets us generate a series of dependent samples from the posterior as an empirical approximation to make inference. The key idea is that if we sample a large number of samples \\(S\\), we should have some number \\(S_{eff}<S\\) effectively independent samples.\n\n\nGibbs sampling is one of many methods (but not the only method) to construct a Markov chain comprised of dependent samples from the target distribution.\nConstructing a Markov chain of dependent samples and using these samples to approximate the target distribution is called Markov chain Monte Carlo (MCMC).\n\nImportantly, MCMC sampling algorithms are not models. They do not generate more information than is in \\(\\boldsymbol{y}\\) and \\(p(\\boldsymbol{\\theta})\\). They are simply ways of “looking at” \\(p(\\boldsymbol{\\theta}|\\boldsymbol{y})\\).\n\n\n\n\n\n\nDefinition\n\n\n\nA target distribution is a distribution we are interested in sampling. In Bayesian statistics, this is typically the posterior distribution."
  },
  {
    "objectID": "notes/lec09-mcmc-diagnostics.html#definitions",
    "href": "notes/lec09-mcmc-diagnostics.html#definitions",
    "title": "MCMC diagnostics",
    "section": "Definitions",
    "text": "Definitions\n\n\n\n\n\n\nDefinition\n\n\n\nTypical set\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nStationarity\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nEffective sample size\n\n\n\n\n\n\n\n\nDefinition"
  },
  {
    "objectID": "notes/lec00-hmc.html",
    "href": "notes/lec00-hmc.html",
    "title": "Hamiltonian Monte Carlo",
    "section": "",
    "text": "Often we are interested in some summary (usually an integral) of the target distribution. To evaluate the quantity of interest, we need samples from the typical set."
  },
  {
    "objectID": "notes/lec09-mcmc-diagnostics.html#properties-of-mcmc",
    "href": "notes/lec09-mcmc-diagnostics.html#properties-of-mcmc",
    "title": "MCMC diagnostics",
    "section": "Properties of MCMC",
    "text": "Properties of MCMC\n\ntoy example\nImagine the following target distribution (the joint probability distribution of two variables, \\(\\theta\\) and \\(\\delta\\)).\n\nplotcode\n\n\n\n\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(latex2exp)\nset.seed(360)\n\n## fixed values ## \nmu = c(-3, 0, 3) # conditional means\nsd = rep(sqrt(1 / 3), 3) # conditional sds\nd = c(1, 2, 3) # sample space of delta\nN = 1000 # number of samples\n\ndelta = sample(d, size = N, prob = c(.45, .1, .4), replace = TRUE)\ntheta = rnorm(N, mean = mu[delta], sd = sd[delta])\n\ndf = data.frame(delta, theta)\ndf %>%\n  ggplot(aes(x = theta, y = delta)) + \n  geom_bin2d(bins = 25) +\n  theme_bw() + \n  labs(y = TeX(\"\\\\delta\"), \n       x = TeX(\"\\\\theta\"))\n\n\n\n\nIn this example,\n\\[\n\\begin{aligned}\np(\\delta = d) = \\begin{cases}\n&.45 &\\text{ if } d = 1\\\\\n&.10 &\\text{ if } d = 2\\\\\n&.45 &\\text{ if } d = 3\n\\end{cases}\n\\end{aligned}\n\\]\n\\[\n\\begin{aligned}\n\\{\\theta | \\delta = d\\} \\sim\n\\begin{cases}\n&N(-3, 1/3) &\\text{ if } d = 1\\\\\n&N(0, 1/3) &\\text{ if } d = 2\\\\\n&N(3, 1/3) &\\text{ if } d = 3\n\\end{cases}\n\\end{aligned}\n\\]\nExercise: Construct a Gibbs sampler of the joint density.\nNote: this is a toy example. We can sample from the target distribution directly as seen above. However, we will construct a Gibbs sampler for pedagogical purposes that will become apparent momentarily.\n\n\n\n\n\n\nsolution\n\n\n\n\n\nTo construct a Gibbs sampler, we need the full conditional distributions.\n\n\\(p(\\theta | \\delta)\\) is given.\n\\(p(\\delta| \\theta) = \\frac{p(\\theta | \\delta = d) p(\\delta = d)}{ \\sum_{d=1}^3p(\\theta | \\delta = d)p(\\delta = d)}\\), for \\(d \\in \\{1, 2, 3\\}\\).\n\n\n\n\n\nplotcode\n\n\n\n\n\n\n\n\n\n\n## fixed values ## \nmu = c(-3, 0, 3) # conditional means\ns2 = rep(1 / 3, 3) # conditional sds\nd = c(1, 2, 3) # sample space of delta\nN = 1000 # chain length\nw = c(.45, .1, .4) # delta probabilities\n\n## Gibbs sampler ##\nset.seed(360)\nN = 1000 # number of Gibbs samples\n\ntheta = 0 # initial theta value\nthd.mcmc = NULL\nfor(i in 1:N) {\nd = sample(1:3 , 1, prob = w * dnorm(theta, mu, sqrt(s2))) \ntheta = rnorm(1, mu[d], sqrt(s2[d]))\nthd.mcmc = rbind(thd.mcmc, c(theta,d))\n}\n# note we take advantage that sample() in R does not require the probability\n# to add up to 1\n\ndf = data.frame(theta = thd.mcmc[,1],\n                delta = thd.mcmc[,2])\n\ndf %>%\n  ggplot(aes(x = seq(1, nrow(df)), y = theta)) +\n  geom_line() +\n  theme_bw() +\n  labs(y = TeX(\"\\\\theta\"),\n       x = \"iteration\",\n       title = \"Traceplot of 1000 Gibbs samples\")\n\n\n\n\nExercise:\n\ndescribe how we implement the conditional update for delta in the code above\nwhat do you notice from the traceplot above? Hint: you can imagine hopping from delta islands in the first figure of the joint target over parameter space.\n\n\n\n\n\n\n\nImportant\n\n\n\nThe picture to visualize is that of a particle moving through parameter space.\n\n\n\n\n\nLet’s see how well our samples of \\(\\theta\\) approximate the true marginal \\(p(\\theta)\\)."
  },
  {
    "objectID": "notes/lec09-mcmc-diagnostics.html#terms-to-describe-what-we-mcmc",
    "href": "notes/lec09-mcmc-diagnostics.html#terms-to-describe-what-we-mcmc",
    "title": "MCMC diagnostics",
    "section": "Terms to describe what we MCMC",
    "text": "Terms to describe what we MCMC\n\nautocorrelation: how correlated consecutive values in the chain are. Mathematically, we compute the sample autocorrelation between elements in the sequence that are \\(t\\) steps apart using\n\n\\[\n\\text{acf}_t(\\boldsymbol{\\phi}) =\n\\frac{\\frac{1}{S - t} \\sum_{s = 1}^{S-t} (\\phi_s - \\bar{\\phi})(\\phi_{s+t} - \\bar{\\phi})}\n{\\frac{1}{S-1} \\sum_{s = 1}^S (\\phi_s - \\bar{\\phi})^2}\n\\]\nwhere \\(\\boldsymbol{\\phi}\\) is a sequence of length \\(S\\) and \\(\\bar{\\phi}\\) is the mean of the sequence. In practice we use acf function in R. Example:\n\nacf(thd.mcmc[,1])\n\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nTypical set\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nStationarity\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nEffective sample size\n\n\n\n\n\n\n\n\nDefinition"
  },
  {
    "objectID": "notes/lec09-mcmc-diagnostics.html#terms-to-describe-mcmc",
    "href": "notes/lec09-mcmc-diagnostics.html#terms-to-describe-mcmc",
    "title": "MCMC diagnostics",
    "section": "Terms to describe MCMC",
    "text": "Terms to describe MCMC\n\nautocorrelation: how correlated consecutive values in the chain are. Mathematically, we compute the sample autocorrelation between elements in the sequence that are \\(t\\) steps apart using\n\n\\[\n\\text{acf}_t(\\boldsymbol{\\phi}) =\n\\frac{\\frac{1}{S - t} \\sum_{s = 1}^{S-t} (\\phi_s - \\bar{\\phi})(\\phi_{s+t} - \\bar{\\phi})}\n{\\frac{1}{S-1} \\sum_{s = 1}^S (\\phi_s - \\bar{\\phi})^2}\n\\]\nwhere \\(\\boldsymbol{\\phi}\\) is a sequence of length \\(S\\) and \\(\\bar{\\phi}\\) is the mean of the sequence. In practice we use acf function in R. Example:\n\nacf(thd.mcmc[,1], plot = FALSE)\n\n\nAutocorrelations of series 'thd.mcmc[, 1]', by lag\n\n    0     1     2     3     4     5     6     7     8     9    10    11    12 \n1.000 0.962 0.959 0.954 0.951 0.948 0.948 0.943 0.941 0.936 0.933 0.931 0.928 \n   13    14    15    16    17    18    19    20    21    22    23    24    25 \n0.927 0.923 0.920 0.915 0.911 0.907 0.906 0.908 0.905 0.902 0.899 0.898 0.897 \n   26    27    28    29    30 \n0.895 0.891 0.891 0.887 0.887 \n\n\nThe higher the autocorrelation, the more samples we need to obtain a given level of precision for our approximation. One way to state how precise our approximation is, is with effective sample size.\n\neffective sample size: intuitively this is the effective number of exact samples “contained” in the Markov chain (see Betancourt 2018). In practice we use coda::effectiveSize() function to compute. Example:\n\n\nlibrary(coda)\neffectiveSize(thd.mcmc[,1])[[1]]\n\n[1] 2.065509\n\n\nMore precisely, the effective sample size (ESS) is the value \\(S_{eff}\\) such that\n\\[\nVar_{MCMC}[\\bar{\\phi}] = \\frac{Var[\\phi]}{S_{eff}}.\n\\]\nIn words, it’s the number of independent Monte Carlo samples necessary to give the same precision as the MCMC samples. For comparison, recall \\(Var_{MC}[\\bar{\\phi}] = Var[\\phi]/S\\)\n\nStationarity is when samples taken in one part of the chain have a similar distribution to samples taken from other parts of the chain. Intuitively, we want the particle to move from our arbitrary starting point to regions of higher probability\\(^*\\), then we will say it has achieved stationarity.\n\nTraceplots are a great way to visually inspect whether a chain has converged, or achieved stationarity. In the traceplot above we can see that samples from the beginning of the chain look very different than samples at the end.\n\\(^*\\) recall that probability is really a volume in high dimensions of parameter space, and so it is not enough for a pdf to evaluate to a high value, there must also be sufficient volume.\n\nMixing: how well the particle moves between sets of high probability. Some might refer to this as how well the particle sojourns across the “typical set” (regions of high probability)."
  },
  {
    "objectID": "notes/lec09-mcmc-diagnostics.html#extra-practice",
    "href": "notes/lec09-mcmc-diagnostics.html#extra-practice",
    "title": "MCMC diagnostics",
    "section": "Extra practice",
    "text": "Extra practice\nGibbs sample the target above 10 thousand times. Report and discuss both the autocorrelation and ESS."
  },
  {
    "objectID": "hw/hw05.html",
    "href": "hw/hw05.html",
    "title": "Homework 5",
    "section": "",
    "text": "Risk calculation: Let \\(Y_1, \\ldots, Y_n | \\theta \\sim \\text{ i.i.d. Poission}(\\theta)\\).\n\nFor the case that \\(\\theta \\sim \\text{gamma}(a, b)\\), show that the posterior mean of \\(\\theta\\) given \\(Y_1, \\ldots, Y_n\\) can be written as \\(\\hat{\\theta}_w = w \\bar{y} + (1-w)\\mu\\) for values \\(w\\) and \\(\\mu\\) that depend on \\(n\\), \\(a\\) and \\(b\\).\nNow consider how good this estimator is for a specific value of \\(\\theta\\). Compute \\(E[\\hat{\\theta}_w|\\theta]\\), \\(V[\\hat{\\theta}_w|\\theta]\\), and \\(E[\\bar{y}|\\theta]\\) and \\(V[\\bar{y}|\\theta]\\).\nFind some nice conditions on \\(w\\) and \\(\\mu\\) so that \\(MSE[\\hat{\\theta}_w] < MSE[\\bar{y}]\\)\n[Optional] Now suppose \\(n = 10\\) and \\(\\theta = 5\\). Pick a value of \\(w\\) and \\(\\mu\\) so that your condition in c. is met. Now verify the condition numerically with a Monte Carlo simulation, by simulating 1000 samples of size \\(n=10\\) from the Poisson(5) distribution, computing \\(\\bar{y}\\) and \\(\\hat{\\theta}_w\\) for each simulated sample, and then approximating the MSE of each estimator using the 1000 simulated values of each. Also make histograms or density plots of the simulated estimators, to confirm that one has low(er) variance but positive bias, and the other has zero bias but high(er) variance."
  },
  {
    "objectID": "hw/hw05.html#exercise-2",
    "href": "hw/hw05.html#exercise-2",
    "title": "Homework 5",
    "section": "Exercise 2",
    "text": "Exercise 2\n6.1 from Hoff. Let \\(\\theta\\) and \\(\\gamma\\) be independent. Use the code below to load the data.\n\nbach30 = readr::read_csv(\"https://sta360-fa23.github.io/data/bach30.csv\")\n\nnobach30 = readr::read_csv(\"https://sta360-fa23.github.io/data/nobach30.csv\")"
  },
  {
    "objectID": "hw/hw05.html#exercise-3",
    "href": "hw/hw05.html#exercise-3",
    "title": "Homework 5",
    "section": "Exercise 3",
    "text": "Exercise 3\n6.2 from Hoff. Note the typo: \\(1/\\sigma_j^2\\) is gamma, not \\(1/\\sigma_j\\). Use the code below to load the data.\n\nglucose = readr::read_csv(\"https://sta360-fa23.github.io/data/glucose.csv\")"
  },
  {
    "objectID": "hw/hw06.html",
    "href": "hw/hw06.html",
    "title": "Homework 6",
    "section": "",
    "text": "6.3 from Hoff. You can simulate from a constrained normal distribution with mean mean and standard deviation sd, constrained to lie in the interval \\((a,b)\\) using the following function:\n\nrcnorm<-function(n, mean=0, sd=1, a=-Inf, b=Inf){\n  u = runif(n, pnorm((a - mean) / sd), pnorm((b - mean) / sd))\n  mean + (sd * qnorm(u))\n}\n\nNote that you can use this function to simulate a vector of constrained normal random variables, each with a potentially different mean, standard deviation, and constraints.\nTo load the data for this exercise, run the code below\n\ndivorce = readr::read_csv(\"https://sta360-fa23.github.io/data/divorce.csv\")"
  },
  {
    "objectID": "hw/hw06.html#exercise-2",
    "href": "hw/hw06.html#exercise-2",
    "title": "Homework 6",
    "section": "Exercise 2",
    "text": "Exercise 2\nShow that if \\(W \\sim \\text{Wishart}(m, S)\\) then \\(E[W] = mS\\)."
  },
  {
    "objectID": "hw/hw06.html#exercise-3",
    "href": "hw/hw06.html#exercise-3",
    "title": "Homework 6",
    "section": "Exercise 3",
    "text": "Exercise 3\nSuppose \\(Y\\) is a random normal vector \\(Y \\sim N_p(\\theta, \\Sigma)\\). Let \\(Y_A\\) be the first \\(p_1\\) elements of \\(Y\\) and \\(Y_B\\) be the last \\(p_2 = p - p_1\\) elements, so that \\(Y = (Y_A, Y_B)\\). Similarly, write \\(\\theta = (\\theta_A, \\theta_B)\\). Finally, let\n\\[\n\\Sigma^{-} \\equiv \\Psi = \\left[ {\\begin{array}{cc}\n   \\Psi_{AA} & \\Psi_{AB} \\\\\n   \\Psi_{BA} & \\Psi_{BB} \\\\\n  \\end{array} } \\right]\n\\]\nand note that \\(\\Psi_{AB} = \\Psi_{BA}^T\\). Find the conditional distribution of \\(Y_B\\) given \\(Y_A\\) in terms of \\(\\theta_A\\), \\(\\theta_B\\) and components of \\(\\Psi\\). Try to interpret how \\(E[Y_B|Y_A]\\) differs from \\(E[Y_B]\\) and how \\(V[Y_B|Y_A]\\) differs from \\(V[Y_B]\\).\n\nIdentities for exercise 3\nSome of the following identities will be helpful for interpretation.\nLet\n\\[\n\\Sigma = \\left[ {\\begin{array}{cc}\n   \\Sigma_{AA} & \\Sigma_{AB} \\\\\n   \\Sigma_{BA} & \\Sigma_{BB} \\\\\n  \\end{array} } \\right]\n\\]\nand\n\\[\n\\Psi = \\left[ {\\begin{array}{cc}\n   \\Psi_{AA} & \\Psi_{AB} \\\\\n   \\Psi_{BA} & \\Psi_{BB} \\\\\n  \\end{array} } \\right].\n\\]\nThen\n\\[\n\\begin{aligned}\n\\Psi_{AA}^- &= \\Sigma_{AA} - \\Sigma_{AB} \\Sigma_{BB}^- \\Sigma_{BA}\\\\\n\\Psi_{BB}^- &= \\Sigma_{BB} - \\Sigma_{BA} \\Sigma_{AA}^- \\Sigma_{AB}\\\\\n\\Psi_{AB} &= -\\Psi_{AA} \\Sigma_{AB} \\Sigma_{BB}^-\\\\\n\\Psi_{BA} &= -\\Psi_{BB} \\Sigma_{BA} \\Sigma_{AA}^-,\n\\end{aligned}\n\\]\nand note that \\(\\Sigma_{AB} = \\Sigma_{BA}^T\\) and \\(\\Psi_{AB} = \\Psi_{BA}^T\\)."
  },
  {
    "objectID": "hw/hw06.html#useful-identities-for-exercise-3",
    "href": "hw/hw06.html#useful-identities-for-exercise-3",
    "title": "Homework 6",
    "section": "Useful identities for exercise 3",
    "text": "Useful identities for exercise 3\nLet\n\\[\n\\Sigma = \\left[ {\\begin{array}{cc}\n   \\Sigma_{AA} & \\Sigma_{AB} \\\\\n   \\Sigma_{BA} & \\Sigma_{BB} \\\\\n  \\end{array} } \\right]\n\\]\nand\n\\[\n\\Psi = \\left[ {\\begin{array}{cc}\n   \\Psi_{AA} & \\Psi_{AB} \\\\\n   \\Psi_{BA} & \\Psi_{BB} \\\\\n  \\end{array} } \\right].\n\\]\nThen\n\\[\n\\begin{aligned}\n\\Psi_{AA}^- &= \\Sigma_{AA} - \\Sigma_{AB} \\Sigma_{BB}^- \\Sigma_{BA}\\\\\n\\Psi_{BB}^- &= \\Sigma_{BB} - \\Sigma_{BA} \\Sigma_{AA}^- \\Sigma_{AB}\\\\\n\\Psi_{AB} &= -\\Psi_{AA} \\Sigma_{AB} \\Sigma_{BB}^-\\\\\n\\Psi_{BA} &= -\\Psi_{BB} \\Sigma_{BA} \\Sigma_{AA}^-,\n\\end{aligned}\n\\]\nand note that \\(\\Sigma_{AB} = \\Sigma_{BA}^T\\) and \\(\\Psi_{AB} = \\Psi_{BA}^T\\)."
  },
  {
    "objectID": "notes/lec10-mvn.html",
    "href": "notes/lec10-mvn.html",
    "title": "Multivariate normal",
    "section": "",
    "text": "Example 1: Twenty two students take a reading comprehension test before and after receiving an instructional method. The result for each student is a bivariate vector \\(Y_i\\) that includes a pre- and post- instructional score.\n\n\n\n\n\nExample 2: We measure three features of Gentoo penguins: bill length, bill depth and body mass. For each penguin we record \\(Y_i\\), a three-dimensional vector of trait measurements.\n\n\n\n\n\n\n\n\n\nWe say a \\(p\\) dimensional vector \\(\\boldsymbol{Y}\\) has a multivariate normal distribution if its sampling density is given by\n\\[\np(\\boldsymbol{y}| \\boldsymbol{\\theta}, \\Sigma) = (2\\pi)^{-p/2} |\\Sigma|^{-1/2} \\exp\\{\n-\\frac{1}{2}(\\boldsymbol{y}-\\boldsymbol{\\theta})^T \\Sigma^{-1} (\\boldsymbol{y}- \\boldsymbol{\\theta})\n\\}\n\\]\nwhere\n\\[\n\\boldsymbol{y}=  \\left[ {\\begin{array}{cc}\n   y_1 \\\\\n   y_2\\\\\n   \\vdots\\\\\n   y_p\n  \\end{array} } \\right]\n  ~~~\n   \\boldsymbol{\\theta}= \\left[ {\\begin{array}{cc}\n   \\theta_1 \\\\\n   \\theta_2\\\\\n   \\vdots\\\\\n   \\theta_p\n  \\end{array} } \\right]\n  ~~~\n  \\Sigma =\n  \\left[ {\\begin{array}{cc}\n   \\sigma_1^2 & \\sigma_{12}& \\ldots & \\sigma_{1p}\\\\\n   \\sigma_{12} & \\sigma_2^2 &\\ldots & \\sigma_{2p}\\\\\n   \\vdots & \\vdots & & \\vdots\\\\\n   \\sigma_{1p} & \\ldots & \\ldots & \\sigma_p^2\n  \\end{array} } \\right].\n\\]\n\n\n\n\n\\(\\boldsymbol{y}\\in \\mathbb{R}^p\\) ; \\(\\boldsymbol{\\theta}\\in \\mathbb{R}^p\\); \\(\\Sigma > 0\\)\n\\(E[\\boldsymbol{y}] = \\boldsymbol{\\theta}\\)\n\\(V[\\boldsymbol{y}] = E[(\\boldsymbol{y}- \\boldsymbol{\\theta})(\\boldsymbol{y}- \\boldsymbol{\\theta})^T] = \\Sigma\\)\nMarginally, \\(y_i \\sim N(\\theta_i, \\sigma_i^2)\\).\nIf \\(\\boldsymbol{\\theta}\\) is a MVN random vector, then the kernel is \\(\\exp\\{-\\frac{1}{2} \\boldsymbol{\\theta}^T A \\boldsymbol{\\theta}+ \\boldsymbol{\\theta}^T \\boldsymbol{b} \\}\\). The mean is \\(A^{-1}\\boldsymbol{b}\\) and the covariance is \\(A^{-1}\\).\n\n\n\nlibrary(mvtnorm) contains functions we need.\n\nrmvnorm() to sample from a multivariate normal\ndmvnorm() to compute the density\npmvnorm() to compute the distribution function\nqmvnorm() to compute quantiles of the multivariate normal"
  },
  {
    "objectID": "notes/lec10-mvn.html#matrix-algebra-fundamentals",
    "href": "notes/lec10-mvn.html#matrix-algebra-fundamentals",
    "title": "Multivariate normal",
    "section": "Matrix algebra fundamentals",
    "text": "Matrix algebra fundamentals\n\nmatrix facts\n\nmatrix multiplication proceeds row \\(\\times\\) column, so if we have the product \\(AB\\), \\(A\\) must have the same number of ___ as B has ___.\nthe determinant of a matrix, \\(|A|\\), measures the size of the matrix\nthe identity matrix is the matrix multiplicative identity. It is represented by \\(\\boldsymbol{I}\\), in general \\(\\boldsymbol{I}_p\\) is a \\(p \\times p\\) matrix with 1 on each diagonal and 0 on every off-diagonal. \\(\\boldsymbol{I}A = A \\boldsymbol{I}= A\\).\nthe inverse of a matrix \\(A^{-1}\\) works as follows: \\(A A^{-1} = A^{-1}A = \\boldsymbol{I}\\).\nthe trace of a matrix, tr(A), is the sum of its diagonal elements\norder matters: \\(AB \\neq BA\\) in general.\n\\(\\Sigma > 0\\) is shorthand for saying the matrix is positive definite. This means that for all vectors \\(\\boldsymbol{x}\\), the quadratic form \\(\\boldsymbol{x}^T \\Sigma \\boldsymbol{x} > 0\\). \\(Sigma > 0 \\iff\\) all eigenvalues of \\(\\Sigma\\) are positive.\n\nExercise:\n\n\\(\\boldsymbol{\\theta}\\) and \\(\\boldsymbol{b}\\) are \\(p \\times 1\\) vectors, \\(A\\) is a symmetric matrix. Simplify \\(\\boldsymbol{b}^T A \\boldsymbol{\\theta}+ \\boldsymbol{\\theta}^T A \\boldsymbol{b}\\) what is the dimension of the result?\nwhat’s the dimension of \\(V[\\boldsymbol{y}]\\)?\n\n\n\nmatrix operations in R\n\n# make a matrix A\nA = matrix(c(1,.2, .2, 2), ncol = 2)\nA\n\n     [,1] [,2]\n[1,]  1.0  0.2\n[2,]  0.2  2.0\n\n# invert A (expensive for large matrices)\nAinv = solve(A)\n\n# matrix multiplication\nAinv %*% A\n\n     [,1] [,2]\n[1,]    1    0\n[2,]    0    1\n\n# determinant of A\ndet(A)\n\n[1] 1.96\n\n# trace of A\nsum(diag(A))\n\n[1] 3\n\n# create a vector b\nb = matrix(c(1, 2), ncol = 1)\nb\n\n     [,1]\n[1,]    1\n[2,]    2\n\n# transpose the vector b\nt(b)\n\n     [,1] [,2]\n[1,]    1    2\n\n\n\nb %*% A\n\nError in b %*% A: non-conformable arguments\n\n\n\nWhat went wrong in the code above?"
  },
  {
    "objectID": "notes/lec10-mvn.html#semi-conjugate-priors",
    "href": "notes/lec10-mvn.html#semi-conjugate-priors",
    "title": "Multivariate normal",
    "section": "Semi-conjugate priors",
    "text": "Semi-conjugate priors\n\nprior on \\(\\boldsymbol{\\theta}\\)\nIf\n\\[\n\\begin{aligned}\n\\boldsymbol{y}| \\boldsymbol{\\theta}, \\Sigma &\\sim MVN(\\boldsymbol{\\theta}, \\Sigma),\\\\\n\\boldsymbol{\\theta}&\\sim MVN(\\mu_0, \\Lambda_0),\n\\end{aligned}\n\\]\nthen\n\\[\n\\boldsymbol{\\theta}| \\boldsymbol{y}, \\Sigma \\sim MVN(\\boldsymbol{\\mu_n}, \\Lambda_n),\n\\]\nwhere\n\\[\n\\begin{aligned}\n\\Lambda_n &= (\\Lambda_0^{-1} + n \\Sigma^{-1} )^{-1},\\\\\n\\boldsymbol{\\mu_n} &= (\\Lambda_0^{-1} + n \\Sigma^{-1} )^{-1}(\\Lambda_0^{-1} \\boldsymbol{\\mu}_0 + n \\Sigma^{-1} \\bar{\\boldsymbol{y}}).\n\\end{aligned}\n\\]\nExercise: interprt \\(E[\\boldsymbol{\\theta}| \\boldsymbol{y}_1, \\ldots \\boldsymbol{y}_n, \\Sigma]\\) and \\(Cov[\\boldsymbol{\\theta}| \\boldsymbol{y}_1, \\ldots \\boldsymbol{y}_n, \\Sigma]\\)."
  },
  {
    "objectID": "notes/lec10-mvn.html#semiconjugate-priors",
    "href": "notes/lec10-mvn.html#semiconjugate-priors",
    "title": "Multivariate normal",
    "section": "Semiconjugate priors",
    "text": "Semiconjugate priors\n\nsemiconjugate prior for \\(\\boldsymbol{\\theta}\\)\nIf\n\\[\n\\begin{aligned}\n\\boldsymbol{y}| \\boldsymbol{\\theta}, \\Sigma &\\sim MVN(\\boldsymbol{\\theta}, \\Sigma),\\\\\n\\boldsymbol{\\theta}&\\sim MVN(\\mu_0, \\Lambda_0),\n\\end{aligned}\n\\]\nthen\n\\[\n\\boldsymbol{\\theta}| \\boldsymbol{y}, \\Sigma \\sim MVN(\\boldsymbol{\\mu_n}, \\Lambda_n),\n\\]\nwhere\n\\[\n\\begin{aligned}\n\\Lambda_n &= (\\Lambda_0^{-1} + n \\Sigma^{-1} )^{-1},\\\\\n\\boldsymbol{\\mu_n} &= (\\Lambda_0^{-1} + n \\Sigma^{-1} )^{-1}(\\Lambda_0^{-1} \\boldsymbol{\\mu}_0 + n \\Sigma^{-1} \\bar{\\boldsymbol{y}}).\n\\end{aligned}\n\\]\nExercise: interpret \\(E[\\boldsymbol{\\theta}| \\boldsymbol{y}_1, \\ldots \\boldsymbol{y}_n, \\Sigma]\\) and \\(Cov[\\boldsymbol{\\theta}| \\boldsymbol{y}_1, \\ldots \\boldsymbol{y}_n, \\Sigma]\\).\n\n\nsemiconjugate prior for \\(\\Sigma\\)\nIf\n\\[\n\\begin{aligned}\n\\boldsymbol{y}| \\boldsymbol{\\theta}, \\Sigma &\\sim MVN(\\boldsymbol{\\theta}, \\Sigma),\\\\\n\\Sigma &\\sim \\text{inverse-Wishart}(\\nu_0, S_0^{-1}),\n\\end{aligned}\n\\]\nthen\n\\[\n\\Sigma | \\boldsymbol{y}, \\boldsymbol{\\theta}\\sim \\text{inverse-Wishart} (\\nu_0 + n, (S_0 + S_{\\theta})^{-1}),\n\\]\nwhere \\(S_\\theta = \\sum_{i=1}^n (\\boldsymbol{y}_i - \\boldsymbol{\\theta})(\\boldsymbol{y}_i - \\boldsymbol{y})^T\\) is the residual sum of squares matrix for the vectors \\(\\boldsymbol{y}_1, \\ldots \\boldsymbol{y}_n\\) if the population mean is \\(\\boldsymbol{\\theta}\\).\n\n\n\nthe inverse-Wishart\nthe inverse-Wishart\\((\\nu_0, S_0^{-1})\\) density is given by\n\\[\n\\begin{aligned}\np(\\Sigma | \\nu_0, S_0^{-1}) = \\left[\n2^{\\nu_0 p / 2} \\pi^{{p \\choose 2}/2} |S_0|^{-\\nu_0/2} \\prod_{j = 1}^p \\Gamma([\\nu_0 + 1 - j]/2)\n\\right]^{-1} \\times\\\\\n|\\Sigma|^{-(\\nu_0 + p + 1)/2} \\times \\exp \\{ -\\frac{1}{2}tr(S_0 \\Sigma^{-1})\\}.\n\\end{aligned}\n\\]\n\nKey facts\n\nnotice that the first line is the normalizing constant of the density\nthe support is \\(\\Sigma > 0\\) and \\(\\Sigma\\) symmetric \\(p \\times p\\) matrix. \\(\\nu_0 \\in \\mathbb{N}^+\\) and \\(\\nu_0 \\geq p\\). \\(S_0\\) is a \\(p \\times p\\) symmetric positive definite matrix.\nif \\(\\Sigma\\) is inv-Wishart\\((\\nu_0, S_0^{-1})\\) then \\(\\Sigma^{-1}\\) is Wishart\\((\\nu_0, S_0^{-1})\\).\n\\(E[\\Sigma^{-1}] = \\nu_0 S_0^{-1}\\) and \\(E[\\Sigma] = \\frac{1}{\\nu_0 - p - 1} S_0\\).\nintuition: \\(\\nu_0\\) is prior sample size. \\(S_0\\) is a prior guess of the covariance matrix.\n\n\n\nsampling from the inverse-Wishart\n\npick \\(\\nu_0 > p\\), pick \\(S_0\\)\nsample \\(\\boldsymbol{z}_1, \\ldots \\boldsymbol{z}_{\\nu_0} \\sim \\text{ i.i.d. } MVN(\\boldsymbol{0}, S_0^{-1})\\)\ncalculate \\(\\boldsymbol{Z}^T \\boldsymbol{Z} = \\sum_{i = 1}^{\\nu_0} \\boldsymbol{z}_i \\boldsymbol{z}^T\\)\nset \\(\\Sigma = (\\boldsymbol{Z}^T \\boldsymbol{Z})^{-1}\\)\n\n\nlibrary(mvtnorm) # contains function rmvnorm\n\n# 2x2 example: generating 1 sample from an inv-Wishart\nset.seed(360)\np = 2\nnu0 = 3\nS0 = matrix(c(1, .1, .1, 1), ncol = 2)\nS0inv = solve(S0)\nZ = rmvnorm(n = nu0, # number of observations of the 2D vector Z\n        mean = rep(0, p), # mean 0\n        sigma = S0inv) # prior variance\nSigma = solve(t(Z) %*% Z)\neigen(Sigma)$values\n\n[1] 0.7821737 0.4174527\n\nSigma\n\n           [,1]      [,2]\n[1,]  0.5271834 -0.167273\n[2,] -0.1672730  0.672443\n\n\nExercise/show offline: why does this work? Hint: what is \\(cov[\\boldsymbol{z}]\\)?\nWe can also use the monomvn package to simulate from a Wishart more succinctly,\n\nlibrary(monomvn)\n\nset.seed(360)\nSigma = solve(rwish(nu0, S0inv))\neigen(Sigma)$values\n\n[1] 0.692529 0.160428\n\nSigma\n\n          [,1]      [,2]\n[1,] 0.1899212 0.1217519\n[2,] 0.1217519 0.6630358"
  },
  {
    "objectID": "slides/lab-5.html#full-conditionals-are-proportional-to-the-joint",
    "href": "slides/lab-5.html#full-conditionals-are-proportional-to-the-joint",
    "title": "Full conditionals",
    "section": "Full conditionals are proportional to the joint",
    "text": "Full conditionals are proportional to the joint\nSuppose \\(X, Y, Z, \\theta, \\phi\\) are random variables,\n\\[\n\\begin{aligned}\np(x| y, z, \\theta, \\phi) &=\n\\frac{p(x, y, z, \\theta, \\phi)}{\\int p(x,y,z,\\theta, \\phi) dx}\\\\\n&\\propto_x p(x| y, z, \\theta, \\phi)\n\\end{aligned}\n\\]\nSimilarly, each full conditional is proportional to the joint distribution.\n\n\n🔗 sta360-fa23.github.io"
  },
  {
    "objectID": "quizzes/quiz05.html",
    "href": "quizzes/quiz05.html",
    "title": "Quiz 5",
    "section": "",
    "text": "Exercise 1\nWhat is the purpose of Gibbs sampling?\n\n\nExercise 2\n\\(\\mathbf{x}\\) is a \\(p \\times 1\\) vector.\nWhat is the dimension of \\(\\mathbf{x}^T \\Sigma \\mathbf{x}\\)?\n\n\nExercise 3\nLet \\(\\mathbf{y} = \\left[ {\\begin{array}{cc}  y_1 \\\\  y_2  \\end{array} } \\right]\\), \\(\\boldsymbol{\\theta} = \\left[ {\\begin{array}{cc}  4 \\\\  8  \\end{array} } \\right]\\), \\(\\Sigma = \\left[ {\\begin{array}{cc}  1 & .2 \\\\  .2 & 1.3\\\\  \\end{array} } \\right]\\).\nIf \\(\\mathbf{y} | \\boldsymbol{\\theta}, \\Sigma \\sim MVN(\\boldsymbol{\\theta}, \\Sigma)\\), then \\(y_1 \\sim N(a, b)\\). What is \\(a\\) and \\(b\\)?\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "notes/lec11-missing-data-mvn.html",
    "href": "notes/lec11-missing-data-mvn.html",
    "title": "Inference under MVN with missing data",
    "section": "",
    "text": "This example is from Hoff ch. 7.\nLoad libraries and data.\n\nlibrary(tidyverse)\nlibrary(mvtnorm)\nlibrary(monomvn)\nlibrary(coda)\nY = read_csv(\"https://sta360-fa23.github.io/data/Pima.csv\") %>%\n  as.matrix() \ncolnames(Y) = NULL\n\nThis data set contains\n\nglu blood plasma glucose concentration\nbp diastolic blood pressure\nskin skin fold thickness\nbmi body mass index\n\nfor 200 women of Pima Indian heritage living near Phoenix, Arizona (Smith et al, 1988). Some observations are missing.\n\n\nSetup prior parameters and starting values.\n\n## prior parameters\nn = nrow(Y); p = ncol(Y)\n# prior on theta\nmu0 = c(120, 64, 26, 26); sd0 = (mu0 / 2)\nL0 = matrix(.1, p, p)\ndiag(L0) = 1 \nL0 = L0 * outer(sd0, sd0) # \\Lambda_0\n# prior on Sigma\nnu0 = p + 2; \nS0 = L0\n###\n\n### starting values\nSigma = S0\nY.full = Y\nO = 1 * (!is.na(Y)) # indices for observe values of Y\n\nfor(j in 1:p) {\n  Y.full[is.na(Y.full[,j]),j]<-mean(Y.full[,j],na.rm=TRUE)\n} \n\nExercise: what does the code above set the starting values of \\(\\theta, \\Sigma\\) and \\(\\textbf{Y}_{\\text{mis}}\\) to?\nThe Gibbs sampler.\n\n### Gibbs sampler\nTHETA <- SIGMA <- Y.MISS <- NULL\nset.seed(360)\n\nfor(s in 1:1000) {\n\n  ###update theta\n  ybar <- apply(Y.full, 2 , mean)\n  Ln <- solve(solve(L0) + n * solve(Sigma))\n  mun <- Ln %*% (solve(L0) %*% mu0 + n * solve(Sigma) %*% ybar)\n  theta <- rmvnorm(1, mun, Ln)\n  ###\n  \n  ###update Sigma\n  Sn <- S0 + (t(Y.full) - c(theta)) %*% t(t(Y.full) - c(theta))\n  Sigma <- rwish(nu0 + n, solve(Sn))\n  ###\n  \n  ###update missing data\n  for(i in 1:n) { \n    b <- (O[i, ] == 0)\n    a <- (O[i, ] == 1)\n    if( sum(b) != 0) {\n    iSa <- solve(Sigma[a, a])\n    beta.j <- Sigma[b, a] %*% iSa\n    s2.j   <- Sigma[b, b] - Sigma[b, a] %*% iSa %*% Sigma[a, b]\n    theta.j <- theta[b] + beta.j %*% (as.matrix(Y.full[i, a]) - theta[a])\n    Y.full[i, b] <- rmvnorm(1, theta.j, s2.j)\n    }\n  }\n  \n  ### save results\n  THETA<-rbind(THETA,theta) ; SIGMA<-rbind(SIGMA,c(Sigma))\n  Y.MISS<-rbind(Y.MISS, Y.full[O==0] )\n  ###\n\n  if(s %% 250 == 0 | s == 1) {\n  cat(s,theta,\"\\n\")\n  }\n}\n\n1 129.6031 71.66437 28.97947 31.385 \n250 123.6105 70.56862 29.10075 30.97481 \n500 123.6067 70.36211 29.20791 31.03185 \n750 123.6179 70.78825 29.29216 30.90945 \n1000 123.6017 70.15369 29.22685 31.08064 \n\n#### Posterior mean\napply(THETA,2,mean)\n\n[1] 123.60189  70.57085  29.16132  31.79352\n\n\n\n\n\nEffective sample size of THETA\n\n# effective sample size of THETA \napply(THETA, 2, effectiveSize)\n\n[1]  879.4569 3680.4806 4411.2164 7721.7664"
  },
  {
    "objectID": "notes/lec11-missing-data-mvn.html#inference-using-gibbs-sampling",
    "href": "notes/lec11-missing-data-mvn.html#inference-using-gibbs-sampling",
    "title": "Inference under MVN with missing data",
    "section": "Inference using Gibbs sampling",
    "text": "Inference using Gibbs sampling\nSetup prior parameters and starting values.\n\n## prior parameters\nn = nrow(Y); p = ncol(Y)\n# prior on theta\nmu0 = c(120, 64, 26, 26); sd0 = (mu0 / 2)\nL0 = matrix(.1, p, p)\ndiag(L0) = 1 \nL0 = L0 * outer(sd0, sd0) # \\Lambda_0\n# prior on Sigma\nnu0 = p + 2; \nS0 = L0\n###\n\n### starting values\nSigma = S0\nY.full = Y\nO = 1 * (!is.na(Y)) # indices for observe values of Y\n\nfor(j in 1:p) {\n  Y.full[is.na(Y.full[,j]),j]<-mean(Y.full[,j],na.rm=TRUE)\n} \n\nExercise: what does the code above set the starting values of \\(\\theta, \\Sigma\\) and \\(\\textbf{Y}_{\\text{mis}}\\) to?\nThe Gibbs sampler.\n\n### Gibbs sampler\nTHETA <- SIGMA <- Y.MISS <- NULL\nset.seed(360)\n\nfor(s in 1:1000) {\n\n  ###update theta\n  ybar <- apply(Y.full, 2 , mean)\n  Ln <- solve(solve(L0) + n * solve(Sigma))\n  mun <- Ln %*% (solve(L0) %*% mu0 + n * solve(Sigma) %*% ybar)\n  theta <- rmvnorm(1, mun, Ln)\n  ###\n  \n  ###update Sigma\n  Sn <- S0 + (t(Y.full) - c(theta)) %*% t(t(Y.full) - c(theta))\n  Sigma <- rwish(nu0 + n, solve(Sn))\n  ###\n  \n  ###update missing data\n  for(i in 1:n) { \n    b <- (O[i, ] == 0)\n    a <- (O[i, ] == 1)\n    if( sum(b) != 0) {\n    iSa <- solve(Sigma[a, a])\n    beta.j <- Sigma[b, a] %*% iSa\n    s2.j   <- Sigma[b, b] - Sigma[b, a] %*% iSa %*% Sigma[a, b]\n    theta.j <- theta[b] + beta.j %*% t((t(Y.full[i, a]) - theta[a]))\n    Y.full[i, b] <- rmvnorm(1, theta.j, s2.j)\n    }\n  }\n  \n  ### save results\n  THETA<-rbind(THETA,theta) ; SIGMA<-rbind(SIGMA,c(Sigma))\n  Y.MISS<-rbind(Y.MISS, Y.full[O==0] )\n  ###\n\n  if(s %% 250 == 0 | s == 1) {\n  cat(s,theta,\"\\n\")\n  }\n}\n\n1 129.6031 71.66437 28.97947 31.385 \n250 123.6105 70.56862 29.10075 30.97481 \n500 123.6067 70.36211 29.20791 31.03185 \n750 123.6179 70.78825 29.29216 30.90945 \n1000 123.6017 70.15369 29.22685 31.08064 \n\n#### Posterior mean and correlation matrix\napply(THETA,2,mean)\n\n[1] 123.60189  70.57085  29.16132  31.79352\n\nCOR <- array( dim=c(p,p,1000) )\nfor(s in 1:1000)\n{\n  Sig<-matrix( SIGMA[s,] ,nrow=p,ncol=p)\n  COR[,,s] <- Sig/sqrt( outer( diag(Sig),diag(Sig) ) )\n}\n\napply(COR,c(1,2),mean)\n\n            [,1]        [,2]        [,3]        [,4]\n[1,]  1.00000000 -0.05304617 -0.02145301 -0.02476015\n[2,] -0.05304617  1.00000000 -0.05261611 -0.05542203\n[3,] -0.02145301 -0.05261611  1.00000000 -0.24354650\n[4,] -0.02476015 -0.05542203 -0.24354650  1.00000000\n\n\nEffective sample size of THETA\n\n# effective sample size of THETA \napply(THETA, 2, effectiveSize)\n\n[1]  879.4569 3680.4806 4411.2164 7721.7664"
  },
  {
    "objectID": "notes/lec12-hierarchical-intro.html",
    "href": "notes/lec12-hierarchical-intro.html",
    "title": "Hierarchical modeling",
    "section": "",
    "text": "Example from Hoff Ch. 8\n\nEach year, students across North Carolina take an identical standardized test. In our sample, we observe scores from students at \\(m\\) different schools. At the \\(j\\)th school, \\(n_j\\) students take the exam and \\(j \\in \\{1, \\ldots m\\}\\). The exam is designed to give an average score of 50 on a 0 to 100 scale.\n\n\n\n# load packages\nlibrary(tidyverse)\nlibrary(coda)\n\n\n# load data\nmathScores = read_csv(\"https://sta360-fa23.github.io/data/mathScores.csv\")\n\n\nhead(mathScores, n = 3)\n\n# A tibble: 3 × 2\n  school mathscore\n   <dbl>     <dbl>\n1      1      52.1\n2      1      57.6\n3      1      66.4\n\n\nCodebook\n\nschool: which school the math score came from\nmathScore: score from 0 to 100 of an individual student\n\n\n\n\n\n\n\n\nConvert data to list for downstream processing\nY.school.mathscore <- as.matrix(mathScores)\n#### Put data into list form.\nY <- list()\nJ <- max(Y.school.mathscore[, 1])\nn <- ybar <- ymed <- s2 <- rep(0, J)\nfor (j in 1:J) {\n  Y[[j]] <- Y.school.mathscore[Y.school.mathscore[, 1] == j, 2]\n}"
  },
  {
    "objectID": "notes/lec12-hierarchical-intro.html#questions-about-the-data",
    "href": "notes/lec12-hierarchical-intro.html#questions-about-the-data",
    "title": "Hierarchical modeling",
    "section": "Questions about the data",
    "text": "Questions about the data\n\nHow are the schools ranked?\nDoes school 51 have a higher average score than school 41?\nWhat is the probability a single student randomly selected from school 51 performs better on the exam than a single student randomly selected from school 41?"
  },
  {
    "objectID": "notes/lec12-hierarchical-intro.html#modeling",
    "href": "notes/lec12-hierarchical-intro.html#modeling",
    "title": "Hierarchical modeling",
    "section": "Modeling",
    "text": "Modeling"
  },
  {
    "objectID": "notes/lec12-hierarchical-intro.html#gibbs-sampling",
    "href": "notes/lec12-hierarchical-intro.html#gibbs-sampling",
    "title": "Hierarchical modeling",
    "section": "Gibbs sampling",
    "text": "Gibbs sampling\n\n#### MCMC approximation to posterior for the hierarchical normal model\n\n## weakly informative priors\nnu0 <- 1; s20 <- 100\neta0 <- 1; t20 <- 100\nmu0 <- 50; g20 <- 25\n\n## starting values\nm <- length(Y)\nn <- sv <- ybar <- rep(NA, m)\nfor (j in 1:m)\n{\n  ybar[j] <- mean(Y[[j]])\n  sv[j] <- var(Y[[j]])\n  n[j] <- length(Y[[j]])\n}\ntheta <- ybar\nsigma2 <- mean(sv)\nmu <- mean(theta)\ntau2 <- var(theta)\n\n## setup MCMC\nset.seed(1)\nS <- 5000\nTHETA <- matrix(nrow = S, ncol = m)\nMST <- matrix(nrow = S, ncol = 3)\npredictiveY = NULL\n\n## MCMC algorithm\nfor (s in 1:S)\n{\n  # sample new values of the thetas\n  for (j in 1:m)\n  {\n    vtheta <- 1 / (n[j] / sigma2 + 1 / tau2)\n    etheta <- vtheta * (ybar[j] * n[j] / sigma2 + mu / tau2)\n    theta[j] <- rnorm(1, etheta, sqrt(vtheta))\n  }\n  \n  #sample new value of sigma2\n  nun <- nu0 + sum(n)\n  ss <- nu0 * s20\n  for (j in 1:m) {\n    ss <- ss + sum((Y[[j]] - theta[j]) ^ 2)\n  }\n  sigma2 <- 1 / rgamma(1, nun / 2, ss / 2)\n  \n  #sample a new value of mu\n  vmu <- 1 / (m / tau2 + 1 / g20)\n  emu <- vmu * (m * mean(theta) / tau2 + mu0 / g20)\n  mu <- rnorm(1, emu, sqrt(vmu))\n  \n  # sample a new value of tau2\n  etam <- eta0 + m\n  ss <- eta0 * t20 + sum((theta - mu) ^ 2)\n  tau2 <- 1 / rgamma(1, etam / 2, ss / 2)\n  \n  #store results\n  THETA[s, ] <- theta\n  MST[s, ] <- c(mu, sigma2, tau2)\n  \n  # predictive sampling\n  y51 = rnorm(1, mean = theta[51], sd = sqrt(sigma2))\n  y41 = rnorm(1, mean = theta[41], sd = sqrt(sigma2))\n  predictiveY = rbind(predictiveY, c(y51, y41))\n  \n}\n\nmcmc1 <- list(THETA = THETA, MST = MST)"
  },
  {
    "objectID": "notes/lec12-hierarchical-intro.html#answers",
    "href": "notes/lec12-hierarchical-intro.html#answers",
    "title": "Hierarchical modeling",
    "section": "Answers",
    "text": "Answers\n\nHow are the schools ranked? How does the ordering compare to just ranking the schools by the sample means?\n\n\n# Ordering E[theta | data] and comparing to ybar\n\nposteriorMean = THETA %>%\n  apply(2, mean)\n\norderedTable = mathScores %>%\n  group_by(school) %>%\n  summarize(ybar = mean(mathscore),\n            n = n()) %>%\n  cbind(posteriorMean) %>%\n  arrange(posteriorMean) %>%\n  relocate(school, n, ybar, posteriorMean) %>%\n  mutate_if(is.numeric, round, digits = 2)\n\nDT::datatable(\n  orderedTable,\n  fillContainer = FALSE, options = list(pageLength = 10)\n)\n\n\n\n\n\n\nHow many of the schools are ranked in the same position in the posterior ordering as the sample mean ordering?\n\noutputcode\n\n\n\n\n[1] 46\n\n\n\n\n\npostOrdering = posteriorMean %>%\n  order()\n\nybarOrdering = mathScores %>%\n  group_by(school) %>%\n  summarize(ybar = mean(mathscore), \n            n = n()) %>%\n  arrange(ybar) %>%\n  pull(school)\n\nsum(postOrdering == ybarOrdering)\n\n\n\n\n\nDoes school 51 have a higher average score than school 41? Re-cast as a Bayesian question: what’s \\(p(\\theta_{51} > \\theta_{41} | \\text{data})\\)?\n\n\nmean(THETA[,51] > THETA[,41])\n\n[1] 0.9892\n\n\n\nWhat’s the probability a student randomly selected from school 51 performs better than a student selected randomly from school 41?\n\nBefore looking at the solution below, how would you answer this problem?\n\n\nSolution\nmean(predictiveY[,1] > predictiveY[,2])\n\n# output:\n# [1] 0.685"
  },
  {
    "objectID": "notes/lec12-hierarchical-intro.html#mcmc-diagnostics",
    "href": "notes/lec12-hierarchical-intro.html#mcmc-diagnostics",
    "title": "Hierarchical modeling",
    "section": "MCMC diagnostics",
    "text": "MCMC diagnostics\n\ntrace plots\n\nplotscode\n\n\n\n\n\n\n\n\n\n\ncolnames(MST) = c(\"mu\", \"sigma2\", \"tau2\")\nMST2 = MST %>%\n  as.data.frame() %>% \n  pivot_longer(cols = 1:3)\n\nMST2 %>%\n  ggplot(aes(x = seq(1, nrow(MST2)), y = value)) +\n  geom_line() +\n  theme_bw() +\n  facet_wrap(~ name, scales = \"free_y\") +\n  labs(y = \"mu\",\n       x = \"iteration\",\n       title = \"Traceplot of 5000 Gibbs samples\")\n\n\n\n\n\n\neffective sample size and autocorrelation\n\neffectiveSize(MST)\n\n      mu    sigma      tau \n3925.336 4461.112 2905.517 \n\npar(mfrow=c(1,3))\nacf(MST[,1])\nacf(MST[,2]) \nacf(MST[,3]) \n\n\n\n\n\n\nposterior means and standard error\n\n# MC error of mu, sigma2, tau2\nMCERR <- apply(MST,2,sd)/sqrt( effectiveSize(MST) )\napply(MST,2,mean)\n\n      mu    sigma      tau \n48.12530 84.82892 24.79410 \n\nMCERR\n\n         mu       sigma         tau \n0.008528321 0.041664073 0.082344432 \n\n\nWe can do the exact same for the thetas, but the output will be 100 lines, so I suppress output below.\n\n# MC error of thetas\neffectiveSize(THETA) -> esTHETA\nTMCERR <- apply(THETA,2,sd)/sqrt( effectiveSize(THETA) )\nTMCERR"
  },
  {
    "objectID": "notes/lec12-hierarchical-intro.html#model",
    "href": "notes/lec12-hierarchical-intro.html#model",
    "title": "Hierarchical modeling",
    "section": "Model",
    "text": "Model\nSuppose students scores at school \\(j\\) are exchangeable for all \\(n_j\\). By de Finetti’s theorem, this means\n\\[\n\\{y_{1,j}, \\ldots y_{n_j,j} | \\phi_j \\} \\sim \\text{ i.i.d. } p(y|\\phi_j).\n\\]\nThat is, the student’s scores at school \\(j\\) are conditionally i.i.d. given some school specific parameters \\(\\phi_j\\). This describes our within-group sampling variability.\nNow suppose that all the schools we sampled are similar in some way. Maybe they belong to some larger population of schools across the country i.e. schools in North Carolina are somewhat distinct from schools in South Carolina. We might imagine that the school-specific parameters themselves are exchangeable for all \\(m\\). By de Finetti’s theorem, this means\n\\[\n\\{\\phi_1, \\ldots \\phi_m\\} \\sim \\text{ i.i.d. } p(\\phi|\\psi).\n\\]\nIn words, school-specific parameters are conditionally i.i.d. given some population specific parameters \\(\\psi\\). This describes our between-group sampling variability.\nFinally, if our hierarchy stops there, then to complete model specification, we may describe our prior beliefs about \\(\\psi\\) according to some prior density \\(p(\\psi)\\).\nExercise: Imagine variability among scores is the same across all schools, but there does exist heterogeneity in the mean scores of the schools. Write down the mathemtical form of a model that describes this using the normal distribution. What are some priors you could pick on relevant parameters to make sure full conditionals are easy to compute for Gibbs sampling? What are the full conditionals?\n\nSolution:\n\nsampling distributions:\n\n\\[\n\\begin{aligned}\np(y_j | \\theta_j, \\sigma^2) &\\sim N(\\theta_j, \\sigma^2)\\\\\np(\\theta_j | \\mu, \\tau^2) &\\sim N(\\mu, \\tau^2)\n\\end{aligned}\n\\]\n\npriors distributions:\n\n\\[\n\\begin{aligned}\np(1/\\sigma^2) &\\sim \\text{ gamma}(\\nu_0/2, \\nu_0 \\sigma_0^2/2)\\\\\np(1/\\tau^2) &\\sim \\text{ gamma}(\\eta_0/2, \\eta_0 \\tau_0^2/2)\\\\\n\\mu &\\sim N(\\mu_0, \\gamma_0^2)\n\\end{aligned}\n\\]\n\nTo facilitate Gibbs sampling, notice\n\\[\np(\\theta_1, \\ldots \\theta_m, \\mu, \\tau^2, \\sigma^2 | \\mathbf{y}_1, \\ldots \\mathbf{y}_m) \\propto\np(\\mu, \\tau^2, \\sigma^2) p(\\theta_1, \\ldots \\theta_m | \\mu, \\tau^2, \\sigma^2) \\times p(\\mathbf{y}_1, \\ldots \\mathbf{y}_m| \\theta_1, \\ldots \\theta_m, \\mu, \\tau^2, \\sigma^2)\n\\]\nIt follows that the full conditionals are:\n\\[\n\\begin{aligned}\np(\\mu | \\cdot) &\\propto p(\\mu) \\prod_{j = 1}^m p(\\theta_j| \\mu, \\tau^2)\\\\\np(\\tau^2 | \\cdot) &\\propto p(\\tau^2) \\prod_{j = 1}^m p(\\theta_j| \\mu, \\tau^2)\\\\\np(\\sigma^2|\\cdot) &\\propto p(\\sigma^2)\\prod_{j =1}^m \\prod_{i = 1}^{n_j} p(y_{i,j}|\\theta_j, \\sigma^2)\\\\\np(\\theta_j | \\cdot) &\\propto p(\\theta_j | \\mu, \\tau^2) \\prod_{i = 1}^{n_j} p(y_{i,j}|\\theta_j, \\sigma^2)\n\\end{aligned}\n\\]"
  }
]