---
title: "Chapter summaries"
mainfont: Lato
format: 
  html:
    toc: true
---

## Chapter 2

*Axioms of probability*

For all sets $F$, $G$ and $H$,

- $0 = Pr(\neg H | H) \leq Pr(F | H) \leq Pr(H | H) = 1$
- $Pr(F \cup G | H) = Pr(F|H) + Pr(G|H) \text{ if } F \cap G = \emptyset$
- $Pr(F \cap G | H) = Pr(G | H) Pr(F | G \cap H)$

*Partitions and probability*

Suppose $\{ H_1, \ldots, H_K\}$ is a partition of $\mathcal{H}$, $Pr(\mathcal{H}) = 1$ and $E$ is some specific event. From the axioms of probability one may prove:

- *Rule of total probability*: 

\begin{equation}
\sum_{k = 1}^K Pr(H_k) = 1
\end{equation}

- *Rule of marginal probability*:

\begin{equation}
\begin{aligned} 
Pr(E) &= \sum_{k = 1}^K Pr(E \cap H_k)\\ &= \sum_{k = 1}^K Pr(E | H_k) Pr(H_k) 
\end{aligned}
\end{equation}

- *Bayes' theorem*: 

\begin{equation}
Pr(H_j | E) = \frac{Pr(E|H_j) Pr(H_j)}{Pr(E)}
\end{equation}

Note it is often useful to replace the denominator, $Pr(E)$, using the rule of marginal probability.

*Independence*

Two events $F$ and $G$ are conditionally independent given $H$ if $Pr(F \cap G |H) = Pr(F|H) Pr(G|H)$.


### Additional related content (Ch2)

- *Law of total expectation* $E(X) = E(E(X|Y))$ 
- *Law of total variance* $Var(X) = E(Var(X|Y)) + Var(E(X|Y))$

::: callout-note
Remember we can always add conditioning statements e.g.

- *Law of total expectation* $E(X|Z) = E(E(X|Y)|Z)$ 
- *Law of total variance* $Var(X|Z) = E(Var(X|Y)|Z) + Var(E(X|Y)|Z)$

:::

## Chapter 3

### Definitions and conjugacy

- Be able to define **likelihood**, **prior**, **poserior**, **normalizing constant**

::: callout-note
## Definition
A prior $p(\theta)$ is said to be **conjugate** to the data generative model $p(y|\theta)$ if the family of the posterior is necessarily in the same family as the prior. In math,  $p(\theta)$ is conjugate to $p(y|\theta)$ if

$$
p(\theta) \in \mathcal{P} \implies p(\theta | y) \in \mathcal{P}
$$
:::

- Examples of conjugate models: beta-binomial, gamma-Poisson.

### Reliability 

::: callout-note
## Definition
Let $\Phi$ be the support of $\theta$.
An interval $(l(y), u(y)) \subset \Phi$ has 95% **posterior coverage** if 

$$
p(l(y) < \theta < u(y) | y ) = 0.95
$$

Interpretation: after observing $Y = y$, our probability that $\theta \in (l(y), u(y))$ is 95%.

Such an interval is called 95% posterior confidence interval (CI). It may also sometimes be referred to as a 95% "credible interval" to distinguish it from a frequentist CI.
:::

::: callout-note
## Definition

A $100 \times (1-\alpha)$% **high posterior density** (HPD) region is a set $s(y) \subset \Theta$ such that 


1. $p(\theta \in s(y) | Y = y) = 1 - \alpha$

2. If $\theta_a \in s(y)$ and $\theta_b \not\in s(y)$, then $p(\theta_a | Y = y) > p(\theta_b | Y = y)$
:::

### Exponential families

If density $p(y|\theta)$ can be written $h(y) c(\phi) e^{\phi t(y)}$ for some transform $\phi = f(\theta)$ we can say $p(y|\theta)$ belongs in the exponential family, and the conjugate prior is $p(\phi | n_0, t_0) =c(\phi)^{n_0} e^{n_0 t_0 \phi}$. Note: the conjugate prior is given over $\phi$ and we'd have to transform back if we care about $p(\theta)$.

## Chapter 4

### Predictive distributions

The posterior predictive distribution,

$$
p(\tilde{y} | y_1, \ldots y_n) = \int p(\tilde{y}|\theta) p(\theta|y_1, \ldots, y_n)d\theta
$$

when $Y | \theta$ conditionally iid.

The prior predictive distribution,

$$
p(\tilde{y}) = \int p(\tilde{y}|\theta) p(\theta)d\theta.
$$

Notice both the posterior and prior predictive distributions are represented as **integrals**. Integrals are expectations. This means we can use Monte Carlo integration to approximate.

To approximate the posterior predictive distribution:

1. sample from the posterior of theta, $p(\theta|y_1,\ldots y_n)$
2. sample from data generative model $p(\tilde{y}|\theta)$ for the values of theta sampled in (1).

To approximate the prior predictive distribution:

1. sample from the prior of theta, $p(\theta)$
2. sample from the data generative model $p(\tilde{y}|\theta)$ for the values of theta sampled in (1).

### Monte Carlo error

Since Monte Carlo approximation can be viewed as a sample mean approximating an expected value, CLT applies. 

More specifically, if $\theta_i |\vec{y}$ iid with mean $\theta$ and finite variance $\sigma^2$, for $i \in \{1, \ldots, N\}$, then the sample mean

$$
\bar{\theta} \sim N(\theta, \frac{\sigma^2}{N} ).
$$

and Monte Carlo estimates converge at a rate $\mathcal{O}\left(\frac{1}{\sqrt{N}}\right)$ regardless of the dimension of the integral!

### The sampling view

If we have a posterior $p(\theta | y_1, \ldots y_n)$ that we can sample from and we want some summary of the posterior... e.g. we want

- $p(\theta < a)$
- quantiles of the posterior , or 
- the posterior of some transform $f(\theta)$, 

then we can simply sample from the posterior to obtain an empirical approximation of the posterior and then report the empirical quantity of interest. This is also called Monte Carlo approximation.

The procedure can be written:

1. sample from the posterior $p(\theta |y_1, \ldots y_n)$ some large number of times and then 
2. compute the quantity of interest



